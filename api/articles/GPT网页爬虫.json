{"title":"GPT网页爬虫","uid":"e70118a7ef900115be6534ffca042ddb","slug":"GPT网页爬虫","date":"2023-12-30T13:29:01.000Z","updated":"2024-02-22T03:52:13.945Z","comments":true,"path":"api/articles/GPT网页爬虫.json","keywords":"计算机技术,大数据,人工智能","cover":"https://images.unsplash.com/photo-1492515114975-b062d1a270ae?q=80&w=2370&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&q=80&w=800","content":"<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><p><a href=\"https://github.com/Tim-Saijun/gpt-web-crawler/\">GPT-Web-Crawler</a> 是一个基于python和puppeteer的网络爬虫，可以爬取网页并从网页中提取内容（包括网页的标题，url，关键词，描述，所有文本内容，所有图片和截图）。它使用起来非常简单，只需要几行代码就可以用来爬取网页并从网页中提取内容，非常适合对网络爬取不熟悉并希望使用网络爬取从网页中提取内容的人。<br><img src=\"https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/crawler.gif\" alt=\"爬虫工作\"><br>爬虫的输出可以是一个json文件，可以很容易地转换为csv文件，导入数据库或构建一个AI代理。<br><img src=\"https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/assistant_demo.gif\" alt=\"助手演示\"></p>\n<h2 id=\"开始\"><a href=\"#开始\" class=\"headerlink\" title=\"开始\"></a>开始</h2><p>步骤1. 安装包。</p>\n<div class=\"language-bash\"><button title=\"Copy code\" class=\"copy\" onclick=\"copyCode(this)\"></button><span class=\"lang\">bash</span><pre class=\"shiki dracula\" style=\"background-color: #282A36\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #50FA7B\">pip</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #F1FA8C\">install</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #F1FA8C\">gpt-web-crawler</span></span></code></pre></div><p>步骤2. 复制config_template.py并将其重命名为config.py。然后，编辑config.py文件以配置openai api密钥和其他设置，如果你需要使用ProSpider帮助你从网页中提取内容。如果你不需要使用ai帮你从网页中提取内容，你可以保持config.py文件不变。</p>\n<p>步骤3. 运行以下代码启动一个爬虫。</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\" onclick=\"copyCode(this)\"></button><span class=\"lang\">python</span><pre class=\"shiki dracula\" style=\"background-color: #282A36\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #FF79C6\">from</span><span style=\"color: #F8F8F2\"> gpt_web_crawler </span><span style=\"color: #FF79C6\">import</span><span style=\"color: #F8F8F2\"> run_spider,NoobSpider</span></span>\n<span class=\"line\"><span style=\"color: #F8F8F2\">run_spider(NoobSpider, </span></span>\n<span class=\"line\"><span style=\"color: #F8F8F2\">           </span><span style=\"color: #FFB86C; font-style: italic\">max_page_count</span><span style=\"color: #FF79C6\">=</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #BD93F9\">10</span><span style=\"color: #F8F8F2\"> ,</span></span>\n<span class=\"line\"><span style=\"color: #F8F8F2\">           </span><span style=\"color: #FFB86C; font-style: italic\">start_urls</span><span style=\"color: #FF79C6\">=</span><span style=\"color: #E9F284\">&quot;</span><span style=\"color: #F1FA8C\">https://www.jiecang.cn/</span><span style=\"color: #E9F284\">&quot;</span><span style=\"color: #F8F8F2\">, </span></span>\n<span class=\"line\"><span style=\"color: #F8F8F2\">           </span><span style=\"color: #FFB86C; font-style: italic\">output_file</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #FF79C6\">=</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #E9F284\">&quot;</span><span style=\"color: #F1FA8C\">test_pakages.json</span><span style=\"color: #E9F284\">&quot;</span><span style=\"color: #F8F8F2\">,</span></span>\n<span class=\"line\"><span style=\"color: #F8F8F2\">           </span><span style=\"color: #FFB86C; font-style: italic\">extract_rules</span><span style=\"color: #FF79C6\">=</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #FF79C6\">r</span><span style=\"color: #FF5555\">&#39;</span><span style=\"color: #8BE9FD; font-style: italic\">.</span><span style=\"color: #FF79C6\">*\\.</span><span style=\"color: #F1FA8C\">html</span><span style=\"color: #FF5555\">&#39;</span><span style=\"color: #F8F8F2\"> )</span></span></code></pre></div><h2 id=\"爬虫\"><a href=\"#爬虫\" class=\"headerlink\" title=\"爬虫\"></a>爬虫</h2><p>在上面的代码中，使用了NoobSpider。 此包中共有四种爬虫，它们可以从网页中提取的内容有所不同。 下表显示了它们之间的差异。</p>\n<table>\n<thead>\n<tr>\n<th>爬虫类型</th>\n<th>描述</th>\n<th>返回内容</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>NoobSpider</td>\n<td>抓取基本的网页信息</td>\n<td>- title <br>- URL <br>- keywords <br>- description <br>- body ：网页的所有文本内容</td>\n</tr>\n<tr>\n<td>CatSpider</td>\n<td>抓取带有截图的网页信息</td>\n<td>- title <br>- URL <br>- keywords <br>- description <br>- body ：网页的所有文本内容 <br>- screenshot_path：截图路径</td>\n</tr>\n<tr>\n<td>ProSpider</td>\n<td>抓取基本信息的同时使用 AI 提取内容</td>\n<td>- title <br>- URL <br>- keywords <br>- description <br>- body ：网页的所有文本内容 <br>- ai_extract_content：GPT 提取的正文文本</td>\n</tr>\n<tr>\n<td>LionSpider</td>\n<td>抓取基本信息的同时提取所有图片</td>\n<td>- title <br>- URL <br>- keywords <br>- description <br>- body ：网页的所有文本内容 <br>- directory：网页上所有图片的目录</td>\n</tr>\n</tbody></table>\n<h3 id=\"Cat-Spider\"><a href=\"#Cat-Spider\" class=\"headerlink\" title=\"Cat Spider\"></a>Cat Spider</h3><p>Cat spider是一个可以对网页进行截图的爬虫。它基于Noob spider，并使用puppeteer模拟浏览器操作对整个网页进行截图并将其保存为图像。 所以当你使用Cat spider时，你需要先安装puppeteer。</p>\n<div class=\"language-bash\"><button title=\"Copy code\" class=\"copy\" onclick=\"copyCode(this)\"></button><span class=\"lang\">bash</span><pre class=\"shiki dracula\" style=\"background-color: #282A36\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #50FA7B\">npm</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #F1FA8C\">install</span><span style=\"color: #F8F8F2\"> </span><span style=\"color: #F1FA8C\">puppeteer</span></span></code></pre></div><h2 id=\"待办事项\"><a href=\"#待办事项\" class=\"headerlink\" title=\"待办事项\"></a>待办事项</h2><ul>\n<li><input disabled=\"\" type=\"checkbox\"> 支持无需配置config.py</li>\n</ul>\n","feature":true,"text":"介绍GPT-Web-Crawler 是一个基于python和puppeteer的网络爬虫，可以爬取网页并从网页中提取内容（包括网页的标题，url，关键词，描述，...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"others","slug":"others","count":3,"path":"api/categories/others.json"}],"tags":[{"name":"爬虫","slug":"爬虫","count":1,"path":"api/tags/爬虫.json"},{"name":"GPT","slug":"GPT","count":1,"path":"api/tags/GPT.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">介绍</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BC%80%E5%A7%8B\"><span class=\"toc-text\">开始</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%88%AC%E8%99%AB\"><span class=\"toc-text\">爬虫</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Cat-Spider\"><span class=\"toc-text\">Cat Spider</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BE%85%E5%8A%9E%E4%BA%8B%E9%A1%B9\"><span class=\"toc-text\">待办事项</span></a></li></ol>","author":{"name":"以太工坊","slug":"blog-author","avatar":"/img/logo.png","link":"/","description":"分享我的课程学习笔记、经验与有趣的小玩意.图片等资源无法加载时请使用代理","socials":{"github":"https://github.com/Tim-Saijun","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"telegram":{"icon":"/img/telegram.svg","link":"https://t.me/tim_run"},"Email":{"icon":"/img/mail.svg","link":"mailto:b@zair.top"},"RSS":{"icon":"/img/rss.svg","link":"/atom.xml"}}}},"mapped":true,"hidden":false,"prev_post":{"title":"网页长截图自动分割工具","uid":"7257ab73c9c7b2fb6eabab288ff4c4fc","slug":"Web-page-Screenshot-Segmentation","date":"2024-02-06T03:29:01.000Z","updated":"2024-02-22T03:52:13.945Z","comments":true,"path":"api/articles/Web-page-Screenshot-Segmentation.json","keywords":"计算机技术,大数据,人工智能","cover":"https://images.unsplash.com/photo-1601972602288-3be527b4f18a?q=80&w=2370&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&q=80&w=800","text":"背景当需要分享或分析网页内容时，长截图是一种非常实用的形式，它能够完整地展示页面。然而，处理这些长截图时，如何保持其信息的完整性和可读性，同时方便进行后续操作，...","link":"","photos":[],"count_time":{"symbolsCount":"3k","symbolsTime":"3 mins."},"categories":[{"name":"OpenCV","slug":"OpenCV","count":2,"path":"api/categories/OpenCV.json"}],"tags":[{"name":"代码工具","slug":"代码工具","count":2,"path":"api/tags/代码工具.json"},{"name":"OpenCV","slug":"OpenCV","count":1,"path":"api/tags/OpenCV.json"}],"author":{"name":"以太工坊","slug":"blog-author","avatar":"/img/logo.png","link":"/","description":"分享我的课程学习笔记、经验与有趣的小玩意.图片等资源无法加载时请使用代理","socials":{"github":"https://github.com/Tim-Saijun","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"telegram":{"icon":"/img/telegram.svg","link":"https://t.me/tim_run"},"Email":{"icon":"/img/mail.svg","link":"mailto:b@zair.top"},"RSS":{"icon":"/img/rss.svg","link":"/atom.xml"}}}},"feature":true},"next_post":{"title":"物联网与传感网复习笔记","uid":"d3e57c86c659836e054cc33b54b43217","slug":"iot-notes","date":"2023-11-30T14:11:44.000Z","updated":"2024-02-22T03:52:13.945Z","comments":true,"path":"api/articles/iot-notes.json","keywords":"计算机技术,大数据,人工智能","cover":"https://images.unsplash.com/photo-1596566430365-55867e5ccaca?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wzNjAwOTd8MHwxfHNlYXJjaHwxNXx8c2Vuc29yfGVufDB8fHx8MTcwMTM1MzU4MXww&ixlib=rb-4.0.3&q=80&w=800","text":"绪论物联网的定义 技术理解物联网是指物体的信息通过智能感应装置，经过传输网络，到达指定的信息处理中心，最终实现物与物、人与物之间的自动化信息交互与处理的智能网络...","link":"","photos":[],"count_time":{"symbolsCount":"7.4k","symbolsTime":"7 mins."},"categories":[{"name":"大数据","slug":"大数据","count":11,"path":"api/categories/大数据.json"}],"tags":[{"name":"学习笔记","slug":"学习笔记","count":17,"path":"api/tags/学习笔记.json"},{"name":"物联网","slug":"物联网","count":1,"path":"api/tags/物联网.json"},{"name":"传感网","slug":"传感网","count":1,"path":"api/tags/传感网.json"}],"author":{"name":"以太工坊","slug":"blog-author","avatar":"/img/logo.png","link":"/","description":"分享我的课程学习笔记、经验与有趣的小玩意.图片等资源无法加载时请使用代理","socials":{"github":"https://github.com/Tim-Saijun","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"telegram":{"icon":"/img/telegram.svg","link":"https://t.me/tim_run"},"Email":{"icon":"/img/mail.svg","link":"mailto:b@zair.top"},"RSS":{"icon":"/img/rss.svg","link":"/atom.xml"}}}}}}