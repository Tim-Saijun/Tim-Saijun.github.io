[{"id":"d8719e661cefd842e9603629d87bd5b8","title":"stderr和stdout：理解日志与输出","content":"标准输出（stdout）与标准错误（stderr）这两个概念虽然简单，但在日志记录、错误处理和数据流管理中扮演着核心角色。本文将探讨stdout和stderr的区别和应用，尤其是在Python环境中如何有效地使用它们。\n标准输出（stdout）与标准错误（stderr）在大多数操作系统中，标准输出和标准错误是进程的两个主要输出流。它们提供了一种机制，使得进程可以将信息和错误消息发送到终端或文件。虽然这两个流在物理上可能相同（例如，都显示在同一终端界面上），但它们在逻辑上用于不同的目的：\n\n标准输出（stdout）：通常用于输出程序的执行结果或正常的运行信息。\n标准错误（stderr）：专门用于输出错误消息或警告，即使在标准输出被重定向时，这些信息通常也需要被看到或记录。\n\nPython中的print和logging在Python中，print函数默认将信息发送到stdout，而logging模块则默认将日志消息发送到stderr。这样做的目的是区分正常的程序输出和日志（包括错误和调试信息）输出，使得开发者可以更容易地管理和过滤输出信息。\n使用printprint是Python中最基本的输出函数，用于将信息输出到标准输出流。它简单易用，适合于快速的调试或向用户显示信息。例如：\npythonprint(&quot;Hello, world!&quot;)使用logginglogging模块提供了一个灵活的框架，用于在应用程序中添加日志消息。与print不同，logging支持不同的日志级别（DEBUG, INFO, WARNING, ERROR, CRITICAL），允许开发者根据需要调整日志的详细程度和输出位置。例如：\npythonimport logging\n\nlogging.error(&#39;This is an error message&#39;)\ntqdm与stderr在复杂的或长时间运行的程序中，使用进度条是向用户展示进程进度的一种有效方式。Python的tqdm库是一个广泛使用的工具，用于在命令行中添加进度条。tqdm默认将进度信息输出到stderr，以免干扰到正常的程序输出（stdout）。\n分流stdout和stderr在某些情况下，将正常输出和错误或日志消息分开，例如，将它们重定向到不同的文件或终端。在命令行中，可以使用重定向操作符&gt;和2&gt;来实现。在Python代码中，可以通过配置logging模块或使用特定的文件对象来实现更细粒度的控制。\nbashpython script.py &gt; output.log 2&gt; error.log\n通过命令行重定向、Python的print函数甚至logging模块，都可以灵活地控制和分流这两种类型的输出，使得错误处理、日志记录和用户交互更加清晰和有序。\n使用nohup管理stdout和stderr在部署长时间运行的后台进程时，nohup命令成为了一个重要的工具。nohup，或“no hang up”，允许命令在用户注销后继续运行，这对于远程启动任务尤其有用。nohup的一个关键特性是它的能力来管理stdout和stderr。\n默认情况下，使用nohup运行命令会将stdout和stderr合并重定向到nohup.out文件，除非另外指定。这意味着无论是正常的输出还是错误消息，都会被捕获到同一个文件中，方便日后审查。但在某些情况下，将这两种输出分开可能更有用。\n分开stdout和stderr的nohup使用要在使用nohup时将stdout和stderr输出到不同的文件，可以结合使用重定向操作符。例如：\nbashnohup python script.py &gt; output.log 2&gt; error.log &amp;这条命令将stdout重定向到output.log，stderr重定向到error.log，并通过&amp;在后台运行。这样，即使关闭了终端或者SSH会话，程序也会继续运行，并且其输出会被妥善记录。\n在Python中的缓冲行为stdout和stderr在缓冲数据时表现不同。默认情况下，stdout是行缓冲的，当连接到终端时，它会缓存数据直到收到换行符或缓冲区满；在非交互模式下，stdout 是块缓冲的（像文件一样）。 而stderr总是行缓冲的（python 3.9版本之前，非交互模式下是块缓冲）。以下内容来自官方文档sys — 系统相关的形参和函数 — Python 3.12.2 文档\n\n\n\n\n\n\n\n\n\nWhen interactive, the stdout stream is line-buffered. Otherwise, it is block-buffered like regular text files. The stderr stream is line-buffered in both cases. You can make both streams unbuffered by passing the [u](&lt;https://docs.python.org/3.12/using/cmdline.html#cmdoption-u&gt;) command-line option or setting the [PYTHONUNBUFFERED](&lt;https://docs.python.org/3.12/using/cmdline.html#envvar-PYTHONUNBUFFERED&gt;) environment variable.\nChanged in version 3.9: Non-interactive stderr is now line-buffered instead of fully buffered.\n缓冲粒度越小，输出就越及时，但相应的IO代价就更大。Python 3.8及之前，将stdout 和stderr 做了相同粒度的缓冲，实在是不太合理；在3.9版本后，stderr 有了更小的缓冲粒度，意味着每个写入操作的输出会比stdout 更及时。这种差异使得stderr适合于错误和日志信息，确保即使在程序崩溃或异常退出时，这些信息也能比标准输出有更高的优先级。\n在C++中，标准错误是无缓冲的（见后文），更为激进，但我个人认为这种会更合理一些。\n但好在，Python中可以通过python -u或设置环境变量PYTHONUNBUFFERED来禁用这种缓冲行为，或是直接操作sys.stdout.flush()来控制输出时机。\n在Python并发环境中的表现在多线程或多进程环境中使用stdout和stderr时，输出可能会交错或混乱，因为来自不同线程或进程的输出可能会在写入终端或文件时相互干扰。解决这一问题的一种方法是为每个线程或进程创建独立的输出文件，或使用线程锁（thread locks）或进程同步机制（如multiprocessing.Lock）来同步对stdout或stderr的访问。\nPython控制stdout和stderr在复杂的应用中，你可能需要更灵活地控制输出流的目的地。Python提供了多种方式来实现这一点：\n\n**重定向stdout和stderr**：可以通过改变sys.stdout和sys.stderr的值来重定向Python程序的标准输出和错误输出。这对于捕获和分析输出，或将输出重定向到图形界面等非标准输出设备特别有用。\n使用subprocess模块：当运行外部命令或脚本时，subprocess模块允许你控制命令的stdout和stderr流，包括将它们重定向到Python程序内部的变量，或将它们分开或合并。\n日志模块的高级应用：Python的logging模块支持将日志输出到多个目的地，包括文件、标准输出、网络等。通过配置不同的日志处理器（handlers），你可以实现复杂的日志管理方案，如基于日志级别或消息内容将日志分流到不同的输出中。\n\n建议\n谨慎管理输出：在设计软件时，明确区分用于用户交互的输出（stdout）和用于错误报告或日志记录的输出（stderr）。这有助于提高程序的可用性和维护性。\n优化性能：考虑输出操作的性能影响，特别是在高频率日志或数据输出的场景下。合理使用缓冲和批量处理可以减少对性能的影响。\n安全性考虑：在输出敏感信息前进行适当的过滤和脱敏，避免通过日志泄露敏感数据。\n\n通过深入理解和灵活应用stdout和stderr，可以构建出更健壮、更易于管理的Python应用程序，有效地处理日志和输出，提升用户体验和应用稳定性。\n在C++中的缓冲行为在C++中，stdout（通常对应于std::cout）和stderr（对应于std::cerr）有不同的缓冲策略：\n\nstd::cout 默认是行缓冲的，这意味着当它连接到一个终端时，输出会在每次换行时刷新，或者缓冲区满时刷新。\nstd::cerr 默认是无缓冲的，因此每次写入std::cerr的数据都会立即输出，这对于报告错误信息非常有用，因为它减少了程序崩溃导致错误信息未被输出的风险。\n\n重定向stdout和stderr在C++程序中，可以通过多种方式重定向stdout和stderr。一种常见的方法是使用freopen函数在程序运行时重定向标准输出或错误输出到文件：\ncppfreopen(&quot;output.txt&quot;, &quot;w&quot;, stdout);\nfreopen(&quot;error.log&quot;, &quot;w&quot;, stderr);这种方法可以用于将输出重定向到文件，方便日后分析和调试。\nC++多线程环境中的使用在多线程的C++程序中使用std::cout和std::cerr时，可能会遇到竞争条件，导致输出混乱。为了避免这种情况，推荐使用互斥锁（如std::mutex）来同步对这些流的访问：\ncpp#include &lt;iostream&gt;\n#include &lt;mutex&gt;\n#include &lt;thread&gt;\n\nstd::mutex cout_mutex;\n\nvoid thread_function(int id) &#123;\n    std::lock_guard&lt;std::mutex&gt; lock(cout_mutex);\n    std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; is running\\\\\\\\n&quot;;\n&#125;\n\nint main() &#123;\n    std::thread t1(thread_function, 1);\n    std::thread t2(thread_function, 2);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n&#125;C++控制输出C++标准库提供了std::streambuf，可以用来实现对std::cout和std::cerr更细粒度的控制，包括重定向和自定义缓冲行为。通过继承std::streambuf并重写相应的成员函数，你可以创建自定义的缓冲策略，或将输出重定向到GUI组件、网络连接等。\n建议\n合理使用缓冲：根据应用场景选择合适的缓冲策略。对于需要立即反馈的错误信息，使用std::cerr或手动刷新std::cout。\n避免在多线程中直接使用标准输出：使用互斥锁或其他同步机制来保证输出的一致性和顺序。\n**使用重定向和自定义streambuf**：为了更灵活地处理输出，考虑使用重定向或自定义streambuf来实现特殊的输出需求，如日志记录、网络传输等。\n\n通过掌握这些进阶技术，可以在保证C++程序健壮性和灵活性的同时，有效地管理和控制程序的输出。\n","slug":"standard-output","date":"2024-02-17T12:42:32.000Z","categories_index":"算法编程","tags_index":"标准输出","author_index":"以太工坊"},{"id":"7257ab73c9c7b2fb6eabab288ff4c4fc","title":"网页长截图自动分割工具","content":"背景当需要分享或分析网页内容时，长截图是一种非常实用的形式，它能够完整地展示页面。然而，处理这些长截图时，如何保持其信息的完整性和可读性，同时方便进行后续操作，一直是一个挑战。比如目前（2024年初）市面上主流的AI图像模型，仍然不能处理很大、很复杂的图片，如果强行把一张长截图输入模型，就会导致模型输出的性能变差（很多细节无法被识别到）。为了解决这个问题，我开发了一款基于OpenCV的工具，旨在简化长截图的处理过程，同时保持其内容的完整性和可读性。\n这个项目已在我的Github开源：https://github.com/Tim-Saijun/Web-page-Screenshot-Segmentation\n与许多现有的工具或方法不同，Web-page-Screenshot-Segmentation采用了OpenCV自动地识别和遵循网页内容的自然分隔线，自动找到最合适的分割点。也就是说无论是标题、段落还是图表，都能够被整齐地保留在分割后的图片中，不会出现内容断裂或遗漏的情况。\n使用Web-page-Screenshot-Segmentation非常简单，只需准备一张长截图，工具便会自动分析图片内容，并智能决定分割点。最终将获得一系列完整且结构化良好的图片，方便进行分享和进一步处理。\n介绍该项目用于根据文本的高度将网页的长截图分割成几个部分。主要思想是找到图像的低变化区域，然后在低变化区域中找到分割线。输出的是网页的小而完整的图像，可以用于使用Screen-to-code生成网页或训练模型。更多结果可以在images目录中找到。\n开始使用安装txt pip install Web-page-Screenshot-Segmentation在命令行中使用获取图像的分割线的高度\nbashpython -m Web_page_Screenshot_Segmentation.master -f &quot;path/to/img&quot;输出应该是个列表:[6, 868, 1912, 2672, 3568, 4444, 5124, 6036, 7698]。它是图像分割线的高度列表。如果你想在图中显示这条分割线，可以加上 -s True参数：\nbashpython -m Web_page_Screenshot_Segmentation.master -f &quot;path/to/img&quot; -s True在图像中画出分割线bashpython -m Web_page_Screenshot_Segmentation.drawer --image_file path/to/image.jpg --hl [100,200] --color (0,255,0)切分图像bashpython -m Web_page_Screenshot_Segmentation.spliter --f path/to/image.jpg -ht &quot;[233,456]&quot;你将得到分割图像，保存在命令返回的路径中。\n更多用法解释请参照帮助：\nbashpython master.py --help\npython spliter.py --help从源码使用split_heights 函数split_heights 函数用于根据各种阈值将图像分割成几个部分。它接受以下参数：\n\nfile_path: 图像文件的路径。\nsplit: 一个布尔值，指示是否分割图像。\nheight_threshold: 低变化区域的高度阈值。\nvariation_threshold: 低变化区域的变化阈值。\ncolor_threshold: 颜色差异的阈值。\ncolor_variation_threshold: 颜色差异变化的阈值。\nmerge_threshold: 两条线之间最小距离的阈值。\n\n如果 split 是 False，函数返回分割线的高程列表；如果 split 是 True，则返回分割图像的路径。\n示例用法pythonimport Web_page_Screenshot_Segmentation\nfrom Web_page_Screenshot_Segmentation.master import split_heights\n\n# 在 &#39;path/to/image.jpg&#39; 分割图像为几个部分\nsplit_image_path = split_heights(\n    file_path=&#39;path/to/image.jpg&#39;,\n    split=True,\n    height_threshold=102,\n    variation_threshold=0.5,\n    color_threshold=100,\n    color_variation_threshold=15,\n    merge_threshold=350\n)\n\nprint(f&quot;分割后的图像保存在 &#123;split_image_path&#125;&quot;)在这个例子中，根据提供的阈值，’path&#x2F;to&#x2F;image.jpg’ 的图像被分割成几个部分。分割后的图像保存在函数返回的路径。\ndraw_line_from_file 函数draw_line_from_file 函数用于在指定高度的图像上绘制线条。它接受以下参数：\n\nimage_file: 图像文件的路径。\nheights: 在指定高度绘制线条的高程列表。\ncolor: 线条的颜色。默认颜色为红色 (0, 0, 255)。\n\n该函数从提供的文件路径读取图像，在指定的高度绘制线条，然后将修改后的图像保存到新文件中。新文件保存在 result 目录下，与原始文件同名，但在文件扩展名前添加了 ‘result’。\n如果函数在读取图像文件时遇到错误（例如，如果文件路径包含 ‘.’ 或中文字符），则会抛出异常。\n示例用法pythonimport Web_page_Screenshot_Segmentation\nfrom Web_page_Screenshot_Segmentation.spliter import draw_line_from_file\n\n# 在 &#39;path/to/image.jpg&#39; 的图像上，在高度 100 和 200 处绘制线条\nresult_image_path = draw_line_from_file(\n    image_file=&#39;path/to/image.jpg&#39;,\n    heights=[100, 200],\n    color=(0, 255, 0)  # 以绿色绘制线条\n)\n\nprint(f&quot;修改后的图像保存在 &#123;result_image_path&#125;&quot;)在这个例子中，’path&#x2F;to&#x2F;image.jpg’ 的图像被修改，以在高度 100 和 200 处绘制绿色线条。修改后的图像保存在函数返回的路径。\n","slug":"Web-page-Screenshot-Segmentation","date":"2024-02-06T03:29:01.000Z","categories_index":"OpenCV","tags_index":"代码工具,OpenCV","author_index":"以太工坊"},{"id":"e70118a7ef900115be6534ffca042ddb","title":"GPT网页爬虫","content":"介绍GPT-Web-Crawler 是一个基于python和puppeteer的网络爬虫，可以爬取网页并从网页中提取内容（包括网页的标题，url，关键词，描述，所有文本内容，所有图片和截图）。它使用起来非常简单，只需要几行代码就可以用来爬取网页并从网页中提取内容，非常适合对网络爬取不熟悉并希望使用网络爬取从网页中提取内容的人。爬虫的输出可以是一个json文件，可以很容易地转换为csv文件，导入数据库或构建一个AI代理。\n开始步骤1. 安装包。\nbashpip install gpt-web-crawler步骤2. 复制config_template.py并将其重命名为config.py。然后，编辑config.py文件以配置openai api密钥和其他设置，如果你需要使用ProSpider帮助你从网页中提取内容。如果你不需要使用ai帮你从网页中提取内容，你可以保持config.py文件不变。\n步骤3. 运行以下代码启动一个爬虫。\npythonfrom gpt_web_crawler import run_spider,NoobSpider\nrun_spider(NoobSpider, \n           max_page_count= 10 ,\n           start_urls=&quot;https://www.jiecang.cn/&quot;, \n           output_file = &quot;test_pakages.json&quot;,\n           extract_rules= r&#39;.*\\.html&#39; )爬虫在上面的代码中，使用了NoobSpider。 此包中共有四种爬虫，它们可以从网页中提取的内容有所不同。 下表显示了它们之间的差异。\n\n\n\n爬虫类型\n描述\n返回内容\n\n\n\nNoobSpider\n抓取基本的网页信息\n- title - URL - keywords - description - body ：网页的所有文本内容\n\n\nCatSpider\n抓取带有截图的网页信息\n- title - URL - keywords - description - body ：网页的所有文本内容 - screenshot_path：截图路径\n\n\nProSpider\n抓取基本信息的同时使用 AI 提取内容\n- title - URL - keywords - description - body ：网页的所有文本内容 - ai_extract_content：GPT 提取的正文文本\n\n\nLionSpider\n抓取基本信息的同时提取所有图片\n- title - URL - keywords - description - body ：网页的所有文本内容 - directory：网页上所有图片的目录\n\n\nCat SpiderCat spider是一个可以对网页进行截图的爬虫。它基于Noob spider，并使用puppeteer模拟浏览器操作对整个网页进行截图并将其保存为图像。 所以当你使用Cat spider时，你需要先安装puppeteer。\nbashnpm install puppeteer待办事项\n 支持无需配置config.py\n\n","slug":"GPT网页爬虫","date":"2023-12-30T13:29:01.000Z","categories_index":"others","tags_index":"爬虫,GPT","author_index":"以太工坊"},{"id":"d3e57c86c659836e054cc33b54b43217","title":"物联网与传感网复习笔记","content":"绪论物联网的定义\n技术理解物联网是指物体的信息通过智能感应装置，经过传输网络，到达指定的信息处理中心，最终实现物与物、人与物之间的自动化信息交互与处理的智能网络。\n应用理解物联网是指把世界上所有的物体都耳到一个网络中，形成物联网，然后’物联网’又与现有的“互联网“结合，实现人类社会与物理系统的整合，达到更加精细和动态的去管理生产和生活。\n通俗理解将 RFID 射频识别和 WSN 无线传感器网络结合为用户提供生产生活的监控、指挥调度、远程数据采集和测量、远程诊断等方面的服务。\n\n物联网的特征\n全面感知利用 RFID、传感器、二维码等随时随地获取物体的信息。\n可靠传递通过网络与互联网的融合，将物体的信息实时准确地传递给用户。\n智能处理利用计算、数据挖掘以及模糊识别等人工智能技术，对海量的数据和信息进行分析和处理，对物体实施智能化的控制。\n\n物联网概念模型感知（感知层）、传输（网络层）、计算（应用层）\n\n感知层：感知层识别物体、采集和捕获信息，通过 RFID 摄像头等方式实现，是物联网全面感知的基础；要求更全面更敏感的感知能力、低功耗、解决小型化和低成本问题。\n网络层：连接感知层和应用层，随时随地的连接实现，也是当前最成熟的部分；包括接入网、核心网、业务平台等三个层次；要求扩展规模实现无处不在、业务可扩展的管理运营能力以及简化结构实现上下层面融合。\n应用层：实现广泛智能化应用的解决方案集合；应用方向有智能家居、电力、交通等；要求信息技术与行业的深度融合，信息的社会化共享和安全保障，基于云计算的应用保障。\n\n传感器数据的主要特点\n海量性：假设每个传感器每分钟内仅传回数据，则 1000 个节点每天、数据量就达到了约 1.4GB\n多态性：生态监测系统（温度湿度光照）；多媒体传感网（音频视频）；火灾导航系统（结构化通讯数据）\n关联性：描述同一个实体的数据在时间上具有关联性（同一节点上温度随时间变化）；描述不同实体的数据在空间上具有关联性（同一区域内不同节点测得温度与湿度相近）；描述实体的不同维度之间也具有关联性（同一节点同一时间测得的温度与湿度相关）；\n语义性：数据被人类赋予含义，方便使用\n\n无线感知方法\n传统感知：各种传感器\n智能无线感知/无需传感器的感知：WiFi，蓝牙，ZeegBee，OWB，RFID\n群智感知：众包、百度地图\n\n无线局域网无线局域网的组成结构\n站/无线接入点（AP）：AP 是无线局域网的核心设备，它提供有线和无线的接口，用于连接工作站和网络服务器。\n无线介质\n分布式系统（DS）：DS 是连接不同 BSS 的设备，它使得工作站可以在 BSS 之间移动，实现漫游功能。\n终端\n\nIEEE 802 .11 b/g 北美标准中共有 11 个信道，其中 1、6、11 信道为不重叠的传输信道\n无线局域网的经典问题无线信息传输的特点：\n\n一个无线用户发出的电磁波会向各个方向扩散\n一定范围内的所有无线用户共享传输信道\n无线通信有覆盖范围。\n\n无线网络的经典问题\n\n\n隐藏终端问题：三个实体，AC 都以为 B 是空闲的，都向 B 发送，结果发生碰撞，RTS 和 CTS 解决（包含源地址、目的地址、通信时间）暴露终端问题：四个实体，A 向 B 发送数据，不影响 C 向 D 发送数据，但是 C 不敢；\nRTC/CTS 机制可以解决隐藏终端问题，但是不能解决暴露终端问题：\n\n在数据传输之前，先通过 RTS / CTS 握手的方式与接收节点达成对数据传输的认可，同时又可以通知发送节点和接收节点的邻居节点即将开始的传输。\n邻居节点在收到 RTS / CTS 后，在以后的一段时间内抑制自己的传输，从而避免了对即将进行的数据传输造成碰撞\n这种解决问题的方式是以增加附加控制消息为代价的\n\nRTS/CTS 不能解决暴露终端问题，是因为 RTS 帧没有高优先级，并且数据报文的存在会与 RTS/CTS 帧发生冲突，下图是一种情况。\n\nCSMA/CD 协议CSMA/CD 协议 载波监听多点接入/碰撞检测 协议内容可以概括为：先听后发、边听边发、冲突停止、延迟重发 CSMACD 协议不适用于无线局域网\nCSMACD 不适用于无线局域网的原因：\n\n无线局域网的设备不能实现 CSMA/CD 协议要求的一个站点在发送本站数据的同时不间断地检测信道（半双工）\n即使我们能够实现碰撞检测的功能，并且当我们在发送数据时检测到信道是空闲的，在接收端仍然有可能发生碰撞（隐藏终端）\n在本节点冲突并不意味着接收端也冲突（暴露终端）\n\nCSMA/CA载波监听介质忙时，则等待到当前传输完全结束。监听方法包括物理载波监听（信号强度判断）和虚拟载波监听协议（源站通知占用信道的时间）。\n\nCSMA/CA 流程图需要掌握。\n冲突避免则有两种方式：\n优先级确认协议帧间间隔 (Inter Frame Space)：所有站在完成发送后，必须再等待一段很短时间（继续监听）才能发送下一个帧。\n优先级：帧间间隔长度取决于该站欲发送帧的类型。高优先级帧需要等待的时间较短，因此可优先获得发送权。\n\n\n\n类型\n时间\n包含的帧类型\n说明\n\n\n\nSIFS 短 IFS\n最短\nACK 帧、CTS 帧、由过长的 MAC 帧分片后的数据帧，以及所有回答 AP 探询的帧\n最短、最高优先级\n\n\nPIFS 点协调功能 IFS\n+ slot\n\n由 AP 协调\n\n\nDIFS 分布式协调功能 IFS\n+ 2 slot\n在 DCF 方式中用来发送数据帧和管理帧,RTS 帧\n最长、分布式协调\n\n\n随机后退算法同一优先级也可能有争用情况。信道从忙态变为空闲时，任何一个站要发送数据帧时，不仅都必须等待一个 DIFS 的间隔，还要进入争用窗口，并计算随机退避时间以便再次重新试图接入到信道。\n当网络负载大时，竞争窗口越小，节点选的随机值越接近，导致太多的冲突；当网络负载轻时，竞争窗口越大，节点等待的时间越长，导致不必要的竞争。系统应该自适应当前想发送节点的数目。指数后退算法：竞争窗口初始化为最小值，当发生冲突时加大窗口，直至达到最大值。\nMAC 层的功能MAC 层必须实现 DCF 分布式协调（由各节点自己确定访问时间），选用 PCF 点协调功能（由 AP 协调，比如轮流）。DCF 和 PCF 都能在同一个 BSS（Basic Service Set,基本服务集合，包含一个 AP 和若干个站，多个 BSS 可以通过路由系统串联成为一个扩展的 BSS）中提供并行的竞争和无竞争的访问。\nMAC 层的主要功能：\n\n媒体访问控制\n加入网络连接\n数据验证和保密\n\n分贝与功率的转换\n\n\n\n\n\n\n\n\n\n\n国标规定路由器最大功率不超过 100mw，约合 20 分贝\nZigzag传输两次，每次随机一个 Δ 时间差，在两个时隙中传输了两个包，可以依次还原出两个数据包，等价于数据包未发生碰撞。依据两个特征：\n\n发送有冲突就必然会重传\n每次冲突的位置是不同的\n\n为了避免解析过程中出现错误而导致的多米诺效应，可以从后向解析出第二个数据包，如若两个数据包相同则采用；如果不同则说明有错误，AP 选用 PHY 置信度高的。\nzigzag 优点\n\n能使用 802．11 标准解码器，而且不需要修改它的协议\nzigzag 包括可以用于多个冲突包的情况，在无冲突的时候不会引入外的开销\nZigzag 需要改变 AP 点，不需要改变客户\n\n无线传感网无线传感网 WSN无线传感器网络系统通常包括传感器节点、汇聚节点和管理节点。是一种大规模、自组织、动态、可靠、与应用相关的网络。\n结构组成传感器节点结构组成如下，操作系统有 TinyOS（灵活可修改上手难度高）和基于 Zigbee 协议栈的 TI（反之）；\n\n传感器模块\n处理器模块\n无线通信模块\n能量供应模块\n\n\n传感网络与无线网络的区别：传感网络首要目标是节能；无线网络的设备可以移动而传感网的节点大多是不动的（但是容易故障）。\n节点的特征局限性：\n\n电源能量有限（通信模块最耗能，通信状态有发送、接收、空闲监听和睡眠等 4 种状态）\n计算和存储能力有限\n通信能力有限\n\n特点：\n\n邻近的节点具有相似的数据（可用于优化）\n传感节点没有全局 ID\n\n天线长度利用无线电通信时，需满足一个基本条件，即通常认为天线尺寸应大于波长的十分之一，信号才能有效地发射出去。实际使用过程中，应将低频波调制到高频。\n天线发射的三种信号：地波、天波（电离层反射）、直线(30MHz 以上)。\n天线的通信距离:\n\n其中  是折射常数。\n两根天线之间的传播最大距离为：\n\n\n传感网络的体系结构内爆与重叠现象\n内爆(Implosion)节点向邻居节点转发数据包，不管其是否收到过相同的，即所谓信息内爆是指网络中的节点收到一个数据的多个副本的现象。\n重叠(Overlap)感知节点感知区域有重叠，导致数据冗余，即由于无线传感器网络节点密集部署，因此在同一局部区域中，若干个节点对区域内同一个事件做出的反应相同，所感知的信息在数据性质上相似，数值上相同，那么这些节点的邻居节点所接收到的数据副本也具有较大的相关性。\n传感器网络的分类先应式网络-连续操作模式 (Continuously Operating Model)\n\n节点定期打开传感器和发送器、感测环境并将感兴趣的数据发送出去\n适用于需要定期监测数据的应用\n\n反应式网络-查询-响应模式（ Query-Response Model）\n\n节点根据用户发来的查询命令给予立即响应\n节点根据网络某些属性值发生的变化立即予以响应\n\n传感网络体系架构分类9 月 22 日\n\n层次体系缺点：离基站近的节点能量消耗快，形成能量空洞。\n分簇体系\nLEACH 协议：Low Energy Adaptive Clustering Hierarchy，簇自发形成、簇主 head 自治选举\nPEGASIS：LEACH 每个节点仅能与 head 通信，但如果有簇内节点离 head 较远，将会产生较大的代价。PEGASIS 针对这点做了优化，节点可以通过链与最近的邻居通信 PPT29/37\n\n优点：任何消息最多两跳、head 分布式选举实现了能量的均衡消耗\n直接传输 Direct Transmission所有节点直接传数据给基站，能量消耗大、基站要处理冲突\n数据分发与数据搜集上述的体系结构都是为了数据搜集，数据搜集的目标是最小化能量消耗以及最小化延迟传输数据，可用 energy*delay 作为算法性能的度量\n数据分发是传感网络中路由查询包和数据包分发的过程，最直接的方法是洪泛法 Flooding，即每一个非目标节点对收到的 TTL 非 0 的包进行广播，这种协议简单，不需要复杂的拓扑维护、路由发现算法，但是会有内部爆炸、数据重叠、资源盲目等问题。\n\n定位技术WSN 定位分类\n基于测距的定位\n信号强度 RSS\n基于时间 TOA/TDOA/RTOF\n基于角度 AOA\n\nTime Of Arrival 要求收发双方（时间）要同步；Time Difference Of Arrival 增加超声波模块，消除了双方的同步要求；Round Travel Of Flight 方法是对前两个的折中，既不要求同步，又不要求硬件，但精度不如 TDOA；\n\n\n\n\n\n\n\n\n\n\n基于测距的测量物理量，成本高，精度高考察形式：给场景、数据、问题，写出方案，算出距离和坐标\n无需测距的定位技术又叫距离无关，不需要测量物理量\n锚点：自身位置已知\n跳段距离：平均一跳多少距离\n质心算法信标节点周期性向邻近节点广播信标分组，信标分组中包含信标节点的标识号和位置信息；当未知节点接收到来自不同信标节点的信标分且数量超过某一个门限 k 或接收一定时间后，就确定自身位置为这些信标节点所组成的多边形的质心。\n\nDV-HOP 算法10 月 11 日\n未知位置的节点，依赖已知位置的节点，自行计算自身的位置\n算法要求确定最小跳数和每跳平均距离\n为什么是最小跳数？因为这样可以减少累计误差、距离最接近直线。\n平均距离怎么确定？根据已知位置的节点估计。PPT19/73 三种方法：只采用最近的节点（首先收到的、不合理）、平均、加权\n最小跳数怎么确定？PPT16/73\n适用于锚点多、分布均匀的网络\n考察平均跳段距离计算\nAPIT10 月 13 日\n节点与邻居通信，模拟运动的过程，再根据 PIT 准则近似确定自己是在三角形的内外 PPT8-9 ，多次重复此过程，确定多个三角形重叠的区域，取质心作为位置 PPT12\n缺点：会有判断错误的情况；节点数量过少时（≤3)无法定位；对节点的覆盖率与分布有要求；基于信号测距只能适用于空旷的野外；距离和信号强度也不是完全对应。\n定位相关的其他技术序列定位节点对锚点信号的接收序列进行排序，通过多个中垂线确定公共区域。\n另一种方法是确定邻居序列并进行排序、计算相似度（特征距离）、最后修正两个节点之间的特征距离，如果两个节点的相似度很大，则位置很近（逻辑距离、特征距离）。\n在这种方法里，每个节点的邻居数量是不同的，如何计算相似度（维度不同的条件下）？用节点对的次序作为度量标准，计算相似度，可以有显式 explicit  、隐式 implicit 、疑似 possible 不同等三种情况。\n\n，\n\n特征距离的计算例题\nRSD 方法优点：\n\n精度提高\n能达到每一跳的精度\n高效：没有洪泛，两个节点交换序列\n计算复杂度低\n可以集中式或者分布式\n\nRSD 的不足之处依旧在信号强度和距离并不是完全对应的\n传感网的时间同步机制2023 年 10 月 20 日\n时间同步的作用：定位、数据融合、休眠唤醒（节能！环保！）\n影响时间同步的传输时延：PPT5/117 发送，访问（最不确定 PPT23/117），传送，传播，接受，接收\n\n发送时间：发送方组装并将报文交付 MAC 层的时间\n访问时间：发送方 MAC 层从获得报文后到获取无线信道发送权的时间。最不确定因素，取决于网络负载\n传送时间：发送方传送报文的时间\n传播时间：报文从发送方传送到接收方的时间\n接收时间：接收方接收报文的时间\n接受时间：接收方处理接收到的报文的时间\n\nNTP\n这里的同步只需要计算出时间差即可，列方程解得\n\n从此式可以看出，时间差与服务器或者客户端的处理耗时无关\n计算机网络使用的协议，不适用于传感网的原因：\n\n传感网链路受环境影响而中断的概率大\n传感网的网络结构（拓扑结构）不稳定\nNTP 服务器无法通过网络自身实现\nNTP 信息交换频繁，能量消耗大\n\nRBS 类Reference Broadcast Synchronization，多个节点接收同一个同步信号，然后多个收到同步信号的节点之间进行同步（多次，使用最小二乘法减少误差）。该算法消除了同步信号发送一方的时间不确定性。\n\n原理：参考报文不需携带发送节点的本地时间，RBS 协议会广播时间同步消息，求彼此消息到达的时间差平均值，从而尽量消除非同时记录的影响\n优点：时间同步与 MAC 层协议分离，不再受限，互操作性好\n缺点：协议开销大\n发送者无需写入时间。\n为了减少时间传播的误差，可以采用统计技术，同时广播多个时间的同步消息，求相互之间消息到达时间差的平均值。\nTPSN采用层次结构，所有节点按照层次结构进行逻辑分级，每个节点与上一级的一个节点进行同步（NTP）。\n原理/思想：\n\n采用层次结构实现同步\n节点按照层次结构进行逻辑分级，表示到根结点的距离\n基于发送者-接受者的节点对方式，每个节点都与上一级节点同步\n\n根结点：与外界通信并获取时间，是整个网络系统的时钟源\n过程：\n\n生成层次：根节点为 0 级，i 级节点至少可以与一个 i-1 级节点通信\n时间同步：1 级节点同步到根结点，i 级节点同步到 i-1 级节点\n\n问题：存在同步误差的积累；整个网络同步时间长；两层相邻节点同步时可能碰撞\n问题：误差积累，竞争问题（随机等待解决），整个网络同步时间非常长\n优化：在 MAC 层消息开始发送时才给消息加上时间标记，以消除访问误差\n工业互联网什么是工业互联网\n什么是数字孪生，五维模型\n工业互联网与传统的消费互联网PPT 36/117 工业互联网是在互联网的基础之上，面向实体经济的演进与升级。\n\n工业互联网与 4.0 的关系工业 4.0 诞生在德国，侧重点更在于生产与制造过程的智能化、数字化。\n工业互联网源于美国，更偏重借助互联网技术改善生产设备和产品服务。\n数字孪生五维模型\n物理实体：各个子系统和传感器\n虚拟实体：对物理设备的映射\n服务：优化物理设备，矫正虚拟设备\n网络连接：使物理设备、虚拟设备、服务在运行中保持交互\n孪生数据：物理设备、虚拟设备、服务运行的驱动\n\n中国制造 2025 具体内容从意义上讲，中国制造 2025 比之于工业 4.0 和工业互联网，目标更明确，内涵更确切，路线更清晰。\n主题：促进制造业创新发展\n中心：提质增效\n主线：加快新一代信息技术与制造业深度融合\n主攻方向：推进智能制造\n目标：满足经济社会发展和国防建设对重大技术设备的需求\n终极问题物联网、大数据、云计算及人工智能，彼此之间是什么关系?\n\n物联网设备产生大量数据，作为大数据来源的一部分\n云计算为大数据处理和分析提供大规模的计算和存储资源\n大数据和云计算分别为人工智能的学习提供充足的训练样本和计算资源\n物联网为人工智能提供了更广阔的应用场景，如智能家居、智能交通等\n综上所述，物联网、大数据、云计算和人工智能之间互为支撑\n\n20级真题（部分）简答题从复习提纲中随便抽几个\n分析题\n为什么CSMA/CD协议不适用于无线局域网？\n定位技术的两大分类并分别列举一些算法。\n分析比较TPSN和RBS。\n\n综合题\n给一个八个节点的网络拓扑图，第一问要求写出其中五个节点的邻居节点序列；第二问要求算其中两个节点的RSD。\n对一张类似于下图中的红框进行完形填空，要求写出英文缩写并进行解释。\n\n\n","slug":"iot-notes","date":"2023-11-30T14:11:44.000Z","categories_index":"大数据","tags_index":"学习笔记,物联网,传感网","author_index":"以太工坊"},{"id":"1bb59b525f70790803a1bd9347a0f0e5","title":"魔改Hexo-Aurora主题","content":"前言Aurora主题是由@三钻开发的Hexo主题。主题大气美观，但作为面向大众的设计，仍有一些小众的需求未能被满足。因此我就按照自己的需求进行了魔改，也就是Aurora-s。需要注意的是：\n\n在我修改的内容里，有一部分修改的一些提示文字无法被自定义，比如加载动画下方的提示文字\n修改版本的Aurora-s基于AuroraV2.5.2，会尽力跟进原版更新内容，但不能保证完全采纳Aurora在美观性上几乎是无可挑剔的，但在功能性上仍有欠缺，比如阅读体验上。上图是在笔记本的小屏幕上截取的原版页面，可以看到组件间的间距非常大，内容展示密度很低，在小屏幕上的需要不断滑动，阅读体验非常差（在大屏幕上倒不是很明显）。因此魔改版本最主要的目的是提高展示密度，优化阅读体验。\n\n魔改内容加载动画由于主题生成的js与css是会变化的，无法托管于第三方，而且js文件还不小，加上我部署在国外，网络糟糕时会有不短的首次加载时间（期待三钻优化）。如果加载半天还是一片空白，会被误以为网站挂了。因此加了加载动画，当页面大致框架加载出来时，这个动画就会消失。动画是纯代码实现的，开销非常小。\ncss.loader &#123;\n    width:200px;\n    height:22px;\n    border-radius:20px;\n    color:#514b82;\n    border:2px solid;\n    position:absolute;\n    top:50%;\n    left:50%;\n    transform:translate(-50%,-50%)\n&#125;\n.loader::before &#123;\n    content:&quot;&quot;;\n    position:absolute;\n    margin:2px;\n    inset:0 100% 0 0;\n    border-radius:inherit;\n    background:currentColor;\n    animation:l6 2s infinite\n&#125;\n@keyframes l6 &#123;\n    100% &#123;\n    inset:0\n&#125;\n&#125;放置于body的js脚本，当加载完成时让动画消失:\njswindow.addEventListener(&#39;load&#39;, function() &#123;\n          var loader = document.querySelector(&#39;.loader&#39;);\n          loader.remove();\n      &#125;);更小的间距1-6级标题、引用块等样式之间的间距更小\n一级二级标题居中\n将一级二级标题居中，使视觉效果更匀称\n二级标题下方的色条更细，以作区分\n1-6级标题字号均降了一级\n\n图片缩放原版图片默认与屏幕等宽，现调整为72%宽度居中，防止小图片占大空间\n代码复制功能在代码块的右上角，通过js实现代码复制。作者说后续版本也会实现，期待。\n菜单栏收窄将阅读时的菜单栏收到最窄，以提高阅读面积\n页脚修改\n去除页脚上面的色条\n调换了页脚左侧列表的文字顺序，按长度升序\n添加pv与uv的提示文字\n去除页脚右侧的头像\n\n使用方法用过Aurora如果需要使用修改后的主题，您仍然可以保留现有配置，只需按照以下步骤操作：打开hexo根目录并执行：\nbashnpm uninstall hexo-plugin-aurora\nnpm install hexo-theme-aurora-s\nnpm install hexo-plugin-aurora\n在_config.yml中，将theme由aurora变为aurora-s\n将hexo根目录下的_config.aurora.yml拷贝一份并重命名为_config.aurora-s.yml然后继续像往常一样使用即可。\n\n没用过Aurora按照以下步骤操作：打开hexo根目录并执行：\nbashnpm install hexo-theme-aurora-s\nnpm install hexo-plugin-aurora\n在_config.yml中，将theme由aurora变为aurora-s\n在hexo根目录下，下载配置文件模板，并重命名为_config.aurora-s.yml\n按照原版配置指南进行配置即可使用\n\n","slug":"hexo-theme-aurora-s","date":"2023-11-03T08:32:10.000Z","categories_index":"博客","tags_index":"博客,前端,Hexo","author_index":"以太工坊"},{"id":"cdcb5c6b90ae779df8934cdee5c82576","title":"GithubWebhook解析服务","content":"WebhookWebhook是一种基于HTTP的回调函数，可在两个应用编程接口（API）之间实现轻量级的事件驱动通信。客户端向服务器API提供唯一URL，并指定它想要知道的事件。设置webhook后，客户端不再需要轮询服务器；发生指定的事件时，服务器会自动将相关的有效负载发送到客户端的Webhook URL。\nWebhook可以是实现自动化的重要一环，而且实现简单（仅一次http请求，可以嵌到任何地方)，国内飞书、钉钉和企业微信等都支持Webhook推送消息。\n以上是好处，那么坏处就是http请求的参数不统一，就是因为它太简单了，没有协议规范，一个平台一个样，比如在某平台上消息叫做”msg”,在其它平台可能就是”message”或”text”。因而想要真正发挥Webhook的作用，需要搭建一个自己的Webhook解析处理服务，好在这并不复杂。本文将以Github Webhook为例，基于Flask进行解析并推送到企业微信。\n然而，如果您没有高度自定义的需求，且仅想使用Github Webhook而不使用其它平台的，可以使用Dingling,它可以将GIthub Webhook转发到企业微信。DIngling只支能推送Markdown格式的消息（不能在微信中直接查看）是我放弃它的原因。\nCloudFlare WebhookCloudFlare Webhook 的消息体非常简单，如下：\njson&#123;&quot;text&quot;:&quot;CloudFlare简直是业界良心！&quot;&#125;使用Flask解析，并将消息转发到企业微信：\npythonfrom flask import Flask, request, jsonify,abort\nimport requests\nfrom config import config\napp = Flask(__name__)\n\n@app.route(&#39;/cloudflare&#39;, methods=[&#39;POST&#39;])\ndef cloudflare():\n  if request.method == &#39;POST&#39;:\n    print(request.json)\n    text = request.json[&#39;text&#39;]\n    data = &#123;\n        &quot;msgtype&quot;: &quot;text&quot;,\n        &quot;text&quot;: &#123;\n            &quot;content&quot;: text\n        &#125;\n        &#125;\n    r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_3&#39;], json=data)\n    print(r.json())\n    return &#39;success&#39;, 200\n  else:\n    abort(400)\n \nif __name__ == &#39;__main__&#39;:\n    app.run(port=5700,host=&#39;0.0.0.0&#39;,debug=True)将Flask进程部署到服务器上，并在Cloudflare上填写地址，如下图\n\n保存并测试之后，应该就能在企业微信中收到一条简短的测试消息了。\nGithub Webhook如果说CloudFlare的Webhook是一条简短的消息，那么Github恨不得把整个网站的信息全都传给你，参数有几十个，但是没有一句是自然语言，因而需要根据自己的需求解析。下段代码的逻辑是先判断事件类型，再根据事件类型提取需要的信息转发出去。下面解析的内容包括push,release,issue,pull等行为。\npython@app.route(&#39;/github&#39;, methods=[&#39;POST&#39;])\ndef github():\n    githubEvent = request.headers[&#39;x-github-event&#39;]\n    if githubEvent == &#39;push&#39;:\n        respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n        branch = request.json[&#39;ref&#39;].split(&#39;/&#39;)[-1]\n        commits = request.json[&#39;commits&#39;]\n        for commit in commits:\n            author = commit[&#39;author&#39;][&#39;name&#39;]\n            message = commit[&#39;message&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了代码\\n分支：&#123;branch&#125;\\n作者：&#123;author&#125;\\n提交信息：&#123;message&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;issues&#39;:\n        action = request.json[&#39;action&#39;]\n        if action == &#39;opened&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            issue = request.json[&#39;issue&#39;]\n            title = issue[&#39;title&#39;]\n            body = issue[&#39;body&#39;]\n            user = issue[&#39;user&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了 issue\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        if action == &#39;closed&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            issue = request.json[&#39;issue&#39;]\n            title = issue[&#39;title&#39;]\n            body = issue[&#39;body&#39;]\n            user = issue[&#39;user&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人关闭了 issue\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        if action == &#39;reopened&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            issue = request.json[&#39;issue&#39;]\n            title = issue[&#39;title&#39;]\n            body = issue[&#39;body&#39;]\n            user = issue[&#39;user&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人重新打开了 issue\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;pull_request&#39;:\n        action = request.json[&#39;action&#39;]\n        if action == &#39;opened&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            pull_request = request.json[&#39;pull_request&#39;]\n            title = pull_request[&#39;title&#39;]\n            body = pull_request[&#39;body&#39;]\n            user = pull_request[&#39;user&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了 pull request\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        if action == &#39;closed&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            pull_request = request.json[&#39;pull_request&#39;]\n            title = pull_request[&#39;title&#39;]\n            body = pull_request[&#39;body&#39;]\n            user = pull_request[&#39;user&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人关闭了 pull request\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        if action == &#39;reopened&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            pull_request = request.json[&#39;pull_request&#39;]\n            title = pull_request[&#39;title&#39;]\n            body = pull_request[&#39;body&#39;]\n            user = pull_request[&#39;user&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人重新打开了 pull request\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;release&#39;:\n        action = request.json[&#39;action&#39;]\n        if action == &#39;published&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            release = request.json[&#39;release&#39;]\n            tag_name = release[&#39;tag_name&#39;]\n            body = release[&#39;body&#39;]\n            user = release[&#39;author&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人发布了 release\\n版本：&#123;tag_name&#125;\\n内容：&#123;body&#125;\\n发布者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;ping&#39;:\n        data = &#123;\n            &quot;msgtype&quot;: &quot;text&quot;,\n            &quot;text&quot;: &#123;\n                &quot;content&quot;: &quot;github webhook test&quot;\n            &#125;\n        &#125;\n        r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;], json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;create&#39;:\n        ref_type = request.json[&#39;ref_type&#39;]\n        if ref_type == &#39;branch&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            branch = request.json[&#39;ref&#39;]\n            user = request.json[&#39;sender&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人创建了分支\\n分支：&#123;branch&#125;\\n创建者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                              json=data)\n        if ref_type == &#39;tag&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            tag = request.json[&#39;ref&#39;]\n            user = request.json[&#39;sender&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人创建了 tag\\ntag：&#123;tag&#125;\\n创建者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                              json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;delete&#39;:\n        ref_type = request.json[&#39;ref_type&#39;]\n        if ref_type == &#39;branch&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            branch = request.json[&#39;ref&#39;]\n            user = request.json[&#39;sender&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人删除了分支\\n分支：&#123;branch&#125;\\n删除者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                              json=data)\n        if ref_type == &#39;tag&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            tag = request.json[&#39;ref&#39;]\n            user = request.json[&#39;sender&#39;][&#39;login&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人删除了 tag\\ntag：&#123;tag&#125;\\n删除者：&#123;user&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(&#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                              json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;pull_request_review&#39;:\n        action = request.json[&#39;action&#39;]\n        if action == &#39;submitted&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            pull_request = request.json[&#39;pull_request&#39;]\n            title = pull_request[&#39;title&#39;]\n            body = pull_request[&#39;body&#39;]\n            user = pull_request[&#39;user&#39;][&#39;login&#39;]\n            review = request.json[&#39;review&#39;]\n            state = review[&#39;state&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了 pull request review\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;\\n状态：&#123;state&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(\n                &#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                json=data)\n        return &#39;success&#39;, 200\n    if githubEvent == &#39;pull_request_review_comment&#39;:\n        action = request.json[&#39;action&#39;]\n        if action == &#39;created&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            pull_request = request.json[&#39;pull_request&#39;]\n            title = pull_request[&#39;title&#39;]\n            body = pull_request[&#39;body&#39;]\n            user = pull_request[&#39;user&#39;][&#39;login&#39;]\n            comment = request.json[&#39;comment&#39;]\n            comment_body = comment[&#39;body&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了 pull request review comment\\n标题：&#123;title&#125;\\n内容：&#123;body&#125;\\n提交者：&#123;user&#125;\\n内容：&#123;comment_body&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(\n                &#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                json=data)\n        return &#39;success&#39;, 200\n    # if githubEvent == &#39;check_run&#39;:\n    #     action = request.json[&#39;action&#39;]\n    #     if action == &#39;created&#39;:\n    #         respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n    #         check_run = request.json[&#39;check_run&#39;]\n    #         name = check_run[&#39;name&#39;]\n    #         conclusion = check_run[&#39;conclusion&#39;]\n    #         data = &#123;\n    #             &quot;msgtype&quot;: &quot;text&quot;,\n    #             &quot;text&quot;: &#123;\n    #                 &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了 check run\\n名称：&#123;name&#125;\\n状态：&#123;conclusion&#125;&quot;\n    #             &#125;\n    #         &#125;\n    #         r = requests.post(\n    #             &#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n    #             json=data)\n    #     return &#39;success&#39;, 200\n    if githubEvent == &#39;check_suite&#39;:\n        action = request.json[&#39;action&#39;]\n        if action == &#39;completed&#39;:\n            respority = request.json[&#39;repository&#39;][&#39;name&#39;]\n            check_suite = request.json[&#39;check_suite&#39;]\n            conclusion = check_suite[&#39;conclusion&#39;]\n            data = &#123;\n                &quot;msgtype&quot;: &quot;text&quot;,\n                &quot;text&quot;: &#123;\n                    &quot;content&quot;: f&quot;&#123;respority&#125; 有人提交了 check suite\\n状态：&#123;conclusion&#125;&quot;\n                &#125;\n            &#125;\n            r = requests.post(\n                &#39;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&#39;+config[&#39;API_KEY_2&#39;],\n                json=data)\n        return &#39;success&#39;, 200配置好服务端和Github，可在历史记录中查看详细的推送信息。\n\n参考文档Github官方文档\n","slug":"githubWebhook","date":"2023-10-26T15:18:13.000Z","categories_index":"技术帖子","tags_index":"Github,Webhook","author_index":"以太工坊"},{"id":"012ca7b0d77460ec19ed77e3ecba6065","title":"保研文书模板","content":"\n\n\n\n\n\n\n\n\n声明：本文非原创，原地址是github上yuezih的King-of-Pigeon仓库，但目前作者已经删除了该仓库。\n\n\n  \n    \n      King of Pigeon：计算机保研文书实用模板\n  \n\n---\n### What's New\n\n\n 2022/10/27 Overhauled and removed some useless content. \n 2022/04/08 Added Resume (or CV) template and Festival Wishes templates. \n 2022/03/15 Some updates to meet 100 stars! \n 2022/03/14 We published a Python package with the Python Package Index, try pip install pigeonking &amp;&amp; pigeonking! \n 2022/03/14 Reimplemented the code with Github Copilot. \n 2021/11/07 Added How to Breakup Without Just Cause template. \n 2021/09/17 Added Recommendation Letter Request and Recommendation Letter templates. \n 2021/09/16 Added Self-recommendation Letter template and Offer Confirmation template. \n 2021/09/14 Published Pigeoning and Licking Back template. We hope these templates will help you get up the courage to explain to the mentor as soon as possible.\n\n简历本仓库提供了一份简历模板【点击下载】，以及一些制作简历时的建议，希望对你有所帮助。\n1. 概览  \n\n 该模板由PPT制作，修改后可导出为PDF。背景是一张与页面等大的白色图片，便于全选-另存为图片-以图片形式分享。  \n 照片不建议使用红底&#x2F;蓝底（个人感觉不太好看），可以用Office自带的抠图工具（双击图像激活选项卡中的图片格式，菜单栏最左侧“删除背景”）将人像抠出来，放到一个浅色或者渐变灰的背景上。  \n 字号、不同板块的间距等可以根据内容的丰富程度随机应变，如果内容比较少，就把字号调大一些，板块间距拉开一些。\n\n2. 扬长避短  \n\n 科研、竞赛、项目等板块自由度比较高，如果某一方面薄弱，可以用较长篇幅强调一下其它方面，占一下位置。比如模板简历中，张忝苟没有竞赛，那么就把科研经历和项目经历展开叙述，直接不写竞赛。\n 分清主次，各板块之间的比重要有区分，学生工作、社会实践的篇幅要小于科研经历等重要部分，简历要力求呈现老师希望你具备的能力。\n\n3. 宁缺毋滥，点到为止  \n\n 自己有一些含金量不那么高的东西时，不宜把所有东西都写上去，可以利用等来收纳这些内容。比如张忝苟除了国奖，剩下的都是一些水奖，那就只用一行来概括荣誉奖项，在后面加一个体育/文艺类奖项若干 等，既可以缓解张忝苟没什么奖的尴尬，又能给老师一种这个等字里面还有很多水奖的错觉，还能通过这种高冷和不屑的态度体现张忝苟独具一格的不俗品味。\n 这个等字需要把控好程度，但凡有一点含金量都是可以写上去的，然后配合简历排版（字号、间距等），内容刚好铺满整个页面时，老师就会觉得你简历里那个等是因为简历放不下了才没写上去的，而不是因为太水了。同时，要注意水奖守门员的选取，也就是列出来的最后一个奖项，你省略的肯定比这个更水，守门员不能太拉垮。\n 有的同学知道自己奖项不多，为了让它看起来多一点，喜欢每个奖占一行，排成一个列表。这样其实并不好，老师就会知道你所有的奖都在这里了，一个多的都没有。个人建议还是采取轻描淡写策略，然后在其它板块多下点功夫。（除非实在写不满一页了）\n\n4. 语言的艺术  \n\n 简历用语要精炼，避免口水话。除此之外要注意修饰，不想多说，举几个例子吧~\n 大创负责人可以说作为负责人主持大创项目一项，带领团队……或者独立主持大创项目……\n 大创高开低走可以扬长避短：中期审查优秀（29/112），已顺利结题\n 申请专利“xxx”改成以发明人身份提交专利“xxx”,目前正在受理中\n 大创实在没成果可以说目前已取得阶段性成果\n “小小早餐”调研队队长改成校园餐饮服务调研队队长\n 还有一些其它的细节，比如 rk1 就不用再说百分比了。\n\n推荐信1. 推荐信请求亲爱的朱老师，我是您上学期《编译原理》课上的学生张忝苟，最近打算报名参加中科大计算机学院的保研考核，对方学院有推荐信要求，请问老师是否愿意帮我署名一份推荐信呢？如果可以的话，我写一份初稿，随附简历发送给您，待内容确认之后，我打印好去找您签字。（或有其它安排，依老师吩咐）如果老师比较忙不方便，还请老师告知，我就不打扰老师了。谢谢老师！  \n2. 报喜答谢朱老师，您好！在您的有力推荐下，我已顺利通过中科大计算机学院夏令营考核、拿到心仪导师的直博offer，并确定为最终去向。非常感谢老师在我保研过程中对我的支持和帮助，同时也感谢您在编译原理课程中的辛勤付出和对我们的悉心教导。我会继续努力，不辜负老师的教育和期待。衷心祝愿老师工作顺利、生活愉快！  \n3.1 推荐信模板：任课老师版尊敬的中科大计算机学院领导，您好！我是电子科技大学计算机学院的朱朝阳，是张忝苟 《编译原理》课程的授课老师。很高兴作为推荐人向贵单位推荐忝苟攻读博士学位。忝苟是大三转专业过来的，此前我并不认识他，但这个每次上课坐在第一排正对着讲台的男孩给了我很深的印象。在我眼里，他是那种专注踏实、喜欢独立思考的“内敛型学霸”，没问过我问题，也几乎从来不在课堂上回答问题，然后一声不吭地在我的期中考试中拿了满分。对于《编译原理》这样一门高难度的专业课，这样令人满意的表现离不开他的认真踏实、聪明细心。在课堂之外，我观察到他积极参加学院老师的讲座，了解学科发展的前沿，拓展视野，也帮助自己更好地选择未来的研究方向，是一个有想法、有规划的学生。作为一名从教十年的老师，我认为忝苟在课程学习中所体现出的诸多特质对于他将来的学习和研究大有裨益，也展现了他的科研潜力。我了解到他过去在材料学院的导师指导下已经有了不错的科研成果，虽然这些跟他未来的研究方向可能完全无关，但这无疑说明他已经有了一定的科研基础，也具备一定的科研能力。因此，我非常相信他可以胜任直博生的科研工作，自律踏实，有想法、有能力，在贵单位的栽培下，一定可以取得出色的成就。真诚地希望贵单位考虑一下这位优秀的候选人，也期待忝苟能在贵单位找到自己的“伯乐”！预祝研招工作顺利！  \n3.2 推荐信模板：科研导师版尊敬的贵学院评审委员，您好！我是电子科技大学材料学院教授刘华强，是张忝苟本科期间的科研导师。我了解到他准备申请贵院的博士研究生，特向您予以推荐！张忝苟成绩优异，数理基础非常扎实，通过学院拔尖人才培养计划加入了我的课题组，至今已有一年半时间。他是一个非常踏实的学生，初入科研后很快便能静下心来阅读、整理文献，在跨校区一个小时车程的阻碍下，也从来没有缺席过一次组会。在科研中，他有很强的求知欲和主观能动性，除了广泛阅读文献，还会自己从学校图书馆借阅专业书籍填补自己理论基础的空缺，这对于课业相对繁重的本科生来讲是非常难得的。他还有明确的目标和清晰的规划，独自承担了一项大创，没有与同学组队，就是为了通过自己一个人从始至终的参与得到一个完整的科研训练。这些都是他作为一个科研新人所体现出来的优秀素养，让我看到了他的科研潜质。而在这一年半的科研经历中，我也见证了他的不断成长：从初入课题组的胆怯内敛，到自信流利的组会报告；从旁观者、参与者、共同作者，到独自完成自己的一作论文……尽管受到疫情的严重影响，有长达七个月的时间无法进行实验，而他转入新专业后，又需要补修整整一年的课，但他还是顶住了层层压力，凭借自己的自律和坚持，取得了非常不错的成果。我认为，他所表现出的种种好的习惯、态度和品质，一定可以帮助他在未来的研究中取得优异的成绩；另一方面，通过近两年的科研训练，他已经历了从理论学习、实验设计到数据分析、论文撰写这样一个完整的训练，具备了不错的科研基础。因此，我相信他是一位可塑之才，即使切换到一个全新的科研方向，他也能够快速入门、学有所成。衷心希望贵院给予张忝苟继续深造的机会，让他在祖国的计算机领域发光发热！  \n套磁亲爱的张兰老师，您好！见字如面。我是电子科技大学计算机科学与技术专业的18级本科生张忝苟，希望能保送到您的课题组攻读硕士研究生。我乐观善良、自律勤奋，数理基础扎实，有良好的项目基础和科研经历。我原本是化学专业的学生，第四学期转专业到计算机，大三学年在一年时间补修两年课程的压力下，仍以94.63的均分和众多奖项专业排名1/713，综测排名1/713，并潜心科研，在刘华强教授的指导下以第一作者或共同作者身份完成论文4篇，其中一篇 CVPR 已发表（一作），两篇 ACM MM 在审（分别为一作和三作），一篇 PNAS（学生一作）拟投稿。此外，我有丰富的算法实习经历（字节、商汤）和扎实的英语功底（IELTS 7.5 等），具备研究工作中所需的基本技能。我认为我在本科期间已经经历了一个较为完整的科研训练，有能力胜任研究生的科研任务。最重要的是，我踏实专注，能吃苦、有韧劲，有信心在未来的科研道路中取得优异的成果。中科大计算机学院作为我国计算技术领域首屈一指的学院，不但有强大的科研实力和纯粹的科研环境，更有像您一样通才硕学、春风化雨的优秀导师，让我无比向往。我对数据安全的跨领域应用很感兴趣，而数据共享交易又是当下亟待突破的重要方向之一，因此，我非常渴望能进入您的课题组读研，在相关领域的研究中尽己所能、有所贡献。为此，我已报名计算机学院夏令营，并将您作为我填报的意向导师，希望借助科大夏令营让我有机会成为您的学生。但在此之前，我想通过这封邮件请问老师是否有兴趣给我这个机会，如果可能的话，期待与您的进一步联系！非常感谢老师读到这里，我在附件中放了我的简历，如果老师有兴趣，欢迎下载查阅。敬颂钧安。  \n张忝苟电子科技大学 计算机科学与工程学院E-mail: &#116;&#105;&#97;&#110;&#x67;&#x6f;&#x75;&#64;&#115;&#x74;&#x64;&#46;&#117;&#101;&#x73;&#x74;&#x63;&#x2e;&#101;&#x64;&#117;&#46;&#99;&#110;Tel&#x2F;Wechat: 199-2021-0916  \n确认offer张老师您好，我是张忝苟，我确定来您这边读博，不会再有变数。非常感谢老师对我的认可，如果您有其它事宜嘱咐，请您随时联系我。很抱歉这么晚回复，希望没有打扰到您。谢谢老师！  \n鸽张老师您好，我怀着万分愧疚的心情告诉您，我打算放弃您的博士名额了，请先允许我向您诚挚地道歉。此前我已拿到南京大学的推荐资格，但老师告诉我没有学硕名额了，而后又很惊喜、很幸运地收到了您的邀请。彼时彼刻，我几乎完全不需要纠结，所以很快给了您一个确切答复。本以为不会再有变数，但南大老师突然通知有学硕名额候补到我，实在没想到会有这么一出，这突如其来的消息让我坐立难安。说实话，我不知道自己能不能在科研这条路上一直走下去，而作为寒门独子，读博的风险需要我的家人和我一起承担。于理而言，硕士对我来说无疑是更合适的选择；但于情而言，我又已向您给出承诺，一言既出，驷马难追。经过漫长的心理斗争，我最终还是决定，用我这一次的背信弃义，换取一条在未来很长一段时间更适合我的道路。从另一方面来讲，如果我不能直面直博的风险，同时又心系就业，这种分心或许也会严重影响我读博期间的科研工作，既不利于自己的成果产出，更辜负您的悉心栽培，所以我可能本来就不是一个合格的候选人，也衷心希望老师能招到更合适的学生。给您这样的消息，我感到非常难受、煎熬，但我相信您此刻的心情一定比我更糟糕。我知道我的行为给您和学院的招生工作带来了很大的麻烦，更伤害了您的感情，我为我的所作所为再次真诚道歉，也恳请老师谅解。最后，祝老师科研顺利，生活顺心，阖家幸福，万事胜意！  \n回舔张老师您好，很抱歉又来打扰您，没想到这样戏剧性的一幕居然会发生在我身上：我误解了南大老师的意思，以为自己得到了学硕offer，但今天才得知学硕名额无法保证（老师的语言极具迷惑性，我身边几位同学也跟我有同样的遭遇）。前几天，我接到南大老师的“口头offer”，并最终决定选择南大时，由于害怕耽误您招生，给您造成更大的伤害，我第一时间向您传达了放弃直博名额的决定，对此，我至今仍心存歉意。但如今，南大老师的飘忽不定，让我对这所学校丧失信心。尽管仍有机会录取为学硕，但我已决定不再考虑，而是下定决心重返科大，潜心科研。然而，面对您的邀请，短短几天之内，我先是明确地肯定，又是不舍地放弃，反复无常的态度，不但给您带来了很多麻烦，更伤害了您的感情。如今，我已无颜再面对您，更不敢奢求您重新给我一次机会。而且，以老师享誉学界的通才硕学，相信老师也已经有了更优秀的人选。但今天冒昧打扰您，是想跟您说，如果老师您依然留有宝贵的名额，并且愿意给我机会，我将无比乐意地接受并给出绝对可靠的承诺，并即刻加入课题组，惜时如金，开启科研生活。出生二十年，从来没有整过这么大的幺蛾子，不知我的行为在您看来是可笑还是可气，反正我已对自己彻底无语……也许您已对我失去信心，但倘若有机会，我将在未来的几年中，用尽我全力来弥补。感谢老师愿意读到这里，再次向您道歉。  \n再鸽\n\n\n\n\n\n\n\n\n超出能力范围了，暂无参考。如果硬要再鸽的话，就找一个不可抗力因素当作借口吧，比如：\n老师，我嫖娼被抓，保研资格没了，抱歉。\n节日祝福新年祝福  \n\n亲爱的张老师，岁除之夜，辞旧迎新！祝您家兴人和事顺遂，永远年轻、充满活力，春风桃李，百木成林。带着满满的祝福，大家携手向未来！\n亲爱的张老师，新年到了，祝您和家人新春愉快，天天开心，生活顺顺当当，身体健健康康！祝您在新的一年里工作顺利、科研顺心，万事胜意！\n亲爱的师姐，岁除之夜，辞旧迎新！祝你和家人新春愉快，虎年大吉！新的一年再携书卷，剑指南溟，继续带领大家共同成长！&#x2F;天高地阔任君跃，愿师姐新的一年蜚英腾茂，大展宏图！&#x2F;感谢师姐的悉心帮助，预祝工作顺利，万事胜意！&#x2F;奋斗有为正青春，愿新的一年再携书卷、直济沧海！&#x2F;(同级)十六载寒窗试锋芒，愿新的一年踔厉奋发，求皆如愿，我们一起进步成长！\nTo be continued…\n\n","slug":"保研文书","date":"2023-10-10T09:55:45.000Z","categories_index":"others","tags_index":"保研","author_index":"以太工坊"},{"id":"60101ff7c958535a3d3adf3b1d35269f","title":"保研经验帖","content":"基本情况末流211计算机学院大数据专业，排名（2&#x2F;99），CET6 (553)，三段项目经历，无paper，一些水奖；\n夏令营夏令营基本情况可见下图：\n\n其中入营了13个，除了一些宣讲性质不发offer的和中科院系列（没联系导师），一共参加了5个夏令营。以下对这5个夏令营的经历以流水账的形式呈现。\n吉林大学软件学院\n\n\n\n\n\n\n\n\n夏令营考核于6月18日-6月19日远程考核，首先请每位营员进行500字以内的自我介绍（时间不超过2分钟）；然后抽取试题，回答问题；最后专家提问，回答问题。\n英语: How to improve youself in the future?计网：电子邮件协议的格式？操作系统：IO中断时，数据的输入方式？项目：你这最终要实现甚么目标？国内外有人做过吗？\n南京大学计算机学院报名之后会有初筛，然后是进在线考试，在线考试合格才可以在线下进行机试和面试；初筛只是筛掉很少一部分人，大部分是倒在在线考试。7月9日进行在线测试，合格者于7月20号左右下线参与机试和面试。\n在线测试的内容无所不包，传统408Linux内核数论群论离散数学编译原理概率论逻辑推理脑筋急转弯，题量大范围广，这里有21年的真题2021年南京大学计算机科学与技术系本科生开放日7月8日线上考核.pdf，21年的真题，23年还能遇到一些原题。\n在线测试结束后还有心理测评和学术问卷，学术问卷的问题如下：\n\n你认为你在计算机学科中，最有兴趣且掌握得最好的课程是什么?\n针对这门课程，你分别在课内和课外经受过怎样的训练有怎样的成果?\n你是否打算从事与这门课程相关的研究工作?为什么?\n你是否具有良好的代码工程能力? 如何证明这一点?\n一些导师指出，许多本科生在发表论文、参加竞赛和创新项目等活动时，主要目的是为了丰富自己的简历，而非真正完成高标准的科研训练。他们认为，这种急功近利的行为可能会导致许多竞赛项目经历成为减分项。结合你自身经历，简要描述你的看法\n你拟从事的研究方向\n拟报考的南京大学计算机系课题组或导师，列出不超过2位\n简要描述你与导师联系的过程，以及导师的反馈，可以为两位导师分别列出\n请简要描述你打算申请的导师吸引你的特点，包括但不限于他们的代表性研究，出版的教材等。请尽可能提供一些具体的细节\n请列举一个你拟从事研究方向近年来有望取得突破的重要研究问题，并简述你拟从事研究方向的基本研究方法\n\n倒在了在线测试，因此没有后续。\n中国人民大学高瓴人工智能学院主观感受先吹一波：19年成立的高瓴以如此小的规模和年轻的年龄，坐拥高瓴资本和人大附中的加持，引进各路大佬，取得十分耀眼的成绩。也许再过几年，绿裙里“清北之下科研第一选择”的帽子就要归高瓴了。高瓴里面的老师有在哈佛回来的，也有MIT、加州大学的，不仅学术能力强，还有微软亚洲研究院、腾讯等connection，“高瓴无坑导”这句话没有一点吹牛的成分。\n所谓大学之大，非有大楼之谓也，乃有大师之谓也”，高瓴是两者兼有的，下面的图是在高瓴楼里俯瞰中关村。\n\n我报的是直博，遂入营；学硕根本是神仙打架，最终录取结果是直博候补到22，学硕候补到15；高瓴是我参与的印象最深刻的夏令营。\n夏令营考核高瓴的考核绝对是最规范的那一批，考核的内容细则可以在官网找到，主要有笔试和面试，CSP满足标准可以给笔试加10分（有机会一定要考CSP）；\n第一天 笔试：\n笔试主要考察数据结构与算法、英语和数学（线性代数、矩阵论）以及人工智能基础；试卷大概也就是这三部分，第一部分是数据结构基础、线代概率论的填空选择，难度与期末考试相仿，第二部分是英文翻译中译英（分数不如一道填空题），第三部分是算法设计（要给出伪代码）与数学证明任选。\n第三天 面试流程：\n面试前有一个德智体美劳部分，5分钟，问了下面这些问题：\n\n自我介绍一下（中文）\n你刚才提到了你做的项目，那能不能说一下你觉得这里面最困难的部分是什么，你是怎么解决的。\n你最讨厌什么样的人，你会和他们怎样打交道。\n如果在读研期间，比如你在研一的时候，其他人都发了很多论文，有很多产出，但是你还是没有成果，你会怎么做？\n如果在读研的时候，你和你导师的意见有分歧，你会怎么做？\n你跟你父母有没有矛盾，是怎样化解的呢？\n如果你在生活中遇到了困难或者问题，你会怎么做？自己消化还是？\n平常有没有可以消遣的活动？\n你有没有比较好的朋友？可以介绍一下吗？\n你觉得他吸引你的特质是什么，你有没有跟他学到了什么？\n在研究生期间，你会参加社团活动吗？\n\n结束之后到另一个会议室参加面试，面试严格限时，到时间答不完也不行：\n英语考核：\n\n介绍你自己，一到两分钟。\nHow to achieve your short-time goal and long-time goal?\n\n专业面试：\n\n文院长：这里有一到五号信封，任选一个。\n综合问题：介绍你印象最深的一个项目，你在项目过程中遇到了什么困难，你是怎样解决的？\n算法题：一张图有红点和蓝点，可能有自环和平行边，求从0号点开始，依次穿插经过蓝点和红点，到每个点的最短距离。\n数学题：直方图的应该怎样构建，分辨率过小有什么影响，分辨率过大有什么影响？有没有办法可以让分辨率自适应？\n\n还有的同学面试抽到数分，高等代数的东西，以及在人工智能中的应用。\n面试流程很规范，顺序是现场抽签，等待时被关在小黑屋里不能用手机（因此需要把复习材料打印），面试完成的人禁止与等待的人接触，全程有人跟着监督；不像车大，所有人在外面一起等，后面的人把老师的题库都摸透了。\n第二天 学术市集：白天面试老师，晚上被面试\n第二天的活动不计入考核，主要是给一个相互交流的机会；白天的学术市集是老师或者他的学生在展位前，向营员介绍自己的研究方向，这时候营员也可以投简历加微信，我就见到那位宋老师收了无数简历，以及带着A区论文的西交爷被承诺只要是优营就收。\n晚上的面试官方说法是面谈，需要提前与老师约好，实际就是面试，主要是抢好导师的，但导师一般不能承诺offer，因为是超强COM。\n中南大学大数据研究院大数据研究院不像计算机学院一样是海王，但是优营和候补是在一个名单里的（优营20-30人，录取10-20人）。夏令营了解下来的感觉是，学术水平一般，横向多，研究氛围很怪，靠着湘雅医院的资源吃饭。\n考核包括笔试、机试、英语+PPT面试，任一小于60分即不合格（其实最后机试很多人机试5题做两题也合格了）。\n\n笔试包含四个科目，分别是计算机组成原理、操作系统、数据结构和数据库，每个科目一张试卷，总时长2小时。题型有选择判断填空简答，题量还能做完，期末考试的难度。\n机试是第二天去新校区考的，4小时5道题，一题签到题，三题图论（有两个最短路问题类似，用Dijkstra模板级别的），一题DP。整体机试难度不大。\n面试在第三天，包含英语问答和PPT面试，分别在两个教室。英语面试除了常规的问答外，还可能问专业相关的知识（由你引导，不会刁钻，比如计算机视觉经典的网络模型）。PPT面试先是按照PPT介绍，随后专家提问，一般是关于项目经历和成果的。\n所有流程结束后在长沙玩了两天，长沙太适合旅游了。\n东南大学计算机学院车大每年都是夏令营最晚开的，别家都快开预推免了。流程是预推免的规格，只有面试，包含赶路的时间，一共只花了三小时。虽然开的晚，但是联系老师和PALM还是要尽早。23年和去年一样需要老师推荐，学院筛选后入营，去年还卡学科评估，今年似乎就不卡了。\n面试准备一个PPT，先PPT介绍，然后是英语问答，最后老师提问，我的问题如下：\n\n项目的创新点？\n什么背景下做的？\n最难的工作？\n自己的贡献？\n国内外研究进展，与其它人的性能对比？\n你学了最优化，那么损失平面不连续或者不可导该怎么办？\n\n预推免\n预推免由于时间过于集中，只参加了三个，分别是浙大数据科学项目、计算所和人机所。\n计算技术研究所这是官方通知\n\n\n\n\n\n\n\n\n\n中科院计算所2024年推免招生面试流程-分布式系统研究中心首先，面试组长宣布面试开始，请考生说出本人姓名、身份证号以及本科学校和本科专业。（面试时长共20分钟左右）1、英语测试（面试组专家可自由发挥。主要考察考生听说能力）【共3分钟左右】2、业务能力面试：【共17分钟左右】\n请考生用PPT介绍个人情况。如：本科课程、专业兴趣、科研经历和志向等（约5分钟）\n面试组考官对考生进行提问，考生回答。面试组自定题目。主要考核以下方面（约12分钟）：业务能力、综合素质、思想政治品德等\n考生需准备以下材料：1、PPT（13日12点前邮件至*@ict.ac.cn）2、计算所官网推荐免试招生简章第三条提到的电子材料（请准备5份，双面、黑白打印）3、短期意外险（包含面试期间即可，如已有，可不买）\n面试很随便，老师们似乎并不关心具体的项目细节。\n英语口语：\n\n介绍你最崇拜的人，以及为什么？\n介绍你的家乡\n介绍你的家庭\n介绍一下你的成长经历\n\n三分钟口语，全都是用中文提问的（第一次见），去年据说根本就没有口语。\n按PPT介绍。\n提问15min：\n\n你的项目是如何实现云边协同的？\n什么是云计算？\n你的项目中用到Kafka,为什么要用或者说为什么要选择它而不是其他的中间件？卡夫卡是如何实现消息分发的？消息会落到硬盘吗？有没有提升性能的方法？\n专利中你是什么角色？写稿还是贡献？做了什么工作？\n有没有其他offer?为什么选择这里？\n\n最后拿到了offer也签了双选协议，但是最后鸽了，因此如果是学弟学妹在看，真的很抱歉，计算所分布式中心可以不用考虑了，但是仍然可以选择计算所其它实验室，比如上一届有个学长就去了VIPL。\n西安交通大学人工智能学院（人机所）\n\n\n\n\n\n\n\n\n面试时，按面试顺序，每5位同学为一组，提前进入腾讯会议等候区。等候区同学进入面试会议后开启摄像头进行面试，首先依次进行自我介绍（每人不超过3分钟），然后由专家提问。每组总时间不超过30分钟。预祝大家面试顺利！\n人机所的面试非常神奇，可能因为时间有限，所以组织大家参加群面。省内学生线下参加，省外学生线上参加。5个人自我介绍后，20min已经过去了，10min分别针对大家的个人经历，问了一些问题，主要都是项目相关。西交整个学校都很看重背景，人机所往年的录取名单就没有不是985的。\n浙江大学数据科学项目自我陈述\n复试内容每位申请者面试时间不少于20分钟，全程录音录像。面试内容包含思想政治素质和品德考核、个人陈述、本专业综合知识问答、英语问答。申请人需就个人学习与研究或工程经历、成果、获奖、研究志向与发展规划等方面进行陈述（个人陈述时间控制在8分钟内，需包含2-3分钟连贯性的英语内容）。\n专业知识\n三个信封，抽取一个，包含两个问题，一个数学题，一个机器学习相关问题；\n我前面一位抽到的：\n\n什么是连续函数？\n什么是KMeans算法？-老师追问聚类的“聚”是怎么体现的？\n\n我抽到的：\n\n什么是矩阵的奇异值分解？\n什么是梯度下降算法？-老师追问什么是随机梯度算法？\n\n信封回答结束后，老师看了我的简历上写了概率论100分，追问了一个“什么是概率空间？“\n思想考核\n你练**功吗？\n其余\n这一部分属于是流程走完不到二十分钟硬凑时间的，啥问题都有，之前有一个人问的是”你为啥要来浙江大学“？\n我问的是关于项目的：你这个任务为什么要用语义分割，介绍一下你的网络，这个信号处理、极大似然是你做的吗？\n英语似乎在PPT陈述阶段的英语陈述可有可无，都会临时问一个英语问题，我问的是：Introduce one of your favorite algorithm.\n总的来说，考核极其规范，是高瓴那种最规范的，所有面试者都集中到一个等候室中，不允许使用电子设备与相互交流，面完即走，同时使用信封抽题。\n总结23年保研形式的重大变量有：\n线上转线下——虽然部分学校仍然线上考核，夏令营该海的还是海，没有排名或paper，入营难度没有下降\n保研名额增长——哈工大、北交等学校为了给本校兜底，甚至出现反向鸽学生的情况\n强基转段首年——主要是占用头部院校的名额，对计算机相关专业无直接影响但仍然有传导效应\n国优计划首年——30所高校，双学位还不强制当老师，个人感觉非常香，但很多学校只招本校，就算招外校也是在夏令营入营的基础上招\n工程硕博——今年多了很多工程学位的名额，第一年在校上课，后两年去企业实习，毕业需签订竞企协议（干这行只能在我家，不能跑到竞争对手那）。企业大多都是国企，还有华为（华科）与腾讯（南科大）等大厂。很多学校工程学位的名额是临时加的，甚至在预推免结束之后，十月份还有不少坑位，其中不乏清北华五的。此外这个招生不是由教育部组织的，而是中组部，虽然也填同一套系统，但录取优先级高于专硕学硕，也就是说，被工程学位录取的，其余专硕学硕offer作废（道听途说，没找到官方文件）。\n联系导师要趁早，许多清北华五顶级组甚至在前一年年底就没啥实习坑位了。如果现在没有好看的排名或者预计没有paper，可以试试联系导师要求实习，很多实验室的老师会在主页说在招实习生。中科大、中科院、南开和北邮都是话语权在老师，老师收了就能录取；厦大和车大则是要求有他们自己学校的老师推荐。\n个人感觉寒假就可以找老师考核或者复习专业课，4、5月份准备材料和期末考试，6月之后开始各种报名和参营，很难再找到大段时间了。\n","slug":"baoyan","date":"2023-10-09T09:55:45.000Z","categories_index":"others","tags_index":"保研","author_index":"以太工坊"},{"id":"6e6b30b0bd6d414033ab3567b4a4ecfb","title":"单配置多主题博客方案","content":"起因\n\n\n\n\n\n\n\n\n很少有主题能兼顾实用与美观，比如极光主题虽然炫酷好看，但是单页展示的内容过少，不能专注于内容；就是想折腾\n因而产生了如下需求：\n\n一份配置文件生成多种主题的博客，同时存在\n站点间路由一致，方便随时切换由于现在的博客全站是基于Git管理的，虽然可以使用不同的分支管理不同的主题，但这么做在每次更新文章的时候非常不方便，所以这种方案不采用。\n\n\n配置由于hexo generate可以指定配置文件，这就为本方案提供了可能。本次使用的是Hexo Next 8 和 Aurora 两套主题，配置文件在根目录的组织形式如下：\ntxt-/\n--_config.yml  为Aurora准备的全局配置\n--_configsimple.yml  为Next准备的全局配置\n--_config.aurora.yml  Aurora主题配置\n--_config.next.yml  Next主题配置对于一般的主题，使用hexo generate --config x.yml也就没什么问题了，但是Aurora主题需要的插件hexo-plugin-aurora直接是对hexo命令生效的，也就是Aurora主题与其它主题互斥，有它在的情况下，就别想用别的主题，难道就没办法了吗？由于不了解npm，我想到的笨办法是直接把hexo-plugin-aurora卸了，在构建需要时再装回来，这样就能保持package.json是干净的。捋一下，现在为了两套主题，我们要做的：\n\n维护好各自独有的依赖\n使用自定义的生成命令\n\n\n\n\n主题\n安装阶段\n生成阶段\n\n\n\nAurora\nnpm install hexo-plugin-aurora\nhexo generate --config _config.yml \n\n\nNext 8\n无额外依赖\nhexo generate --config _configsimple.yml\n\n\n路由问题统一多个站点的路由，比如我现在在www.zair.top/post/a 页面里面，想要切换到另一个主题，只需要把www替换成s即可，即s.zair.top&#x2F;post&#x2F;a ，从而实现快速切换主题。\n这里的问题主要在地址的.html后缀上，一般来说，确保多个主题的全局配置文件中的以下字段统一即可：\nyml# permalink: :year/:month/:day/:title/ 配置详见https://hexo.io/zh-cn/docs/permalinks.html\npermalink: /post/:title.html\npermalink_defaults:\npretty_urls:\n  trailing_index: true # Set to false to remove trailing &#39;index.html&#39; from permalinks\n  trailing_html: true  # Set to false to remove trailing &#39;.html&#39; from permalinks但Aurora哪是一般的主题，它是由Vue构建的单页应用，地址栏输入的后缀（如&#x2F;post&#x2F;a）统统按请求参数处理，而一般的主题则认为它是一个静态页面的路径。如果托关于Cloudflare Pages上，这个问题可以忽略，但Vercel的需要自己配置，具体来说，需要在根目录创建vercel.json，内容如下：\njson&#123;\n    &quot;redirects&quot;: [\n        &#123; &quot;source&quot;: &quot;/post/:path*.html&quot;, &quot;destination&quot;: &quot;/post/:path*&quot; &#125;\n    ],\n    &quot;rewrites&quot;: [\n        &#123; &quot;source&quot;: &quot;/:path*&quot;, &quot;destination&quot;: &quot;/index.html&quot; &#125;\n    ]\n&#125;第一条将所有的.html后缀重定向，这是为了兼容一般静态主题；第二条将所有请求反向代理到根页面，是Aurora在Vercel上需要配置的；两条规则其实是冲突的，但冲突时，Vercel选择靠前的遵守，用起来没问题。\n对于许多静态页面托管网站，都有Pretty URL的功能，将URL的.html后缀去掉，但Vercel叒没有，如果想用，得配置另一个vercel.json:\njson&#123;\n    &quot;rewrites&quot;: [\n        &#123; &quot;source&quot;: &quot;/:path*&quot;,&quot;destination&quot;: &quot;/:path*.html&quot;&#125;\n    ]\n&#125;但是，Vercel的配置文件不支持重命名，只能有一个，所以Next主题的网站就只能托管于Netlify，Netlify对.html后缀就处理得很好。最后再分享一下在两个网站得部署配置：这是在Vercel上部署Aurora的配置，其实是两条命令\nbashnpm install hexo-plugin-aurora &amp;&amp; cp index_prod-00ee5e98.js node_modules/hexo-theme-aurora/source/static/js/第二条是用来覆盖我自定义的主题js；\n下图是在Netlify上的配置：\n","slug":"单配置多主题博客方案","date":"2023-09-09T08:52:47.000Z","categories_index":"技术帖子","tags_index":"Vercel,Netlify","author_index":"以太工坊"},{"id":"319b8234c5d2a285f0f89f7f3059426e","title":"首页导航","content":"你好，欢迎来到以太工坊！👋\n如果您使用笔记本电脑，或是希望专注与内容，推荐访问极简版s.zair.top如果您使用24寸及以上的高分屏，或是希望体验更多功能，推荐访问完整版www.zair.top在任何文章页面，您可以通过在浏览器地址栏更改前缀来切换主题，譬如本文地址为www.zair.top&#x2F;post&#x2F;home 时，访问的是完整版；地址为s.zair.top&#x2F;post&#x2F;home 的则是极简版。如果遇到图片无法显示的情况，请先检查网络代理，有部分图片托关于Github。遇到任何内容问题，欢迎您评论或是与我联系。🎉\n","slug":"home","date":"2023-09-08T13:13:52.000Z","categories_index":"","tags_index":"","author_index":"以太工坊"},{"id":"389ce8386cc3fe14689588a474c2dc6f","title":"大数据可视化复习","content":"论述题（7*8分)\n论述数据、图形与可视化的关系\n论述可视化的流程\n论述比较类图，分布类图，流程类图的特点\n论述矢量图与位图的特点\n论述结构化、数据半结构化数据、非结构化数据的特点\n论述云服务的分类与华为云DLV的特点\n论述AR VR MR的特点\n\n看图写代码一个图里三条线，带图例，样式考察仅限于线型、点型（matplotlib)\n看代码画图matplotlib: 上下两个子图echarts:考察点grid实现子图每个子图中，柱状图与折线图两个系列叠加dataset.source花式切分数据系列（layoutby&#x3D;’row’)\n","slug":"大数据可视化复习","date":"2023-06-30T03:05:46.000Z","categories_index":"大数据","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"0958d5ba8c7f08fa8c58292fe8de4d1f","title":"深度学习复习课","content":"复习课视频录像GRC和他小伙伴的笔记\n0. 题型\n\n\n题型\n数量\n分值\n\n\n\n简答题\n4\n60\n\n\n设计题\n2\n25\n\n\n未知题型\n1\n15\n\n\n老师对最后的题目讳莫如深，“你只要上课听了，还是能拿一点分的”。乐。\n1. 提纲第二章\n\n掌握随机梯度下降算法\n掌握批量梯度下降算法\n理解正则化（L1，L2）\n掌握Dropout思想、处理流程等\n掌握常用定理：NFL、丑小鸭、奥卡姆剃刀等\n\n第三章\n\n掌握Logistic回归、Softmax回归\n掌握各种常见的损失函数公式以及针对具体的应用场景，如平方损失、交叉熵损失等\n理解经验风险与结构风险\n\n第四章\n\n掌握几种常见的激活函数(Sigmoid、ReLU)优缺点\n理解前馈神经网络的基础知识\n\n第五章\n\n掌握卷积神经网络的特点（对比全连接网络）\n卷积网络：卷积核、特征图、颜色通道数\n汇聚层的作用\n常见典型CNN卷积结构的参数计算（例如卷积层的参数量、链接数、输出图大小等）\n掌握残差网络（工作原理、公式等）\n\n第六章\n\nRNN公式的表达\nRNN中出现的梯度消失和梯度爆炸问题\n对应的解决办法\n\n\n掌握序列到序列的模型（同步和异步）\n具体应用（同步和异步-Sentiment Analysize）\n公式表达\n优缺点\n\n\n掌握LSTM\n三个门的作用与意义\nLSTM对比RNN的优缺点\n‘输入与输出\n’LSTM可以解决梯度消失问题，类似残差网络的处理方法\n\n\n掌握GRU\n对比LSTM有哪些改进\n‘GRU的公式\n\n\n\n第七章 网络优化\n\n学习率的改进\n学习率衰减-看看就行\n周期性调整-不必看公式\n重点掌握：自适应调整：Adagrad, Adadelta, RMSProp \n三种方法掌握公式与原理，重点是公式\n\n\n梯度优化\n动量法\nNesterov加速梯度\nAdam算法\n\n\n梯度截断\n高低维度情况下的网络优化\n\n\n\n\n\n\n\n\n逃离鞍点\n\n数据归一化三种方法\n’取出相关维度的相关性-白化\n\n\n掌握批量归一化与层归一化（定义、方法、具体操作方法）\n丢弃法(Dropout)\n\n第八章\n\n掌握注意力模型\n意义-为啥要注意力模型\n公式\n处理流程等\n\n\n掌握自注意力模型\n意义-重点掌握、教之前的提升、KQV计算等\n公式\n处理流程\n\n\n掌握Transformer（结构、技术等）\n\n第十四章\n\n强化学习的五要素\n第五要素：策略\n\n\n两个值函数：状态值函数、状态-动作值函数\n掌握策略迭代算法、值迭代算法、SARSA算法以及Q-Learning算法\n\n\n\n\n\n\n\n\n\n\n蒙特卡洛采样\n2.机器学习概述机器学习三要素模型线性模型广义线性模型\n学习准则\n\n\n\n\n\n\n\n\n在线性回归模型中，下面的所有损失函数 都是平方损失函数。\n期望风险是对现实情况而言的但是真实的数据分布无法获得，只能通过经验风险近似：在使用经验风险近似期望风险时，会产生泛化错误。减小泛化错误的需要优化和正则化（损害优化，防止过拟合）两种手段。结构风险在经验风险的基础上增加了正则化项，结构风险最小化可以解决（缓解）过拟合问题。\n优化方法（批量）梯度下降、随机梯度下降、小批量梯度下降、早停\n（批量）梯度下降批量梯度下降法在每次迭代时需要计算每个样本上损失函数的梯度并求和（目标函数是整个训练集上的风险函数）。当训练集中的样本数量𝑁 很大时，空间复杂度比较高，每次迭代的计算开销也很大。\n随机梯度下降批量梯度下降法相当于是从真实数据分布中采集𝑁 个样本，并由它们计算出来的经验风险的梯度来近似期望风险的梯度．为了减少每次迭代的计算复杂度，我们也可以在每次迭代时只采集一个样本，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法批量梯度下降和随机梯度下降之间的区别在于，每次迭代的优化目标是对所有样本的平均损失函数还是对单个样本的损失函数．由于随机梯度下降实现简单，收敛速度也非常快，因此使用非常广泛．随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声．在非凸优化问题中，随机梯度下降更容易逃离局部最优点．\n小批量梯度下降*\n正则化方法正则化（Regularization）是一类通过限制模型复杂度，从而避免过拟合，提高泛化能力的方法，比如引入约束、增加先验、提前停止等．正则化的方法有如下：\n\nL范数正则化\n权重衰减\n提前停止\n丢弃法\n数据增强\n标签平滑\n\nL范数正则化本质上是引入一个约束，作为惩罚。这样在优化的时候，不能只看目标函数，还得考虑引入的惩罚（正则化项）。得治治\nL1正则化无论权重大小，施予相同的惩罚，较小的权重就会变成0. 使得L1正则化最大的作用是使大量参数变为0，将模型稀疏化。L2正则化对大权重惩罚很重，小权重惩罚很轻。引入到式子里的一般是二范数的平方方便计算（如上图）。\nDropout详细参见网络优化-Dropout部分训练阶段测试阶段\n常用定理没有免费午餐定理(NFL)：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效．如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差．也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性．必须要“具体问题具体分析”\n奥卡姆剃刀（Occam’s Razor）原理：“如无必要，勿增实体”．奥卡姆剃刀的思想和机器学习中的正则化思想十分类似：简单的模型泛化能力更好．如果有两个性能相近的模型，我们应该选择更简单的模型．因此，在机器学习的学习准则上，我们经常会引入参数正则化来限制模型能力，避免过拟合．\n丑小鸭定理：“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”．因为世界上不存在相似性的客观标准，一切相似性的标准都是主观的．如果从体型大小或外貌的角度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果从基因的角度来看，丑小鸭与它父母的差别要小于它父母和其他白天鹅之间的差别．这里的丑小鸭是指幼年白天鹅\n3. 线性模型参考：两种线性模型的比较\nLogistic 回归\n\n\n\n\n\n\n\n\n西瓜书中叫对数几率回归，是一种常用的二分类问题模型\n这是一个平平无奇的线性模型：引入激活函数进行非线性变换，将输出映射到之间，作为预测为正例的概率:实际上输出的值是样本x为正反例后验概率的比值的对数，叫对数几率：损失函数使用交叉熵：其中是真实值（标签），为预测值求导结果为输入与一阶损失的乘积，因此梯度下降法更新如下：\nSoftmax回归多分类的Logistic回归，是Logistic更一般的形式\n\n\n\n\n\n\n\n\n\n\n在风险函数中加入正则化来约束其参数．不加入正则化项限制权重向量的大小, 可能造成权重向量过大, 产生上溢.\n\n\n\n\n\n\n\n\n\n\n分析为什么平方损失函数不适用于分类问题.分类问题中的标签，是没有连续的概念的。每个标签之间的距离也是没有实际意义的，所以预测值和标签两个向量之间的平方差这个值不能反应分类这个问题的优化程度。\n比如分类 1,2,3, 真实分类是1, 而被分类到2和3错误程度应该是一样的, 但是平方损失函数的损失却不相同.\n①目标函数不一致：分类问题的目标是将样本正确分类到不同的类别中，而不是预测一个连续值。平方损失函数的目标是最小化预测值与真实值之间的平方差异，这与分类问题的目标不一致。②异常值敏感性：平方损失函数对异常值非常敏感。在分类问题中，异常值通常表示样本的错误分类，这意味着对异常值的错误分类会导致非常高的损失。分类问题中的异常值更常见，因为分类问题涉及到预测离散的类别标签，而异常值可能导致较大的误差。③梯度消失：平方损失函数在分类问题中容易出现梯度消失的问题。由于分类问题的输出是一个概率或类别标签，使用平方损失函数时，梯度可能变得非常小，使得模型难以学习或收敛。④不可导性：在分类问题中，常用的激活函数（如sigmoid、softmax）通常与平方损失函数不兼容。这是因为这些激活函数产生的输出不是连续的，而平方损失函数对于连续的输出是可导的。因此，在分类问题中使用平方损失函数可能会导致不可导的情况，使得无法使用常规的优化算法进行训练。\n\n  \n\n4. 神经网络激活函数一个合格的激活函数应该具有以下性质：\n\n连续可导\n简单、方便计算\n值域在一个合适的区间\n\nSigmoid系列两者都是simoid型函数，具有饱和性：\n\n计算开销大\n输出平滑，没有跳跃值\n处处可导\n适用于概率\n梯度消失\n以0/不以0为中心\n\nReLU系列优点    - 计算开销小，只有简单的加乘    - 生物合理性：单侧抑制    - 左侧饱和，x&gt;0时导数为1，缓解梯度消失    - 加速梯度下降的收敛速度缺点    非0中心化，给后层带来偏置    死亡ReLU问题：一次不恰当的更新，就永远不能被激活(ELU可以解决)\n前馈神经网络输入层不算入网络层数，网络层数指的是隐层数量\n\n通用近似定理根据通用近似定理，对于具有线性输出层和至少一个使用“挤压”性质的激活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可以以任意的精度来近似任何从一个定义在实数空间中的有界闭集函数。神经网络可以作为一个“万能”函数来使用，可以用来进行复杂的特征转换，或逼近一个复杂的条件分布。\n5. CNNFCN处理图像有如下问题：\n\n参数太多\n局部不变特性  自然图像中的物体都具有局部不变性特征，比如尺度缩放、平移、旋转等操作不影响其语义信息．而全连接前馈网络很难提取这些局部不变性特征\n\nCNN特点CNN天生就适合处理图像：\n\n局部连接：局部连接会大大减少网络的参数。在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的。让每个神经元只与输入数据的一个局部区域连接，该连接的空间大小叫做神经元的感受野，它的尺寸是一个超参数，其实就是滤波器的空间尺寸。\n权值共享：在卷积层中使用参数共享是用来控制参数的数量。每个滤波器与上一层局部连接，同时每个滤波器的所有局部连接都使用同样的参数，此举会同样大大减少网络的参数。\n空间或时间上的次采样：它的作用是逐渐降低数据的空间尺寸，这样的话就能减少网络中参数的数量，使得计算资源耗费变少，也能有效控制过拟合。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性．和前馈神经网络相比，卷积神经网络的参数更少\n\n卷积层卷积核大小：卷积核定义了卷积的大小范围，在网络中代表感受野的大小，二维卷积核最常见的就是 3*3 的卷积核。一般情况下，卷积核越大，感受野越大，看到的图片信息越多，所获得的全局特征越好。但大的卷积核会导致计算量的暴增，计算性能也会降低。（大到极致就是FCN）步长：卷积核的步长代表提取的精度, 步长定义了当卷积核在图像上面进行卷积操作的时候，每次卷积跨越的长度。对于size为2的卷积核，如果step为1，那么相邻步感受野之间就会有重复区域；如果step为2，那么相邻感受野不会重复，也不会有覆盖不到的地方；如果step为3，那么相邻步感受野之间会有一道大小为1颗像素的缝隙，从某种程度来说，这样就遗漏了原图的信息。填充：卷积核与图像尺寸不匹配，会造成了卷积后的图片和卷积前的图片尺寸不一致，为了避免这种情况，需要先对原始图片做边界填充处理。\n特征映射（Feature Map）为一幅图像（或其他特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征．为了提高卷积网络的表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征．在输入层，特征映射就是图像本身．如果是灰度图像，就是有一个特征映射，输入层的深度𝐷 = 1；如果是彩色图像，分别有RGB 三个颜色通道的特征映射，输入层的深度𝐷 = 3．卷积层输入特征映射，输出  ,，每一个输出特征映射都需要𝐷 个卷积核以及一个偏置．假设每个卷积核的大小为𝑈 × 𝑉，那么共需要𝑃 × 𝐷 × (𝑈 × 𝑉) + 𝑃 个参数．卷积输出图的大小:连接数： 参数个数 ×输出的特征图平面大小\n\n\n以LeNet-5为例进行计算：\n汇聚层作用：\n\n减少计算量和参数数量，使得模型更容易训练；\n降低特征图的分辨率，减少过拟合；\n提取更为重要的特征，因为汇聚层只选择最大值或平均值，这些值往往包含更多的信息\n\n残差网络\n\n\n\n\n\n\n\n\n\n题目\n分析卷积神经网络中用1 × 1的卷积核的作用．\n解答\n降维（减少参数）在Inception网络中使用 1 × 1 的卷积来减少特征映射的深度\n升维（使用最少的参数拓宽维度）如下的ResNet网络结构图右侧最后一层使用 1 × 1 × 256 的卷积核来将输出的64维提升到 256 维且只需要 64_1_1*256 个参数\n跨通道信息交互实现升维和降维的操作，其实就是不同通道之间的线性组合，这就是跨通道信息交互\n增加非线性特性每一个卷积操作之后会添加一个非线性激活函数，使用 1 × 1 的卷积核可以在保持特征图尺度不变的情况下增加非线性特性\n\n\n6. 注意力机制\n\n\n\n\n\n\n\n\n由于优化算法和计算能力的限制，神经网络要想达到通用近似能力，网络不能太复杂。\nAttention意义解决长序列语义丢失与输入贡献度分配问题\n\nSource 经过 Encoder，生成中间的语义编码 C。\nC 经过 Decoder 之后，输出翻译后的句子。在循环神经网络中，先根据 C 生成 y1，再基于（C，y1）生成 y2，依此类推。传统的循环神经网络中，y1、y2 和 y3 的计算都是基于同一个 C. 然而，可能并不是最好的方案，因为 Source 中不同单词对 y1、y2 和 y3 的影响（贡献）是不同的。\n\n从语义编码C入手，注意力机制使其在每个时刻根据编码器的输入自适应变化，从而对下个模块（比如：解码器）的输出产生影响。AIM：解决每个输入贡献度问题\n公式\n流程\n\nF(Q,K)计算相似度，可选用Dot Product, Cosine, MLP\nF 的输出再经过 Softmax 进行归一化就得到注意力分配概率\n最后根据计算输入信息的加权平均，得到注意力值这张图与之前的一张没什么不同，更简洁直观了。需要注意SoftMax之后的加权平均，可以写成随机变量的期望形式。\n\n变体李宏毅讲的就是这种键值对注意力机制。\n多头注意力机制。\nSelf-Attention意义引入 Self Attention 机制，顾名思义，指的是 Source 内部元素之间或者 Target 内部元素之间发生的 Attention 机制，也可以理解为 Source = Target 这种特殊情况下的Attention 机制，具体计算过程和 Soft Attention 是一样的\nKQV模式与李宏毅讲的一毛一样。SoftMax中的处理稍有不同，分母是一个常数。\n流程\n\n计算向量，这三个向量分别由输入的与对应的权重矩阵相乘得到\n计算self-attention，由Query与Key点乘(dot product)得到，该分数值决定了当我们再某个未知encode一个词时，对输入句子其它部分的关注程度\n将点乘结果除以一个常数（一般），再把结果softmax,得到的结果时每个词对当前位置词的相关性大小（与自己最大）\n把Value与Softmax得到的值相乘相加，得到的结果就是self-attention再当前节点的值(缩放点积注意力)\n\nTransformer结构\ntransformer采用encoder-decoder架构，如下图所示。Encoder层和Decoder层分别由6个相同的encoder和decoder堆叠而成，模型架构更加复杂。其中，Encoder层引入了Muti-Head机制，可以并行计算，Decoder层仍旧需要串行计算。\n炫技\n\nSelf-attention: 计算句子中的每个词都和其他词的关联，从而帮助模型更好地理解上下文语义\n\nMulti-head attention: 每个头关注句子的不同位置，增强了Attention机制关注句子内部单词之间作用的表达能力Transformer为什么需要进行Multi-head Attention ?  原论文中说到进行Multi-head Attention的原因是将模型分为多个头，形成多个子空间，可以让模型去关注不同方面的信息，最后再将各个方面的信息综合起来。直观上讲，多头的注意力有助于网络捕捉到更丰富的特征/信息。\n\n前馈神经网络FFN: 为encoder引入非线性变换，增强了模型的拟合能力\n\nDecoder接受output输入的同时接受encoder的输入，帮助当前节点获取到需要重点关注的内容\n\nFeed Forward Network: 每一层经过attention之后，还会有一个FFN，这个FFN的作用就是空间变换。FFN包含了2层linear transformation层，中间的激活函数是ReLu。FFN的加入引入了非线性(ReLu激活函数)，变换了attention output的空间, 从而增加了模型的表现能力。把FFN去掉模型也是可以用的，但是效果差了很多\n\n层归一化（Layer Normalization）: 规范优化空间，加速收敛\n\nPositional Encoding: 位置信息编码位于encoder和decoder的embedding之后，每个block之前。它非常重要，没有这部分模型就无法运行。Positional Encoding是transformer的特有机制，弥补了Attention机制无法捕捉sequence中token位置信息的缺点，使得每个token的位置信息和它的语义信息(embedding)充分融合，并被传递到后续所有经过复杂变换的序列表达中去。\n\nMask 机制: mask 表示掩码，它对某些值进行掩盖，使其在参数更新时不产生效果。Transformer 模型里面涉及两种 mask，分别是 padding mask 和 sequence mask。其中，padding mask 在所有的 scaled dot-product attention 里面都需要用到，而 sequence mask 只有在 decoder 的 self-attention 里面用到。\n\nPadding mask：每个批次输入序列长度或许不同，需要对输入序列进行对齐。\n\n具体来说，给在较短的序列后面填充 0；\n如果输入的序列太长，则是截取左边的内容，把多余的直接舍弃\nattention机制不应该关注这些，把这些位置的值加上一个非常大的负数(负无穷)，这样的话，经过 softmax，这些位置的概率就会接近0\n\n\nSequence mask：使得 decoder 不能看见未来的信息。对于一个序列，在 time_step 为 t 的时刻，解码输出应该只能依赖于 t 时刻之前的输出，而不能依赖 t 之后的输出。因此需要把 t 之后的信息隐藏起来。产生一个上三角矩阵，上三角的值全为0。把这个矩阵作用在每一个序列上\n\nResidual Network 残差网络： \n\n\n\n\n\n\n\n\n\n网络退化现象：在神经网络可以收敛的前提下，随着网络深度的增加，网络表现先是逐渐增加至饱和，然后迅速下降。\n\n\n在transformer模型中，encoder和decoder各有6层，为了使当模型中的层数较深时仍然能得到较好的训练效果，模型中引入了残差网络。解决网络过深带来的网络退化问题\n好处都有啥\n\n\n\n\n\n\n\n\nSeq2Seq模型的两个痛点： \n\n序列过长，语义消失问题\n位置信息丢失\n\n\n\n首先改进了上面两个缺点，做法为： 1-残差结构，2-位置编码\n多头注意力能提取更多的信息\nencoder层的多头注意力可以并行计算\nself-attention模块让源序列和目标序列首先“自关联”起来，使得源序列和目标序列自身的embedding表示所蕴含的信息更加丰富\nFFN层也增强了模型的表达能力\n…\n\n\n7. RNNSRN\n\n\n\n\n\n\n\n\n前馈神经网络层与层之间连接，层内不连接（不循环）；同时输入与输出都是固定的长度，不能处理变长的序列数据。\n\n\n\n图灵完备是指一种数据操作规则，可以实现图灵机的所有功能，解决所有的可计算问题。所有的图灵机都可以被一个由使用sigmoid激活函数的神经元构成的全连接循环网络模拟。\n双向RNN就是两个方向的RNN拼起来，一个正着读一个句子（序列），一个倒着读句子，这样每一个节点的输出都是包含了整个句子信息的。\n长程依赖问题梯度爆炸与梯度消失问题，只能学习到短周期的依赖关系。梯度爆炸    权重衰减（Weight Decay）: 是一种正则化技术，旨在限制模型的复杂度。它是通过向模型的损失函数中添加一个正则项来实现的，这个正则项通常是模型权重L2范数的惩罚项。这个惩罚项的作用是让模型权重不要太大，以此来减小模型的复杂度，从而抑制模型的过拟合。    梯度截断：对大于阈值的梯度进行截断（如&gt;15就=15）梯度消失问题    循环边改为线性依赖:  -这也其实解决了长程依赖问题    增加非线性（残差结构）：  \n\n\n\n\n\n\n\n\n\n对于梯度消失的两个结构上的改进，实际就是LSTM做的。LSTM可以缓解梯度消失的问题，但并不能解决梯度爆炸的问题（甚至更厉害，因为更复杂）。关于LSTM梯度爆炸的问题，李宏毅给出的解释是：不同于一般情况下，梯度消失由sigmoid函数导致，RNN中的梯度消失是因为同一个参数被反复用到多次，就好比, 的微小变化会带来结果的极大变化。LSTM缓解梯度消失的原因则是：细胞记忆，将原来循环边由乘改为加，记忆的影响会一直存在（除非遗忘门发力），记忆更持久。\nLSTMLSTM网络引入门控机制( Gating Mechanism )来控制信息传递的路径。三个“门”分别为输入门、遗忘门和输出门 ，这三个门的作用为：\n\n遗忘门控制上一个时刻的内部状态需要遗忘多少信息(保留)\n输入门控制当前时刻的候选状态有多少信息需要保存(输入)\n输出门控制当前时刻的内部状态有多少信息需要输出给外部状态\n\n\nLSTM对比RNN的优点：缺点就是梯度仍然爆炸！\nRNN的优点：\n\n具有记忆功能，可以处理和预测时间序列的数据。RNN的缺点：\n在处理长序列时，RNN的性能较差，因为信息传播时距离较长时，梯度传播容易出现梯度消失或梯度爆炸的问题。\nRNN的参数更新速度较慢，因为反向传播时需要等待前一时刻的输出结果。\nRNN的模型容量较小，因为信息的传播路径较短，难以捕捉长程依赖信息。LSTM的优点：\n可以处理长序列信息，因为LSTM通过记忆单元来存储长期依赖信息，信息传播路径较长。\nLSTM的参数更新速度较快，因为记忆单元中存储了长期依赖信息，可以更快地更新参数。\nLSTM的模型容量较大，因为记忆单元中存储了长期依赖信息，可以更好地捕捉序列信息。LSTM的缺点：\n虽然LSTM可以处理长序列信息，但在处理较短序列时，性能不如RNN。\n\nGRU\n\n\n\n\n\n\n\n\nGate Recurrent Unit 的精神是：旧的不去，新的不来。输入和输出门联动，输入打开则输出关闭，输出打开则输入关闭，每次都是置换船新数据。\n\n\nSeq2Seq ???具体应用：\n公式表达：\n同步：\n异步：\n8. 网络优化网络优化的难点\n\n\n\n\n\n\n\n\n结构差异大    没有通用的优化算法    超参数多非凸优化问题    参数初始化    逃离局部最优梯度消失、梯度爆炸\n低维空间的非凸优化问题：存在一些局部最优点(Local minima)与参数初始化。高维空间的非凸优化问题（深度神经网络）：不在于逃离局部最优点，而在于鞍点。鞍点一阶梯度为0，但海森矩阵非半正定。在高维空间中，局部最小值（Local Minima）要求在每一维度上都是最低点，这种概率非常低，也就是说，在高维空间中大部分驻点都是鞍点。随机梯度下降对于高维空间中的非凸优化问题十分重要，通过在梯度方向上引入随机性，可以有效地逃离鞍点。当一个模型收敛到一个平坦的局部最小值时，其鲁棒性会更好，即微小的参数变动不会剧烈影响模型能力；而当一个模型收敛到一个尖锐的局部最小值时，其鲁棒性也会比较差。在训练网络时，没有必要找全局最小值，这反而可能导致过拟合。\n神经网络优化的改善方法：\n\n优化算法\n动态学习率调整\n梯度修正估计\n\n\n参数初始化方法、预处理方法\n修改网络结构优化地形\n超参数优化\n\n优化算法\n批量大小的影响批量大小不影响随机梯度的期望，但是会影响随机梯度的方差；    批量大-随机梯度方差小-稳定-较大的学习率\n学习率调整学习率衰减学习率预热\n\n\n\n\n\n\n\n\n\n在小批量梯度下降法中，当批量大小的设置比较大时，通常需要比较大的学习率．但在刚开始训练时，由于参数是随机初始化的，梯度往往也比较大，再加上比较大的初始学习率，会使得训练不稳定。因此需要在开始阶段的学习率较小，之后再慢慢恢复(warmup)，warmup结束之后，可以使学习率再衰减\n其中为预热的迭代次数\n周期性学习率调整，包括循环学习率，热重启等，都是在一个周期内先上升后下降，整体是下降，这样能对付尖锐最小值和平坦最小值，找到局部最优解。\n自适应学习率调整\n学习率，为衰减率，的存在是为了防止分母为0Adagrad有学习率单调下降的问题RMSProp将的计算方式由累积变为指数衰减移动平均，学习率不再单调\n梯度优化Momentum其中为动量因子，一般取0.9，为学习率，参数更新每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值，当某个参数在最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小（训练末期）；相反，当在最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用（训练初期）。\nNesterov加速梯度应付唐朝刚的容易引起误解的版本：真正的版本：二者的不同在于：Momentum使用的是点的梯度，NAG使用的是点的梯度。Nesterov一步走完Momentum两步走的路，因此是“加速”。\nAdamAdam ≈ RMSProp + Momentum\n\n先计算两个移动平均\n偏差修正\n更新\n\n梯度截断阈值截断按模截断\n参数初始化\n预训练\n随机初始化\n高斯分布（正态）\n均匀分布\n\n\n固定值初始化\n\n数据预处理数据归一化最大最小值归一化 Max-min Normalization标准化 Standardization白化与PCA经过白化处理，特征之间的相关性较低，所有特征具有相同的方差。一个主要的实现方式是PCA\n批量归一化与层归一化计算是这么计算，不过对象不同：批量归一化在不同样本间做，层归一化在同一样本内做。批量归一化是不同训练数据之间对单个神经元的归一化，层归一化是单个训练数据对某一层所有神经元之间的归一化\n\n\n\n\n\n\n\n\n\n题目习题7-8 分析为什么批量归一化不能直接应用于循环神经网络．\n解答层归一化是可以用于RNN的，如下显示二者的区别 \n\n批量归一化是对一个中间层的单个神经元进行归一化操作，因此要求小批量样本的数量不能太小，否则难以计算单个神经元的统计信息（样本太少没有统计学上的意义）\n如果一个神经元的净输入的分布在神经网络中是动态变化的（如RNN），那么就无法应用批量归一化操作\n层归一化是对一个中间层的所有神经元进行归一化， RNN可以用层归一化\n\n\n\n\n\n\n\n\n\n\n题目 参考公式如下 \n解答\n𝑓(BN(𝑾𝒂(𝑙−1) + 𝒃)) 表示线性计算之后、非线性激活之前（即净输入 𝒛(𝑙)）进行 批归一化\n𝑓(𝑾BN(𝒂(𝑙−1)) + 𝒃) 表示上一层的输出，即当前层线性计算之前进行 批归一化\n\n使用第一种批归一化方式，可以避免线性计算对分布的改变\nDropout丢弃法：当训练一个深度神经网络时， 我们可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合。在训练时，激活神经元的平均数量为原来的𝑝 倍．而在测试时，所有的神经元都是可以激活的，这会造成训练和测试时网络的输出不一致．为了缓解这个问题，在测试时需要将神经层的输入𝒙 乘以𝑝，也相当于把不同的神经网络做了平均．保留率𝑝 可以通过验证集来选取一个最优的值．一般来讲，对于隐藏层的神经元，其保留率𝑝 = 0.5 时效果最好，这对大部分的网络和任务都比较有效．当𝑝 = 0.5 时，在训练时有一半的神经元被丢弃，只剩余一半的神经元是可以激活的，随机生成的网络结构最具多样性．对于输入层的神经元，其保留率通常设为更接近1 的数，使得输入变化不会太大．对输入层神经元进行丢弃时，相当于给数据增加噪声，以此来提高网络的鲁棒性．\n\n\n\n\n\n\n\n\n\n这张PPT还是错的，邱锡鹏书上是个子网络，他抄过来就变成2n了😅\n贝叶斯的解释的意思是：丢弃法是对参数的采样。\n变分丢弃法：Dropout应用到RNN上，不应该对循环连接进行丢弃，而应该对非循环连接随机丢弃。对参数矩阵的每个元素进行随机丢弃，并在所有的时刻使用相同的丢弃掩码。\n\n\n\n\n\n\n\n\n\n试分析为什么不能在循环神经网络中的循环连接上直接应用丢弃法？    对每个时刻的隐状态进行随机丢弃，会损坏循环网络在时间维度上的记忆能力.\n9. 深度强化学习五要素强化学习的基本要素包括：\n\n状态𝑠 是对环境的描述，可以是离散的或连续的，其状态空间为𝒮．\n动作𝑎 是对智能体行为的描述，可以是离散的或连续的，其动作空间为𝒜．\n策略𝜋(𝑎|𝑠) 是智能体根据环境状态𝑠 来决定下一步动作𝑎 的函数．（状态到动作的映射）\n状态转移概率𝑝(𝑠′|𝑠, 𝑎) 是在智能体根据当前状态𝑠 做出一个动作𝑎 之后，环境在下一个时刻转变为状态𝑠′ 的概率．\n即时奖励𝑟(𝑠, 𝑎, 𝑠′) 是一个标量函数，即智能体根据当前状态𝑠 做出动作𝑎 之后，环境会反馈给智能体一个奖励，这个奖励也经常和下一个时刻的状态𝑠′ 有关．\n\n马尔科夫过程马尔可夫过程（Markov Process）是一组具有马尔可夫性质的随机变量序列$𝑠0, 𝑠_1, ⋯，𝑠_𝑡 ∈ 𝒮，其中下一个时刻的状态𝑠{𝑡+1}只取决于当前状态𝑠𝑡，$𝑝(𝑠{𝑡+1}|𝑠𝑡, ⋯ , 𝑠_0) = 𝑝(𝑠{𝑡+1}|𝑠_{t}),$$马尔可夫决策过程在马尔可夫过程中加入一个额外的变量：动作，下一个时刻的状态 不但和当前时刻的状态$𝑠𝑡相关，而且和动作𝑎_𝑡相关，$𝑝(𝑠{𝑡+1}|𝑠𝑡,a_t, ⋯ , 𝑠_0,a_0) = 𝑝(𝑠{𝑡+1}|𝑠_{t},a_t),$$其中为状态转移概率。\n\n\n\n\n\n\n\n\n\n⻢尔科夫过程中不存在动作和奖励，马尔可夫决策过程则考虑动作与回报\n给定策略，马尔可夫决策过程的一个轨迹（Trajectory）$$\\tau  = 𝑠0, 𝑎_0, 𝑠_1, 𝑟_1, 𝑎_1, ⋯ , 𝑠{𝑇−1}, 𝑎_{𝑇−1}, 𝑠_{𝑇 }, 𝑟𝑇得到这个轨迹的概率为：p(\\tau )=  p(s_0)\\prod{t=0}^{T-1}\\pi(a|s)p(s_{t+1}|s_{t},a_{t})如果环境没用终止状态，整个轨迹的回报为：G(\\tau ) = \\sum\\limits_{t=0}^{T-1}\\gamma^tr_{t+1}$$其中 是折扣率，当 接近于0 时，智能体更在意短期回报；而当 接近于1 时，长期回报变得更重要. 计算时如无特殊说明，取 .强化学习的目标函数就是使回报的期望最大.\n基于值函数的学习方法状态值函数：从状态开始，执行策略得到的回报的期望\n$$V^{\\pi}(s) =\\mathbb E{{\\tau \\sim p(\\tau)} }{[\\sum\\limits{t=0}^{T-1}\\gamma^{t}r_{t+1}\\vert \\tau_{s_{0}}= s]}$$\n一个策略的期望回报为（所有可能轨迹的期望、从s能到达的所有状态值的期望）$$\\mathbb E{\\tau}{[G(\\tau)]} = \\mathbb E{{s\\sim p(s_0)}}[V^{\\pi}(s)]$$向转移，有贝尔曼方程，$$V^{\\pi}(s) = \\mathbb E{{a\\sim\\pi(a|s) }}\\mathbb E{{s’\\sim p(s’|s,a) }}[r(s,a,s^\\prime)+\\gamma V^{\\pi}{(s^{\\prime})}]=\\sum\\limits_{a\\in A}\\pi(a|s)(R_{s}^{a}+{\\gamma}\\sum\\limits_{s’\\in S}P_{ss’}^{a}V^{\\pi}(s’))$$想象一个马尔科夫链，方便记忆这个公式. 里面的是策略，也就是在状态下，采取的动作的概率分布，是状态可能到达的状态的概率分布.\nQ函数：再详细一些，状态采取动作，然后执行策略得到的期望总回报：$$Q^{\\pi}(s,a) = \\mathbb E{{s’\\sim p(s’|s,a) }}[r(s,a,s^\\prime)+\\gamma V^{\\pi}{(s^{\\prime})}]=\\sum\\limits{s’\\in S}P_{ss’}^{a}(R_s^a+\\gamma V^{\\pi}{(s^{\\prime})})$$相当于是把贝尔曼方程中，采取的动作给定下来了. 状态值函数是Q 函数 关于动作𝑎 的期望，即 ，代入上式，得到Q函数的贝尔曼方程：\n动态规划方法这两种方法都是基于模型的强化学习（模型相关的强化学习），模型是马尔可夫决策过程（MDP）.两点限制：\n\n要求模型已知，即要给出马尔可夫决策过程的状态转移概率𝑝(𝑠′|𝑠, 𝑎)和奖励函数𝑟(𝑠, 𝑎, 𝑠′)．但实际应用中这个要求很难满足（对策：随机游走探索环境）\n状态空间大，效率极低（对策：神经网络近似计算V（深度置信Q网络））\n\n策略迭代策略迭代包含策略评估(计算)和策略改进（简单贪心）两部分.\n值迭代相当于是只迭代，策略不迭代，直接在最后生成.\n蒙特卡罗方法蒙特卡罗（采样）方法：状态转移概率𝑝(𝑠′|𝑠, 𝑎)和奖励函数𝑟(𝑠, 𝑎, 𝑠′)未知，MDP模型崩塌（模型无关的强化学习），需要通过采样来计算Q函数.$$Q^{\\pi}(s,a) = \\frac{1}{N}\\sum\\limits_{n=1}^{N}G(\\tau^{n}{s_0=s,a{0=a}})$$Q函数通过N次实验轨迹的平均回报来近似。 贪心法：以的概率（很小）来选择中的其它动作，每个动作被选择的概率为 \n时序差分法是一种同策略方法。蒙特卡罗方法需要一条完整的路径才能知道其总回报，也不依赖马尔可夫性质；而时序差分学习方法只需要一步，其总回报需要通过马尔可夫性质来进行近似估计．\nQ-Learning是异策略的时序差分法。与SARSA 算法不同，Q学习算法不通过来选下一步的动作，而是直接选最优的Q 函数，因此更新后的Q函数是关于策略 的，而不是策略的．\n演员评论家\n10. 20级真题问答题\n1. CNN计算输入图片97*97*3，15个9*9的滤波器，无0填充，滑动步长为2.(1) 计算输出图像的尺寸 (5分)(2) 该卷积层的参数量(5分)(3)CNN的特点(5分)\n2.自注意力机制······ChatCPT·····马斯克·······危险的AI······(1)  自注意力的模式结构图 （5分）(2) 如果使用点积计算相似度，给出自注意力的完整计算过程 （10分）\n3.解释定理分别解释没有免费午餐定理和丑小鸭定理 （10分）\n4. 优化算法阐述动量法和Nesterov加速梯度(10分)\n5. 优化算法解释高低维度下，参数优化的难点与侧重点(10分)\n简答题\n描述SGD算法，并写出优缺点 （10分）\nLSTM是对RNN的改进，能否解决梯度消失与梯度爆炸问题，请阐述原理(15分)\n\n论述题….小鹏汽车G6自动驾驶很厉害….假如你是小鹏的算法工程师，请利用深度强化学习对小鹏汽车的人机对话系统建模，列举强化学习的五要素，并给出最大化奖励函数的算法。(15分)\n\n\n\n\n\n\n\n\n\n没错，深度强化学习的对话系统；\n","slug":"深度学习复习课","date":"2023-06-21T06:59:17.000Z","categories_index":"机器学习","tags_index":"学习笔记,机器学习,深度学习","author_index":"以太工坊"},{"id":"1edf4b27ac34894917406de57f8d4782","title":"计算机复试常见问题整理","content":"本文非原创，转载自csdn一匹好人呀 \n写在前面：在准备面试的过程中，专业课复习是必不可少的一步。大家可以先下载计算机保研 / 考研复试面试常问问题进行复习，下面是我在准备面试的过程中额外收集整理的一些问题，word版可以点击这里获取。 再分享一个之前收藏的【保研记录】预推免面试可能遇到的问题(偏计算机)，各取所需。\n1. 软件工程和计算机有什么区别？\n基础课程重复度较高。+ 计算机偏学术研究，软件工程偏工程实践。一般来说计算机的学习偏重学习计算机的原理。学习偏理论，学习内容涉及软件也涉及硬件。软件工程，简称 (SE)。SE 的学习主要是围绕着软件的应用、设计、开发、维护架构这几个模块等，偏应用、工程、实践，学习内容涉及一些基本的硬件，但更多是工程的理论和大量的软件实践知识。+ 软件工程培养计划里面一般有项目管理，架构，测试等科目。\n\n2. 算法的基本特征和复杂度（1）基本特征  输入、输出、有穷性、确定性、可行性\n（2）算法的复杂度  时间复杂度、空间复杂度\n3. 用循环比递归效率高吗？  递归和循环两者完全可以互换。不能完全决定性地说循环地效率比递归的效率高。\n（1）递归算法\n优点：代码简洁、清晰，并且容易验证正确性。 +  缺点：它的运行需要较多次数的函数调用，如果调用层数比较深，需要增加额外的堆栈处理（还有可能出现堆栈溢出的情况），比如参数传递需要压栈等操作，会对执行效率有一定影响。但是，对于某些问题，如果不使用递归，那将是极端难看的代码。在编译器优化后，对于多次调用的函数处理会有非常好的效率优化，效率未必低于循环。\n\n（2）循环算法\n优点：速度快，结构简单。 +  缺点：并不能解决所有的问题。有的问题适合使用递归而不是循环。如果使用循环并不困难的话，最好使用循环。\n\n4. P问题、NP问题、NP完全问题的概念1) P (polynominal) 问题 - 多项式问题\n存在多项式时间算法的问题。\n\n2) NP (Nondeterministic Polynominal) 问题 - 非确定多项式问题\n能在多项式时间内验证得出一个正确解的问题。 +  关于 P 是否等于 NP 是一个存在了很久的问题，这里不做讨论。 +  通俗的理解这两个问题的话：在借助计算机的前提下，P 问题很容易求解；NP 问题不容易求解，但对于某一答案我们可以很快验证这个答案是否正确。\n\n举例：\n\n最简单，最基本的：枚举集合  的所有子集的问题 +  旅行推销员问题 +   皇后问题 +  背包问题（是一种组合优化的 NP 完全问题。问题可以描述为：给定一组物品，每种物品都有自己的重量和价格，在限定的总重量内，我们如何选择，才能使得物品的总价格最高。问题的名称来源于如何选择最合适的物品放置于给定背包中。）\n\n3) NPH (Nondeterminism Polynomial Hard) 问题 - NP难问题\n它不一定是一个 NP 问题 +  其他属于 NP 的问题都可在多项式时间内归约成它。通俗理解，NP 难问题是比所有 NP 问题都难的问题。\n\n4) NPC (Nondeterminism Polynomial Complete) 问题 - NP 完全问题\n它是一个 NP 问题 +  其他属于 NP 的问题都可在多项式时间内归约成它。 +  通俗理解，NP 完全问题是介于 NP 问题和 NP 难问题之间的一类问题。\n\n     各问题的关系\n5. 几种树（1）二叉搜索树 (Binary Search Tree)  二叉搜索树满足的条件：\n\n非空左子树的所有键值小于其根节点的键值+ 非空右子树的所有键值大于其根节点的键值\n左右子树都是二叉搜索树\n\n（2）AVL 树 (Self-balancing Binary Search Tree)  AVL 树又称为高度平衡的二叉搜索树。一棵 AVL 树或者是空树，或者是具有下列性质的二叉搜索树：它的左子树和右子树都是 AVL 树，且左子树和右子树的高度之差的绝对值不超过 1。\n（3）红黑树 (Red-Black Tree)  红黑树是这样的一棵二叉搜索树：数中的每一个结点的颜色不是黑色就是红色。可以把一棵红黑树视为一棵扩充二叉树，用外部结点表示空指针。其特性描述如下：\n\n特性1：根结点和所有外部结点的颜色是黑色。\n特性2：从根结点到外部结点的途中没有连续两个结点的颜色是红色。\n特性3：所有从根到外部结点的路径上都有相同数的黑色结点。\n\n  从红黑树中任一结点  出发（不包括结点 ），到达一个外部结点的任一路径上的黑结点个数叫做结点  的黑高度，亦称为结点的阶（rank），记作 。红黑树的高度定义为其根结点的黑高度。\n  对普通二叉搜索树进行搜索的时间复杂度为 ，对于红黑树则为 。\n（4）B 树（特例：2-3树、2-3-4树）  一棵  阶 B 树 (balanced tree of order m) 是一棵平衡的  路搜索树，它或者是空树，或者是满足下列性质的树：\n\n根结点至少有两个子女。\n除根结点以外的所有结点（不包括失败节点）至少有  个子女。\n所有的失败结点都位于同一层。\n\n（5）B+ 树  B+ 树是 B 树的一个升级版，B+ 树是 B树 的变种树，有  棵子树的节点中含有  个关键字，每个关键字不保存数据，只用来索引，数据都保存在叶子节点。是为文件系统而生的。\n  相对于 B 树来说 B+ 树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。   \n\n特点：在 B 树的基础上每个节点存储的关键字数更多，树的层级更少所以查询数据更快，所有指关键字指针都存在叶子节点，所以每次查找的次数都相同所以查询速度更稳定。 \n应用场景： 用在磁盘文件组织 数据索引和数据库索引。\n\n（6）Trie 树（字典树）  Trie，又称前缀树，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。   \n6. 邻接矩阵与邻接表\n邻接矩阵表示法：在一个一维数组中存储所有的点，在一个二维数组中存储顶点之间的边的权值。 +  邻接表表示法：图中顶点用一个一维数组存储，图中每个顶点  的所有邻接点构成单链表。\n\n对比\n\n在邻接矩阵表示中，无向图的邻接矩阵是对称的。矩阵中第  行或第  列有效元素个数之和就是顶点的度。在有向图中第  行有效元素个数之和是顶点的出度，第  列有效元素个数之和是顶点的入度。 +  在邻接表的表示中，无向图的同一条边在邻接表中存储的两次。如果想要知道顶点的度，只需要求出所对应链表的结点个数即可。有向图中每条边在邻接表中只出现一次，求顶点的出度只需要遍历所对应链表即可。求入度则需要遍历其他顶点的链表。 +  邻接矩阵与邻接表优缺点 · 邻接矩阵的优点是可以快速判断两个顶点之间是否存在边，可以快速添加边或者删除边。而其缺点是如果顶点之间的边比较少，会比较浪费空间。因为是一个  的矩阵。 · 邻接表的优点是节省空间，只存储实际存在的边。其缺点是关注顶点的度时，就可能需要遍历一个链表。\n\n7. 最小生成树 (Minimum Spanning Tree, MST)  一个有  个结点的连通图的生成树是原图的极小连通子图，且包含原图中的所有  个结点，并且有保持图连通的最小权值的边。最小生成树可以用 Kruskal（克鲁斯卡尔）算法或 Prim（普里姆）算法求出。\n（1）Kruskal（克鲁斯卡尔）算法  此算法可以称为“加边法”，初始最小生成树边数为 ，每迭代一次就选择一条满足条件的最小代价边，加入到最小生成树的边集合里。\n  针对边展开，稀疏图有优势。   \n（2）Prim（普里姆）算法  此算法可以称为“加点法”，每次迭代选择代价最小的边对应的点，加入到最小生成树中。算法从某一个顶点s开始，逐渐扩大到覆盖整个连通网的所有顶点。\n  针对顶点展开，稠密图有优势。   \n8. 最短路径算法 (Shortest Path Algorithm)（1）Dijkstra 算法——从某一源点到其余各顶点的最短路径，  算法特点：\n\n每次找出前一次迭代后具有最低费用的节点，添加到集合中。\n第  次迭代后，可以知道源点到  个目的节点的最低费用路径。\n\n（2）Floyd 算法——每一对顶点之间的最短路径，  基本思想：最开始只允许经过1号顶点进行中转，接下来只允许经过 号和  号顶点进行中转…允许经过  号所有顶点进行中转，来不断动态更新任意两点之间的最短路程。即求从  号顶点到  号顶点只经过前  号点的最短路程。\n（3）深度或广度优先搜索算法（解决单源最短路径）9. 深度优先搜索（Depth-First-Search, DFS）和广度优先搜索（Breadth-First-Search, BFS）（1）深度优先搜索（DFS）  深度优先搜索在搜索过程中访问某个顶点后，需要递归地访问此顶点的所有未访问过的相邻顶点。\n  初始条件下所有节点为白色，选择一个作为起始顶点，按照如下步骤遍历：\n\n选择起始顶点涂成灰色，表示还未访问。+ 从该顶点的邻接顶点中选择一个，继续这个过程（即再寻找邻接结点的邻接结点），一直深入下去，直到一个顶点没有邻接结点了，涂黑它，表示访问过了。+ 回溯到这个涂黑顶点的上一层顶点，再找这个上一层顶点的其余邻接结点，继续如上操作，如果所有邻接结点往下都访问过了，就把自己涂黑，再回溯到更上一层。+ 上一层继续做如上操作，直到所有顶点都访问过。\n\n（2）广度优先搜索（BFS）  广度优先搜索在进一步遍历图中顶点之前，先访问当前顶点的所有邻接结点。\n\n首先选择一个顶点作为起始结点，并将其染成灰色，其余结点为白色。+ 将起始结点放入队列中。+ 从队列首部选出一个顶点，并找出所有与之邻接的结点，将找到的邻接结点放入队列尾部，将已访问过结点涂成黑色，没访问过的结点是白色。如果顶点的颜色是灰色，表示已经发现并且放入了队列，如果顶点的颜色是白色，表示还没有发现。+ 按照同样的方法处理队列中的下一个结点。 基本就是出队的顶点变成黑色，在队列里的是灰色，还没入队的是白色。\n\n10. 并查集 (Union-Find Set)  并查集顾名思义就是有“合并集合”和“查找集合中的元素”两种操作的关于数据结构的一种算法。\n  并查集，在一些有  个元素的集合应用问题中，我们通常是在开始时让每个元素构成一个单元素的集合，然后按一定顺序将属于同一组的元素所在的集合合并，其间要反复查找一个元素在哪个集合中。\n  并查集是一种树形的数据结构，用于处理一些不相交集合（Disjoint Sets）的合并及查询问题。\n  并查集也是使用树形结构实现。不过，不是二叉树。每个元素对应一个节点，每个组对应一棵树。在并查集中，哪个节点是哪个节点的父亲以及树的形状等信息无需多加关注，整体组成一个树形结构才是重要的。类似森林。\n11. 什么是稳定性排序？为什么排序要稳定？  如果两个具有相同键的对象以相同的顺序出现在排序输出中，则排序算法是稳定的。（假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，，且  在  之前，而在排序后的序列中， 仍在  之前，则称这种排序算法是稳定的；否则称为不稳定的。）\n  稳定性的好处：排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。 基数排序就是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。\n12. 冒泡排序  冒泡排序顾名思义就是整个过程像气泡一样往上升，单向冒泡排序的基本思想是（假设由小到大排序）：对于给定  个记录，从第一个记录开始依次对相邻的两个记录进行比较，当前面的记录大于后面的记录时，交换位置，进行一轮比较和换位后， 个记录的最大记录将位于第  位，然后对前  个记录进行第二轮比较；重复该过程，直到记录剩下一个为止。\n13. 快速排序算法（1）请你介绍一下快排算法  根据哨兵元素，用两个指针指向待排序数组的首尾，首指针从前往后移动找到比哨兵元素大的，尾指针从后往前移动找到比哨兵元素小的，交换两个元素，直到两个指针相遇，这是一趟排序，经常这趟排序后，比哨兵元素大的在右边，小的在左边。经过多趟排序后，整个数组有序。\n\n稳定性：不稳定 +  平均时间复杂度：\n\n（2）简述快速排序过程\n选择一个基准元素，通常选择第一个元素或者最后一个元素。 +  通过一趟排序将待排序的记录分割成独立的两部分，其中一部分记录的元素值均比基准元素值小，另一部分记录的元素值均比基准元素值大。 +  此时基准元素在其排好序后的正确位置。 +  然后分别对这两部分记录用同样的方法继续进行排序，直到整个序列有序。\n\n（3）快排是稳定的吗？  快排算法是不稳定的排序算法。例如：待排序数组：int a[] ={1, 2, 2, 3, 4, 5, 6}；\n\n若选择 （即数组中的第二个 ）为枢轴，而把大于等于比较子的数均放置在大数数组中，则 （即数组中的第一个 ）会到  的右边，那么数组中的两个  非原序。+ 若选择  为比较子，而把小于等于比较子的数均放置在小数数组中，则数组中的两个  顺序也非原序。\n\n（4）快排算法最差情况推导公式  在快速排序的早期版本中呢，最左面或者是最右面的那个元素被选为枢轴，那最坏的情况就会在下面的情况下发生啦：\n\n数组已经是正序排过序的。 （每次最右边的那个元素被选为枢轴） +  数组已经是倒序排过序的。 （每次最左边的那个元素被选为枢轴） +  所有的元素都相同（1、2的特殊情况）\n\n  因为这些案例在用例中十分常见，所以这个问题可以通过要么选择一个随机的枢轴，或者选择一个分区中间的下标作为枢轴，或者（特别是对于相比更长的分区）选择分区的第一个、中间、最后一个元素的中值作为枢轴。有了这些修改，那快排的最差的情况就不那么容易出现了，但是如果输入的数组最大（或者最小元素）被选为枢轴，那最坏的情况就又来了。\n  快速排序，在最坏情况退化为冒泡排序，需要比较  次（ 次）。\n（5）其他关于快速排序的知识  以从小到大为例：快速排序的基本思想是任取待排序序列的一个元素作为中心元素(可以用第一个，最后一个，也可以是中间任何一个)，习惯将其称为 ，枢轴元素；将所有比枢轴元素小的放在其左边，将所有比它大的放在其右边，形成左右两个子表；然后对左右两个子表再按照前面的算法进行排序，直到每个子表的元素只剩下一个。\n  可见快速排序用到了分而治之的思想。\n  将一个数组分成两个数组的方法为：先从数组右边找到一个比枢轴元素小的元素，将数组的第一个位置赋值为该元素；再从数组的左边找到一个比枢轴元素大的元素，将从上面取元素的位置赋值为该值；依次进行，直到左右相遇，把枢轴元素赋值到相遇位置。\n  快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。因此总的比较和交换次数就少了，速度自然就提高了。当然在最坏的情况下，仍可能是相邻的两个数进行了交换。因此快速排序的最差时间复杂度和冒泡排序是一样的都是 ，它的平均时间复杂度为 。\n（6）解释下快排为什么快？不要说快排的什么复杂度或者算法过程，回答为什么快。（这问题我蒙蔽的一匹，最后听老师意思是说从存储中内存和硬盘读取数据频率那里谈，莫非是数据量太大的时候其他排序涉及到外排序、快排二分几次后就避免了外排序的硬盘交互问题？？）（7）归并排序的最坏时间复杂度优于快排，为什么我们还是选择快排？\n快排查找的常量要比归并小。 +  绝大多数情况下，快排遇到的都是平均情况，也就是最佳情况，只有极个别的时候会是最坏情况，因此往往不考虑这种糟糕的情况。\n\n或：\n\nC++ 模板有很强的 inline 优化机制，比较操作相对于赋值（移动）操作要快的多（尤其是元素较大时） +  另一方面，一般情况下，归并排序的比较次数小于快速排序的比较次数，而移动次数一般多于快速排序的移动次数，二者大约都是 2~3 倍的差距。\n\n  因为这样，在 C++ 中快排要比归并排序更快，但其实在 Java 中恰恰相反，移动（赋值）一般比比较快。\n14. 快速排序和归并排序的优缺点1) 快速排序的优缺点\n优点：快，平均性能好，时间复杂度为 。 +  缺点：不稳定，初始序列有序或基本有序时，时间复杂度降为 。\n\n2) 归并排序的优缺点\n优点：快，时间复杂度为 ；是一种稳定的算法；是最常用的外部排序算法（当待排序的记录放在外存上，内存装不下全部数据时，归并排序仍然适用，当然归并排序同样适用于内部排序）。 +  缺点：空间复杂度高（需要  的辅助空间）。\n\n15. 插入排序（1）基本思想  每一步将一个待排序的数据插入到前面已经排好序的有序序列中，直到插完所有元素为止。\n  插入排序的工作方式像许多人排序一手扑克牌。开始时，我们的左手为空并且桌子上的牌面向下。然后，我们每次从桌子上拿走一张牌并将它插入左手中正确的位置。为了找到一张牌的正确位置，我们从右到左将它与已在手中的每张牌进行比较。拿在左手上的牌总是排序好的，原来这些牌是桌子上牌堆中顶部的牌。\n  插入排序是指在待排序的元素中，假设前面 (其中 )个数已经是排好顺序的，现将第  个数插到前面已经排好的序列中，然后找到合适自己的位置，使得插入第  个数的这个序列也是排好顺序的。按照此法对所有元素进行插入，直到整个序列排为有序的过程，称为插入排序。\n（2）复杂度  插入排序的平均时间复杂度也是 ，空间复杂度为常数阶 ，具体时间复杂度和数组的有序性也是有关联的。\n16. 希尔排序 (Shell sort)  希尔排序 (Shell’s Sort) 是插入排序的一种又称“缩小增量排序”（Diminishing Increment Sort），是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。\n  它通过比较相距一定间隔的元素来进行，各趟比较所用的距离随着算法的进行而减小，直到只比较相邻元素的最后一趟排序为止。\n  基本思想：希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。\n17. 选择排序（1）基本思想  找到当前数字序列中最大（最小）的数，记录其所在位置，将其和最前面（最后面）的数进行交换，使最大（最小）的元素上浮（下沉）到本次排序的最前面（最后面），从而完成一趟(pass)排序。下一趟排序时，已经有序的元素不再参与。这样的话， 个元素需要进行  趟排序！！！\n（2）举个例子   个数字  进行从大到小的排序。\n\n第一趟：参与数字序列： · 找到该数字序列中最大的数 7，记录其所在位置，将其和第一个位置的数 4 进行比较，7 大于 4，所以 7 和 4 交换，得到新的序列  · 经过第一趟的排序，使数字序列中最大的数 7 上浮到最前面，此时7属于有序的元素，不需要参与到下一趟的排序。 +  第二趟排序：参与数字序列： · 找到该数字序列中最大的数 6，记录其所在位置，将其和第一个位置的数 6 进行比较，6 等于 6，不需要交换，得到新的序列  · 经过第二趟的排序，使数字序列中第二大的数 6 上浮到第二个前面，此时 7, 6 属于有序的元素，不需要参与到下一趟的排序。 +  第三趟排序：参与数字序列  · 找到该数字序列中最大的数 5，记录其所在位置，将其和第一个位置的数4进行比较，5 大于 4，所以 5 和 4 交换，得到新的序列  · 经过第三趟的排序，使数字序列中第三大的数 5 上浮到第三个前面，此时 7, 6, 5 属于有序的元素，不需要参与到下一趟的排序。 +  最后就剩下一个数 4，就不需要进行排序，排序最终得到的数字序列为：。\n\n（3）选择排序的关键点\n采用双层循环：时间复杂度是  · 外层循环表示的是排序的趟数， 个数字需要  趟，因此，外层循环的次数是  次；同时也代表数的位置。 · 内层循环表示的是每一趟排序的数字。根据选择排序的思想，第  趟排序时，最前面的位置就是 ，用一个循环来不断更新。 +  找到最值数的位置，将该位置的数和当前序列最前面（最后面）位置的数进行交换。（稳定排序）\n\n18. 堆排序（1）堆排序的基本思路\n将无序序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆（一般升序采用大顶堆，降序采用小顶堆）。+ 将堆顶元素与末尾元素交换，将最大元素”沉”到数组末端。+ 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整 + 交换步骤，直到整个序列有序。\n\n（2）堆的操作  在堆的数据结构中，堆中的最大值总是位于根节点（在优先队列中使用堆的话堆中的最小值位于根节点）。堆中定义以下几种操作：\n\n最大堆调整（Max Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点。+ 创建最大堆（Build Max Heap）：将堆中的所有数据重新排序。+ 堆排序（HeapSort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算。\n\n（3）堆排序的优缺点\n比快速排序的优点：在最坏情况下它的性能很优越。 +  比归并排序的优点：使用的辅助存储少。 +  缺点：不适合太小的待排序列（因为需要建堆）；不稳定，不适合对象的排序。\n\n19. 计数排序 (Counting Sort)  计数排序，不是基于元素比较，而是利用数组下标确定元素的正确位置。\n  计数排序是一个非基于比较的排序算法。它的优势在于在对一定范围内的整数排序时，它的复杂度为 （其中  是整数的范围），快于任何比较排序算法。当然这是一种牺牲空间换取时间的做法，而且当  的时候其效率反而不如基于比较的排序（基于比较的排序的时间复杂度在理论上的下限是 ，如归并排序，堆排序）。计数排序是一个稳定的排序算法。\n20. 介绍下桶散列21. 桶排序 (Bucket sort)（1）基本思想：划分多个范围相同的区间，每个子区间自排序，最后合并  桶排序是将待排序集合中处于同一个值域的元素存入同一个桶中，也就是根据元素值特性将集合拆分为多个区域，则拆分后形成的多个桶，从值域上看是处于有序状态的。对每个桶中元素进行排序，则所有桶中元素构成的集合是已排序的。\n（2）算法过程\n根据待排序集合中最大元素和最小元素的差值范围和映射规则，确定申请的桶个数； \n遍历待排序集合，将每一个元素移动到对应的桶中； \n对每一个桶中元素进行排序，并移动到已排序集合中。\n\n  \n22. 基数排序 (Radix Sort)  基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。\n  基数排序（radix sort）属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort）或 bin sort，顾名思义，它是透过键值的部份资讯，将要排序的元素分配至某些“桶”中，藉以达到排序的作用，基数排序法是属于稳定性的排序，其时间复杂度为 ，其中r为所采取的基数，而  为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。\n  基数排序的方式可以采用 LSD（Least significant digital）或 MSD（Most significant digital），LSD 的排序方式由键值的最右边开始，而 MSD 则相反，由键值的最左边开始。   \n  基数排序是一种稳定的排序算法，但有一定的局限性：\n\n关键字可分解。+ 记录的关键字位数较少，如果密集更好。+ 如果是数字时，最好是无符号的。\n\n23. 基数排序 vs 计数排序 vs 桶排序  这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异：\n\n基数排序：根据键值的每位数字来分配桶。\n计数排序：每个桶只存储单一键值。\n桶排序：每个桶存储一定范围的数值。\n\n24. 各类排序算法对比  \n（1）时间复杂度\n平方阶  排序 —— 各类简单排序：直接插入、直接选择和冒泡排序 \n线性对数阶  排序 —— 快速排序、堆排序和归并排序 +  § 排序，§ 是介于 0 和 1 之间的常数 —— 希尔排序  \n线性阶  排序 —— 基数排序，此外还有桶、箱排序\n\n说明：\n\n当原表有序或基本有序时，直接插入排序和冒泡排序将大大减少比较次数和移动记录的次数，时间复杂度可降至 。\n而快速排序则相反，当原表基本有序时，将蜕化为冒泡排序，时间复杂度提高为 。\n原表是否有序，对简单选择排序、堆排序、归并排序和基数排序的时间复杂度影响不大。\n\n（2）稳定性  排序算法的稳定性：若待排序的序列中，存在多个具有相同关键字的记录，经过排序，这些记录的相对次序保持不变，则称该算法是稳定的；若经排序后，记录的相对次序发生了改变，则称该算法是不稳定的。\n\n稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序 +  不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序\n\n（3）选择排序算法准则  一般而言，需要考虑的因素有以下四点：\n  设待排序元素的个数为 .\n\n当 n 较大，则应采用时间复杂度为  的排序方法：快速排序、堆排序或归并排序。+ 当 n 较大，内存空间允许，且要求稳定性：归并排序。+ 当 n 较小，可采用直接插入或直接选择排序。 · 直接插入排序：当元素分布有序，直接插入排序将大大减少比较次数和移动记录的次数。 · 直接选择排序：元素分布有序，如果不要求稳定性，选择直接选择排序。+ 一般不使用或不直接使用传统的冒泡排序。\n\n25. 冒泡排序算法的改进\n设置一标志性变量 ，用于记录每趟排序中最后一次进行交换的位置。由于  位置之后的记录均已交换到位，故在进行下一趟排序时只要扫描到  位置即可。 +  传统冒泡排序中每一趟排序操作只能找到一个最大值或最小值，我们考虑利用在每趟排序中进行正向和反向两遍冒泡的方法一次可以得到两个最终值(最大值和最小值) , 从而使排序趟数几乎减少了一半。\n\n26. 快速排序的改进（1）只对长度大于  的子序列递归调用快速排序，让原序列基本有序，然后再对整个基本有序序列用插入排序算法排序  实践证明，改进后的算法时间复杂度有所降低，且当  取值为 8 左右时，改进算法的性能最佳。\n（2）选择基准元的方式  对于分治算法，当每次划分时，算法若都能分成两个等长的子序列时，那么分治算法效率会达到最大。也就是说，基准的选择是很重要的。选择基准的方式决定了两个分割后两个子序列的长度，进而对整个算法的效率产生决定性影响。最理想的方法是，选择的基准恰好能把待排序序列分成两个等长的子序列。\n[1] 方法1 固定基准元  如果输入序列是随机的，处理时间是可以接受的。如果数组已经有序时，此时的分割就是一个非常不好的分割。\n[2] 随机基准元  这是一种相对安全的策略。由于基准元的位置是随机的，那么产生的分割也不会总是会出现劣质的分割。在整个数组数字全相等时，仍然是最坏情况，时间复杂度是 。实际上，随机化快速排序得到理论最坏情况的可能性仅为 。所以随机化快速排序可以对于绝大多数输入数据达到 的期望时间复杂度。\n[3] 三数取中\n引入的原因：虽然随机选取基准时，减少出现不好分割的几率，但是还是最坏情况下还是 ，要缓解这种情况，就引入了三数取中选取基准。 +  分析：最佳的划分是将待排序的序列分成等长的子序列，最佳的状态我们可以使用序列的中间的值，也就是第  个数。可是，这很难算出来，并且会明显减慢快速排序的速度。这样的中值的估计可以通过随机选取三个元素并用它们的中值作为基准元而得到。事实上，随机性并没有多大的帮助，因此一般的做法是使用左端、右端和中心位置上的三个元素的中值作为基准元。\n\n27. 散列表（哈希表）查找（1）哈希表  哈希表（Hash table，也叫散列表），是根据关键码值 (Key value) 而直接进行访问的数据结构。\n（2）解决哈希冲突的方法  [1] 线性探测法   [2] 平方探测法   [3] 伪随机序列法   [4] 拉链法\n28. 哈希表除留取余法的桶个数为什么是质数？  除留取余，就是使用哈希函数将关键字被某个不大于哈希表长  的数  除后所得的余数作为哈希地址。如果散列值的因数越多，可能导致的散列分布越不均匀，所以在  的选择上需要选择约数少的数值，所以往往将桶个数设置为质数或不包含小于  的质因数的合数。\n29. 字符串的，模式匹配算法（1）BF算法（属于朴素的模式匹配算法）（2）KMP算法\n在一个字符串中查找是否包含目标的匹配字符串。其主要思想是每趟比较过程让子串向后滑动一个合适的位置。当发生不匹配的情况时，不是右移一位，而是移动（当前匹配的长度 - 当前匹配子串的部分匹配值）位。 +  核心：避免不必要的回溯。\n\n30. 贪心算法 vs 动态规划 vs 分治法  分治法，动态规划法，贪心算法这三者之间有类似之处，比如都需要将问题划分为一个个子问题，然后通过解决这些子问题来解决最终问题。\n（1）分治法  分治法（divide-and-conquer）：将原问题划分成 n 个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。\n  分治模式在每一层递归上都有三个步骤：\n\n分解（Divide）：将原问题分解成一系列子问题；+ 解决（Conquer）：递归地解各个子问题。若子问题足够小，则直接求解；+ 合并（Combine）：将子问题的结果合并成原问题的解。\n\n  合并排序（merge sort）是一个典型分治法的例子。其对应的直观的操作如下：\n\n分解：将 n 个元素分成各含 n/2 个元素的子序列；+ 解决：用合并排序法对两个子序列递归地排序；+ 合并：合并两个已排序的子序列以得到排序结果。\n\n（2）动态规划  动态规划算法的设计可以分为如下 4 个步骤：\n\n描述最优解的结构+ 递归定义最优解的值+ 按自底向上的方式计算最优解的值+ 由计算出的结果构造一个最优解\n\n   分治法是指将问题划分成一些独立的子问题，递归地求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子问题。 在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。\n  适合采用动态规划方法的最优化问题中的两个要素：最优子结构和重叠子问题。\n\n最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。 +  重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法课反复地解同样的子问题，而不是总在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。\n\n   分治法：各子问题独立     动态规划：各子问题重叠\n（3）贪心算法  贪心算法是使所做的选择看起来都是当前最佳的，期望通过所做的局部最优选择来产生出一个全局最优解。贪心算法对大多数优化问题来说能产生最优解，但也不一定总是这样的。\n  贪心算法与动态规划与很多相似之处。特别地，贪心算法适用的问题也是最优子结构。贪心算法与动态规划有一个显著的区别，就是贪心算法中，是以自顶向下的方式使用最优子结构的。贪心算法会先做选择，在当时看起来是最优的选择，然后再求解一个结果子问题，而不是先寻找子问题的最优解，然后再做选择。\n  贪心算法是通过做一系列的选择来给出某一问题的最优解。对算法中的每一个决策点，做一个当时看起来是最佳的选择。这一点是贪心算法不同于动态规划之处。在动态规划中，每一步都要做出选择，但是这些选择依赖于子问题的解。因此，解动态规划问题一般是自底向上，从小子问题处理至大子问题。贪心算法所做的当前选择可能要依赖于已经做出的所有选择，但不依赖于有待于做出的选择或子问题的解。因此，贪心算法通常是自顶向下地做出贪心选择，不断地将给定的问题实例归约为更小的问题。贪心算法划分子问题的结果，通常是仅存在一个非空的子问题。\n31. 求拓扑排序的几种方法32. 如何判断一个图是否有环？33. 给你 20G 的数据，在 3G 内存里进行排序，怎么操作？34. 堆和栈1) 程序内存的区域a) 栈区（stack）\n  由编译器自动分配释放 ，存放函数的参数值，局部变量的值等，内存的分配是连续的，类似于平时我们所说的栈，如果还不清楚，那么就把它想成数组，它的内存分配是连续分配的，即，所分配的内存是在一块连续的内存区域内．当我们声明变量时，那么编译器会自动接着当前栈区的结尾来分配内存。\nb) 堆区（heap）\n  一般由程序员分配释放， 若程序员不释放，程序结束时可能由操作系统回收。类似于链表，在内存中的分布不是连续的，它们是不同区域的内存块通过指针链接起来的。一旦某一节点从链中断开，我们要人为的把所断开的节点从内存中释放。\nc) 全局区（静态区）（static）\n  全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 程序结束后由系统释放。\nd) 文字常量区\n  常量字符串就是放在这里的。 程序结束后由系统释放。\ne) 程序代码区\n  存放函数体的二进制代码。   \n2) 堆和栈的区别\n概念 · 栈 stack：存放函数的参数值、局部变量，由编译器自动分配释放。 · 堆 heap：是由 new 分配的内存块，由应用程序控制，需要程序员手动利用 delete 释放，如果没有，程序结束后，操作系统自动回收。  2. 因为堆的分配需要使用频繁的 new/delete，造成内存空间的不连续，会有大量的碎片。 3. 堆的生长空间向上，地址越大，栈的生长空间向下，地址越小。\n\na) 申请方式不同\n\n栈：由系统自动分配。例如：在函数中定义一个局部变量 int a = 0; 系统会在栈上自动开辟相应大小。 注意：系统首先会去查看栈上是否有足够的区域去开辟该空间，如果有就直接开辟，如果没有则栈溢出。 +  堆：由程序员自己去申请开辟，并且指明大小。(利用 new/malloc)\n\nb) 申请大小的限制\n\n栈：在 Windows 下，栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在 Windows 下，栈的大小是 2M（也有的说是 1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示 overflow。因此，能从栈获得的空间较小。 +  堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。\n\nc) 申请效率的比较\n\n栈：由系统自动分配，速度较快。但程序员是无法控制的。 +  堆：是由 new/malloc 分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便。（new/malloc 后一定要显示的调用 free/delete 去释放内存）\n\n  另外，在 Windows 下，最好的方式是用 VirtualAlloc 分配内存，他不是在堆，也不是在栈，是直接在进程的地址空间中保留一快内存，虽然用起来最不方便。但是速度快，也最灵活。\nd) 堆和栈中的存储内容\n\n栈： 在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，在大多数的 C 编译器中，参数是由右往左入栈的，然后是函数中的局部变量。注意静态变量是不入栈的。 当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。 +  堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容由程序员安排。\n\ne) 底层不同\n\n栈：是连续的空间。 +  堆：不是连续的空间。\n\n  \n  请注意：在栈上所申请的内存空间，当我们出了变量所在的作用域后，系统会自动我们回收这些空间，而在堆上申请的空间，当出了相应的作用域以后，我们需要显式的调用 delete 来释放所申请的内存空间，如果我们不及时得对这些空间进行释放，那么内存中的内存碎片就越来越多，从而我们的实际内存空间也就会变的越来越少，即，孤立的内存块越来越多。在这里，我们知道，堆中的内存区域不是连续的，还是将有效的内存区域经过链表指针连接起来的，如果我们申请到了某一块内存，那么这一块内存区将会从连续的（通过链表连接起来的）内存块上断开，如果我们在使用完后，不及时的对它进行释放，那么它就会被孤立开来，由于没有任何指针指向它，所以这个区域将成为内存碎片，所以在使用完动态分配的内存（通过 new 申请）后，一定要显式的对它进行 delete 删除．对于这一点，一定要切记．．．\n35. 如何用栈实现汉诺塔问题？  汉诺塔实现的基本思路是：不断将  个盘的汉诺塔问题转换为  个  个盘的汉诺塔问题，用递归实现比较好理解。设  盘问题为 ，其中参数如下结构体所定义，第一个参数表示需要移动的盘子的数量，第二个参数表示  个盘子起始所在柱子 ，第三个参数表示会被借用的柱子 ，第四个参数表示这  个盘子所在的目标柱子 。\n1) 递归思路  假设  表示把  柱子上的  个盘借助  柱子移动到  柱子上，这个问题的递归求解方式是：\n\n先把  柱子的  盘子借助  柱子移动到  柱子上 ,+ 然后把  柱子剩下的一个盘子移动到  柱子上 ，+ 最后把  柱子上的  个盘子移动到  柱子上 .\n\n  则问题求解可转换为对 、、 这三个问题的求解，其中  不需要递归，可直接实现，将  个盘的汉诺塔问题转换为  个  个盘的汉诺塔问题，然后使用递归将  盘问题转换成  盘问题，直到盘数为 。\n2) 非递归的方式  使用  个栈模拟  个塔，每一步的移动，都按照真实情况进行。\n  递归方式本质上使用栈来实现的，所以如果采用非递归的方式也是使用栈来辅助实现。\n  但是若是用堆栈来实现的话，当将分解出的上述三个问题压入栈时，应该按照“需要先求解的问题后压入”的顺序，也就是压入顺序为：.\nbashtypedef struct {　　//汉诺塔问题的结构类型\n    int N;\n    char A;        //起始柱\n    char B;        //借助柱\n    char C;        //目标柱\n}ElementType;    //汉诺塔问题的结构类型bash//借助栈的非递归实现\nvoid Hanoi(int n)\n{\n    ElementType P, toPush;\n    Stack S;\n\n    P.N = n; P.A = 'a'; P.B = 'b'; P.C = 'c';\n    S.top = -1;\n\n    Push(&amp;S, P);\n    while (S.top != -1)        //当堆栈不为空时\n    {\n        P = Pop(&amp;S);\n        if (P.N == 1)\n            printf(\"%c  -&gt; %c\\n\", P.A, P.C);\n        else\n        {\n            toPush.N = P.N - 1;\n            toPush.A = P.B; toPush.B = P.A; toPush.C = P.C;\n            Push(&amp;S, toPush);        //将第二个待解子问题(n - 1, b, a, c)入栈\n            toPush.N = 1;\n            toPush.A = P.A; toPush.B = P.B; toPush.C = P.C;\n            Push(&amp;S, toPush);        //将可直接求解的子问题(1, a, b, c)入栈\n            toPush.N = P.N - 1;\n            toPush.A = P.A; toPush.B = P.C; toPush.C = P.B;\n            Push(&amp;S, toPush);        //将第一个待解子问题(n - 1, a, c, b)入栈\n        }\n    }\n}bash//借助栈的非递归实现\nvoid Hanoi(int n)\n{\n    ElementType P, toPush;\n    Stack S;\n\n    P.N = n; P.A = 'a'; P.B = 'b'; P.C = 'c';\n    S.top = -1;\n\n    Push(&amp;S, P);\n    while (S.top != -1)        //当堆栈不为空时\n    {\n        P = Pop(&amp;S);\n        if (P.N == 1)\n            printf(\"%c  -&gt; %c\\n\", P.A, P.C);\n        else\n        {\n            toPush.N = P.N - 1;\n            toPush.A = P.B; toPush.B = P.A; toPush.C = P.C;\n            Push(&amp;S, toPush);        //将第二个待解子问题(n - 1, b, a, c)入栈\n            toPush.N = 1;\n            toPush.A = P.A; toPush.B = P.B; toPush.C = P.C;\n            Push(&amp;S, toPush);        //将可直接求解的子问题(1, a, b, c)入栈\n            toPush.N = P.N - 1;\n            toPush.A = P.A; toPush.B = P.C; toPush.C = P.B;\n            Push(&amp;S, toPush);        //将第一个待解子问题(n - 1, a, c, b)入栈\n        }\n    }\n}36. 编译与解释  翻译高级语言编写的程序的方式有编译和解释两种。\n  编译 (compile) 是用编译器 (complier) 程序把高级语言所编写的源程序 (source code) 翻译成用机器指令表达的目标代码，使目标代码和源程序在功能上完全等价，通过连接器 (linker) 程序将目标程序与相关连接库连接成一个完整的可执行程序。其优点是执行速度快，产生的可执行程序可以脱离编译器和源程序存在，反复执行。\n  解释 (interpret) 是用解释器 (interpreter) 程序将高级语言编写的源程序逐句进行分析翻译，解释一句，执行一句。当源程序解释完成时目标程序也执行结束，下次运行程序时还需要重新解释执行。其优点是移植到不同平台时不用修改程序代码，只要有合适的解释器即可。\n37. new、delete、malloc、free 的关系\nmalloc 与 free 是 C++/C 语言的标准库函数，new/delete 是 C++ 的运算符。它们都可用于申请动态内存和释放内存。 +  delete 会调用对象的析构函数，和 new 对应，new 调用构造函数，free 只会释放内存。 +  对于非内部数据类型的对象而言，光用 maloc/free 无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于 malloc/free 是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于 malloc/free。 +  因此 C++ 语言需要一个能完成动态内存分配和初始化工作的运算符 new，以及一个能完成清理与释放内存工作的运算符 delete。注意 new/delete 不是库函数。\n\n1) C++ 中 new 和 malloc 的区别[1] 属性\n  new 和 delete 是 C++ 关键字，需要编译器支持；malloc 和 free 是库函数，需要头文件支持。\n[2] 参数\n   使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。\n[3] 返回类型\n   new 操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故 new 是符合类型安全性的操作符。而 malloc 内存分配成功则是返回 void* ，需要通过强制类型转换将 void* 指针转换成我们需要的类型。\n[4] 自定义类型\n   new 会先调用 operator new 函数，申请足够的内存（通常底层使用 malloc 实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete 先调用析构函数，然后调用 operator delete 函数释放内存（通常底层使用 free 实现）。\n   malloc/free 是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。\n[5] “重载”\n   C++ 允许自定义 operator new 和 operator delete 函数控制动态内存的分配。\n内存区域\n   new 做两件事：分配内存和调用类的构造函数，delete 是：调用类的析构函数和释放内存。而 malloc 和 free 只是分配和释放内存。\n   new 操作符从自由存储区（free store）上为对象动态分配内存空间，而 malloc 函数从堆上动态分配内存。自由存储区是 C++ 基于 new 操作符的一个抽象概念，凡是通过 new 操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C 语言使用 malloc 从堆上分配内存，使用 free 释放已分配的对应内存。自由存储区不等于堆，如上所述，布局 new 就可以不位于堆中。\n[6] 分配失败\n   new 内存分配失败时，会抛出 bac_alloc 异常。malloc 分配内存失败时返回 NULL。\n[7] 内存泄漏\n   内存泄漏对于 new 和 malloc 都能检测出来，而 new 可以指明是哪个文件的哪一行，malloc 确不可以。\n38. C++有哪些性质（面向对象特点）  封装，继承和多态。\n39. 多态性 (polymer phism)\n多态是指相同的操作或函数、过程可作用于多种类型的对象上并获得不同的结果。不同的对象，收到同一消息可以产生不同的结果，这种现象称为多态。 +  多态是指同样的消息被不同类型的对象接收时导致不同的行为。 所谓消息是指对类成员函数的调用，不同的行为是指不同的实现，也就是调用了不同的函数。（C++ 课本） +  多态性是指允许同一个函数（或操作符）有不同的版本，对于不同的对象执行不同的版本。C++ 支持以下两种多态性：（数据结构课本） [1] 编译时的多态性，表现为函数名（或操作符）的重载； [2] 运行时的多态性，通过派生类和虚函数来实现。\n\n40. 虚函数 (virtual function) 与纯虚函数 (pure virtual function)（1）虚函数  一个虚函数是一个在基类中被声明为 “virtual”，并在一个或多个派生类中被重定义的函数。\n  虚函数只能是类中的一个成员函数，且不能是静态的。\n  利用虚函数，可在基类和派生类中使用相同的函数名定义函数的不同实现，从而实现“一个接口、多种方式”。当用基类指针或引用对虚函数进行访问时，系统将根据运行时指针或引用的实际对象来自动确定调用对象所在类的虚函数版本。\n  使用虚函数，系统要增加一定的空间开销用来存储虚函数表，但系统在进行动态联编时的时间开销是很少的，因此，多态性是高效的。\n（2）纯虚函数  在许多情况下，不能在基类中为虚函数给出一个有意义的定义，这时可以将它说明为纯虚函数，将具体定义留给派生类去做。纯虚函数的定义形式为：virtual 返回类型 函数名(形式参数列表) = 0;即在虚函数的声明原型后加上 “=0”，表示纯虚函数根本就没有函数体。\n  纯虚函数的作用是在基类中为其派生类保留一个函数的名字，以便派生类根据需要对它进行定义。如果在一个类中声明了纯虚函数，而在其派生类中没有对该函数定义，则该虚函数在派生类中仍然为纯虚函数。\n（3）虚函数表  虚函数（Virtual Function）是通过一张虚函数表（Virtual Table）来实现的，简称为 V-Table。在这个表中，主要是一个类的虚函数的地址表，这张表解决了继承、覆盖的问题，保证其真实反应实际的函数。这样，在有虚函数的类的实例中这个表被分配在了这个实例的内存中，所以，当我们用父类的指针来操作一个子类的时候，这张虚函数表就显得由为重要了，它就像一个地图一样，指明了实际所应该调用的函数。\n  C++ 的编译器应该是保证虚函数表的指针存在于对象实例中最前面的位置（这是为了保证取到虚函数表有最高的性能 —— 如果有多层继承或是多重继承的情况下）。 这意味着我们通过对象实例的地址得到这张虚函数表，然后就可以遍历其中函数指针，并调用相应的函数。\n（4）在内存中的存储  C++ 中，\n\n虚函数表位于只读数据段（.rodata），即：C++ 内存模型中的常量区。+ 虚函数代码则位于代码段（.text），也就是C++ 内存模型中的代码区。\n\n  \n（5）哪些函数不能声明成虚函数  在 C++，有五种函数不能被声明成虚函数，分别是：非成员函数、构造函数、静态成员函数、内联成员函数、友元函数这五种，下面分别解释为什么这五种函数不能被声明成虚函数。\n\n非成员函数： 非成员函数只能被重载 (overload)，不能被继承 (override)，而虚函数主要的作用是在继承中实现动态多态，非成员函数早在编译期间就已经绑定函数了，无法实现动态多态，那声明成虚函数还有什么意义呢？ +  构造函数： 要想调用虚函数必须要通过“虚函数表”来进行的，但虚函数表是要在对象实例化之后才能够进行调用。而在构造函数运行期间，还没有为虚函数表分配空间，自然就没法调用虚函数了。 +  静态成员函数： 静态成员函数对于每个类来说只有一份，所有的对象都共享这一份代码，它是属于类的而不是属于对象。虚函数必须根据对象类型才能知道调用哪一个虚函数，故虚函数是一定要在对象的基础上才可以的，两者一个是与实例相关，一个是与类相关。 +  内联成员函数： 内联函数是为了在代码中直接展开，减少函数调用花费的代价，虚函数是为了在继承后对象能够准确的执行自己的动作，并且inline函数在编译时被展开，虚函数在运行时才能动态地绑定函数。 +  友元函数： 因为 C++ 不支持友元函数的继承，对于没有继承特性的函数没有虚函数的说法。友元函数不属于类的成员函数，不能被继承。\n\n41. 关于链表的一些问题（涉及到了一点顺序表）42. 数组和链表的区别\n从逻辑结构上来看，数组必须实现定于固定的长度，不能适应数据动态增减的情况，即数组的大小一旦定义就不能改变。当数据增加时，可能超过原先定义的元素的个数；当数据减少时，造成内存浪费；链表动态进行存储分配，可以适应数据动态地增减的情况，且可以方便地插入、删除数据项。 +  从内存存储的角度看，数组从栈中分配空间（用 new 则在堆上创建），对程序员方便快速，但是自由度小；链表从堆中分配空间，自由度大但是申请管理比较麻烦。 +  从访问方式类看，数组在内存中是连续的存储，因此可以利用下标索引进行访问；链表是链式存储结构，在访问元素时候只能够通过线性方式由前到后顺序地访问，所以访问效率比数组要低。\n\n43. 如何判断一个链表是否有环，如何找到这个环的起点？  给定一个单链表，只给出头指针 h：\n\n如何判断是否存在环？+ 如何知道环的长度？+ 如何找出环的连接点在哪里？+ 带环链表的长度是多少？\n\n解法：\n\n对于问题 1，使用追赶的方法，设定两个指针 slow、fast，从头指针开始，每次分别前进 1 步、2 步。如存在环，则两者相遇；如不存在环，fast 遇到 NULL 退出。 +  对于问题 2，记录下问题1的碰撞点 p，slow、fast 从该点开始，再次碰撞所走过的操作数就是环的长度s。 +  问题 3：有定理：碰撞点 p 到连接点的距离 = 头指针到连接点的距离，因此，分别从碰撞点、头指针开始走，相遇的那个点就是连接点。 +  问题 3 中已经求出连接点距离头指针的长度，加上问题 2 中求出的环的长度，二者之和就是带环单链表的长度。\n\n44. 既然已经有数组了，为什么还要链表？  链表是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存储到下一个节点的指针 (Pointer)。\n  从本质上来讲，链表与数组的确有相似之处，他们的相同点是都是线性数据结构，这与树和图不同，而它们的不同之处在于数组是一块连续的内存，而链表可以不是连续内存，链表的节点与节点之间通过指针来联系。\n45. 单向链表和双向链表的优缺点及使用场景（１）单向链表：只有一个指向下一个节点的指针。\n优点：单向链表增加删除节点简单。遍历时候不会死循环； +  缺点：只能从头到尾遍历。只能找到后继，无法找到前驱，也就是只能前进。 +  适用于节点的增加删除。\n\n（２）双向链表：有两个指针，一个指向前一个节点，一个后一个节点。\n优点：可以找到前驱和后继，可进可退； +  缺点：增加删除节点复杂，需要多分配一个指针存储空间。 +  适用于需要双向查找节点值的情况。\n\n46. 循环链表  循环链表是一个所有节点相互连接，形成一个环的数据结构。链表尾部没有 null 节点。循环链表可以是一个单向链表，也可以是双向链表。   \n循环链表的好处\n任何节点都可以做为头节点。可以从任何节点开始进行链表的遍历。只要当第一个节点被重复访问时，则意味着遍历结束。 +  用于实现队列数据结构是很有帮组的。如果使用循环链表，则不需要为了队列而维护两个指针(front 以及 rear)。只需要维护尾节点一个指针即可，因为尾节点的后向节点就是 front 了。 +  循环链表常用于各应用程序中。例如，当运行多个应用程序时，操作系统通常会把这些程序存入至一个链表，并进行循环遍历，给每个应用程序分配一定的时间来执行。此时循环链表对于 OS 是很有帮助的，当达到链表尾部时，可以方便的从头部重新开始遍历。 +  循环双向链表可以用于实现高级数据结构，例如斐波那契堆 (Fibonacci Heap)。\n\n47. 指针和引用（1）指针a) 概念  一个对象的地址称为该对象的指针。\n  通过对象地址访问对象的方式称为指针间接访问。\n  用来存放对象地址（即指针）的变量称为指针变量。\nb) 指针的有效性  程序中的一个指针必然是以下 3 种状态之一：1. 指向一个已知对象；2. 值；3. 未初始化的、或未赋值的、或指向未知对象。\n\n如果指针的值为０，称为 0 值指针，又称空指针 (null pointer)，空指针是无效的。 +  如果指针未经初始化，或者没有赋值，或者指针运算后指向未知对象，那么该指针是无效的。 · 一个指针还没有初始化，称为“野指针” (wild pointer)。严格地说，每个指针在没有初始化之前都是“野指针”，大多数的编译器都对此产生警告。 · 一个指针曾经指向一个已知对象，在对象的内存空间释放后，虽然该指针仍是原来的内存地址，但指针所指已是未知对象，称为“迷途指针” (dangling pointer)。\n\n  在实际编程中，程序员要始终确保引用的指针是有效的，对尚未初始化或为赋值的指针一般先将其初始化为0值，引用指针之前检测它是否为 0 值。\n（2）如何理解引用 (reference)?  简单地说，引用就是一个对象的别名 (alias name)，其声明形式为：引用类型&amp;引用名称 = 对象名称,…\n  引用的本质是位于某个内存地址上的一个指定类型的对象。\n  在 C++ 中，引用全部是 const 类型，声明之后不可更改。引用一经定义，就不能指向别的地址，也不能指向别的类型，编译器不会专门开辟内存单元存储引用，而是将有引用的地方替换为对象的地址，接受引用的地方替换为指针。\n（3）引用与指针的区别\n引用必须被初始化，指针不必。 +  引用初始化以后不能被改变，指针可以改变所指的对象。 +  不存在指向空值的引用，但是存在指向空值的指针。\n\n48. 数组名，数组首地址，数组指针的区别  例如：int array[5] = {0};\n  众所周知，其中的 &amp;array 是整个数组 array 的首地址，array 是数组首元素的首地址（和&amp;array[0]一样），其值相同，但是“意义不同”。\n  静态数组中，数组名在进行地址操作时，&amp;arr 和 arr 值虽相同，但意义不同：&amp;arr 移动的单位是整个数组，而 arr 移动的单位是数组元素！！\n  数组名字、数组名字取地址、数组首元素取地址、指向首元素的指针这四个变量的数值大小是相等的，但是在后面的地址加 1 的操作中，数组名字取地址所得地址在 +1 之后所得的结果与其他变量不同。\n1) 数组指针  数组指针，指的是数组名的指针，即数组首元素地址的指针。即是指向数组的指针。例：int (*p)[10];p 即为指向数组的指针，又称数组指针。\n2) 指针与数组名的区别\n指针：也是一个变量，存储的数据是地址。 +  数组名：代表的是该数组最开始的一个元素的地址。\n\nbashint a[10];\nint *p;\np = &amp;a[0] // 可以写成 p = a;\n对数组元素 a[i] 的引用也可以写成 *(a+i) 这种形式。 +  赋值语句 p=&amp;a[0] 也可以写成下列形式: p=a。 +  p 是个指针，p[i] 与 *(p+i) 是等价的。\n\n  区别：指针是一个变量，可以进行数值运算。数组名不是变量，不可以进行数值运算。\n3) 二维数组中的指针\na+n 表示第 n 行的首地址，在一维数组中，a+n 表示的是数组的第 n+1 个元素的地址； +  &amp;a[0][0] 既可以看作数组 0 行 0 列的首地址，同样还可以看作二维数组的首地址。&amp;a[m][n] 就是第 m 行第 n 列的元素的地址； +  &amp;a[0] 是第 0 行的首地址，当然 &amp;a[n] 就是第 n 行的首地址； +  a[0]+n 表示第 0 行第 n 个元素的地址； +  ((a+n)+m) 表示第 n 行第 m 列元素； +  *(a[n]+m) 表示第 n 行第 m 列元素；\n\n4) C++ 中的 int、int**、int&amp;、int&amp;、int *a[]、int(*a)[]：bashint a;      //a是一个int型【变量】\nint *a;     //a是一个指向int型变量的【指针】\nint **a;    //a是一个指向int型变量指针的指针，也就是【二级指针】\nint &amp;a;     //a是一个【普通变量型引用】，若int &amp;a = i;则a是变量i的一个别名，&amp;a=&amp;i，即a和i的地址一样\nint *&amp;a;    //a是一个【指针变量型引用】，若int *&amp;a = i;则a是指针i的一个引用\nint a[2];   //a是一个含有两个int型变量的【数组】\nint *a[2];  //a是一个【指针数组】，数组a里存放的是两个int型指针\nint (*a)[2];//a是一个【数组指针】，a指向一个含有两个int型变量的数组49. 函数名，函数指针，函数的入口地址的区别\n指针函数是指带指针的函数，即本质是一个函数，函数返回类型是某一类型的指针。 +  函数指针是指向函数的指针变量，即本质是一个指针变量。\n\n  主要的区别是一个是指针变量，一个是函数。 \n  函数指针：1. 指针变量  2. 指针变量指向函数\n  这正如用指针变量可指向整型变量、字符型、数组一样。\n  在编译时 ，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。\n  可利用该指针变量调用函数，就如同用指针变量可引用其他类型变量一样，在这些概念上一致的。事实上，每一个函数，即使它不带有返回某种类型的指针，它本身都有一个入口地址，该地址相当于函数名。尽管函数不是变量，但它在内存中仍有其物理地址，该地址能够赋给指针变量。获取函数方法是：用不带有括号和参数的函数名得到。\n  函数名相当于一个指向其函数入口指针常量。\n  函数名后面加圆括号，表示函数调用。\n  若要得到函数的地址，直接用函数名就可以了\n  ##############################################################   指针函数和函数指针的区别：\n\n指针函数：指带指针的函数，即本质是一个函数。+ 指针函数返回类型是某一类型的指针。\n\n  ##############################################################\n  函数指针有两个用途：调用函数和做函数的参数。函数指针的说明方法为：\n  数据类型标志符 （指针变量名）（形参列表）； \n  注 1 ：“函数类型”说明函数的返回类型，由于“()”的优先级高于“*”, 所以指针变量名外的括号必不可少，后面的“形参列表”表示指针变量指向的函数所带的参数列表。例：\nbashint func(int x); /* 声明一个函数 */\nint (*f) (int x); /* 声明一个函数指针 */\nf=func; /* 将func函数的首地址赋给指针f */  赋值时函数 func 不带括号，也不带参数，func 代表函数的首地址。\n  注 2：函数括号中的形参可有可无，视情况而定。\n  下面的程序说明了函数指针调用函数的方法：\nbash#include\nint max(int x,int y){ return(x&gt;y?x:y); }\nvoid main()\n{\n    int (*ptr)(int, int);\n    int a,b,c;\n    ptr=max;\n    scanf(\"%d,%d\",&amp;a,&amp;b);\n    c=(*ptr)(a,b);\n    printf(\"a=%d,b=%d,max=%d\",a,b,c);\n}  实际上 ptr 和 max 都指向同一个入口地址，不同就是 ptr 是一个指针变量，不像函数名称那样是死的，它可以指向任何函数。\n  注意，指向函数的指针变量没有  和  运算。\n50. const 与 #define 的比较，const 有什么优点?\nconst 常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误（边际效应） 。 +  有些集成化的调试工具可以对 const 常量进行调试，但是不能对宏常量进行调试。\n\n51. 内存的分配方式有几种?\n从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量。 +  在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 +  从堆上分配，亦称动态内存分配。程序在运行的时候用 malloc 或 new 申请任意多少的内存，程序员自己负责在何时用 free 或delete 释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。\n\n52. 全局变量和局部变量有什么区别？是怎么实现的？操作系统和编译器是怎么知道的？\n生命周期不同：全局变量随主程序创建和创建，随主程序销毁而销毁；局部变量在局部函数内部，甚至局部循环体等内部存在，退出就不存在。 +  使用方式不同：通过声明后全局变量程序的各个部分都可以用到；局部变量只能在局部使用；分配在栈区。\n\n  操作系统和编译器通过内存分配的位置来知道的，全局变量分配在全局数据段并且在程序开始运行的时候被加载。局部变量则分配在堆栈里面 。\n53. 进程 process 与线程 thread  进程是操作系统分配资源的单位，线程是 CPU 调度的基本单位，线程之间共享进程资源。\n  进程与线程的一个简单解释(很形象)\n  深入理解进程和线程\n  进程与线程概念\n（1）进程  计算机的核心是 CPU，它承担了所有的计算任务，而操作系统是计算机的管理者，它负责任务的调度，资源的分配和管理，统领整个计算机硬件；应用程序是具有某种功能的程序，程序是运行于操作系统之上的。\n  进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。 进程是一种抽象的概念，从来没有统一的标准定义。进程一般由程序，数据集合和进程控制块三部分组成。程序用于描述进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时所需要的数据和工作区；程序控制块包含进程的描述信息和控制信息是进程存在的唯一标志。\n  进程具有的特征：\n\n动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的。+ 并发性：任何进程都可以同其他进行一起并发执行。+ 独立性：进程是系统进行资源分配和调度的一个独立单位。+ 结构性：进程由程序，数据和进程控制块三部分组成。\n\n（2）线程  在早期的操作系统中并没有线程的概念，进程是拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。\n  后来，随着计算机的发展，对 CPU 的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程，线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。 一个标准的线程由线程 ID，当前指令指针 PC，寄存器和堆栈组成。而进程由内存空间(代码，数据，进程空间，打开的文件)和一个或多个线程组成。\n（3）进程与线程的区别\n线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位. +  一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线。 +  进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段，数据集，堆等)及一些进程级的资源(如打开文件和信号等)，某进程内的线程在其他进程不可见。 +  调度和切换：线程上下文切换比进程上下文切换要快得多。\n\n     线程和进程关系示意图\n  总之，线程和进程都是一种抽象的概念，线程是一种比进程还小的抽象，线程和进程都可用于实现并发。在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位，它相当于一个进程里只有一个线程，进程本身就是线程。所以线程有时被称为轻量级进程。\n  后来，随着计算机的发展，对多个任务之间上下文切换的效率要求越来越高，就抽象出一个更小的概念-线程，一般一个进程会有多个(也可以是一个)线程。\n（4）任务调度  大部分操作系统的任务调度是采用时间片轮转的抢占式调度方式，也就是说一个任务执行一小段时间后强制暂停去执行下一个任务，每个任务轮流执行。任务执行的一小段时间叫做时间片，任务正在执行时的状态叫运行状态，任务执行一段时间后强制暂停去执行下一个任务，被暂停的任务就处于就绪状态，等待下一个属于它的时间片的到来。这样每个任务都能得到执行，由于 CPU 的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发。   \n（5）为何不使用多进程而是使用多线程？  线程廉价，线程启动比较快，退出比较快，对系统资源的冲击也比较小。而且线程彼此分享了大部分核心对象 (File Handle) 的拥有权。\n  如果使用多重进程，但是不可预期，且测试困难。\n（6）一个简单的比喻  做个简单的比喻：进程 = 火车，线程 = 车厢\n\n线程在进程下行进（单纯的车厢无法运行） +  一个进程可以包含多个线程（一辆火车可以有多个车厢） +  不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘） +  同一进程下不同线程间数据很易共享（A 车厢换到 B 车厢很容易） +  进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源） +  进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢） +  进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上） +  进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－“互斥锁” +  进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量”\n\n54. 介绍下几种常见的进程调度算法及其流程（FCFS，SJF，剩余短作业优先，优先级调度，轮转法，多级反馈队列等等）\n先来先服务+ 短作业优先+ 优先级调度+ 最高响应比优先+ 时间片轮转法+ 多级反馈队列调度\n\n55. 虚拟内存  虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。\n56. 内存管理的方式及优点？  Windows 内存管理方式主要分为：页式管理、段式管理、段页式管理。\n（１）页式管理\n基本原理：将各进程的虚拟空间划分为若干个长度相等的页。把内存空间按页的大小划分为片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表，并用相应的硬件地址转换机构来解决离散地址变换问题。页式管理采用请求调页和预调页技术来实现内外存存储器的统一管理。 +  优点：没有外碎片，每个内碎片不超过页的大小。 +  缺点：程序全部装入内存，要求有相应的硬件支持，如地址变换机构缺页中断的产生和选择淘汰页面等都要求有相应的硬件支持。增加了机器成本和系统开销。\n\n（２）段式管理\n基本思想：把程序按内容或过程函数关系分成段，每段有自己的名字。一个用户作业或者进程所包含的段对应一个二维线性虚拟空间，也就是一个二维虚拟存储器。段式管理程序以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。 +  优点：可以分别编写和编译，可以针对不同类型的段采取不同的保护，可以按段为单位来进行共享，包括通过动态链接进行代码共享。 +  缺点：会产生碎片。\n\n（３）段页式管理\n基本思想：系统必须为每个作业或者进程建立一张段表以管理内存分配与释放、缺段处理等。另外，由于一个段又被划分为若干个页，每个段必须建立一张页表以把段中的虚页变换为内存中的实际页面。显然与页式管理时相同，页表也要有相应的实现缺页中断处理和页面保护等功能的表项。 +  优点：段页式管理是段式管理和页式管理相结合而成，具有两者的优点。 +  缺点：由于管理软件的增加，复杂性和开销也增加。另外需要的硬件以及占用的内存也有所增加，使得执行速度下降。\n\n57. 页表、反向页表58. 计算机是如何启动的？\nBIOS 上电自检+ 查找启动设备+ MBR引导程序+ 加载 OS 内核+ OS 取得系统控制权\n\n  按下电源开关后，主板各个器件会供电，CPU 供电完成后会进行一段复位的操作。复位完成后会从主板上的存储芯片（BIOS 芯片）里读取一段启动代码进行上电自检。如果硬件设备都检测正常的话，它就会进行下一步：检测启动设备。\n  假设它查找的启动设备是一块硬盘。接下来，它会到硬盘的第一个扇区去读取一段程序（主引导记录 Master Boot Record，512 字节——引导程序 + 硬盘分区表、分区表数据 + 结束标志 AA55）。\n  当 BIOS 程序找到 MBR 这段数据的时候，它会把数据加载到内存中，然后把系统的控制权交给 MBR 中的那段引导程序。\n  MBR 的引导程序取得系统的控制权之后，它会把操作系统的内核加载到内存，然后把系统的控制权交给操作系统的内核。这个时候，操作系统就取得了系统的控制权。接下来的过程就是操作系统正常启动的过程。\n59. 数据库系统中事务的概念，事务的特性（1）事务的概念\n事务是完成用户某一特定任务的与数据库的一次或多次交互的逻辑单位。 +  对数据库来讲，事务是和数据库交互的一个程序片段。 对于一般意义上的用户来讲，事务是完成一个功能的程序片段或计算机的指令集合。 +  事务（Transaction） 是对数据库进行访问或修改的一个或多个操作，这组操作组成一个单位，共同完成一个任务。（参考资料）\n\n（2）事务的 ACID 特性分别是什么？\n原子性(Atomicity)：执行事务中的操作要么都做，要么都不做。 +  一致性(Consistency)：一致性要求事务维护数据库的完整性约束。 +  隔离性(Isolation)：并发执行的事务之间不能相互影响。 +  持续性(Durability)：事务一旦提交，它一定是永久生效的。\n\n（3）事务的 ACID 特性怎么保证？（REDO/UNDO 机制）60. 事务隔离等级\nREAD UNCOMMITTED 未提交读取（脏读）——有可能读到别的事务尚未提交的数据 +  READ COMMIT 提交读取——只能读到别的事务已经提交的数据 +  REPEATABLE READ 可重复读——在同一个事务中，对同一个数据的多次读，值是一样的（取决于第一次读取到的数据），即使在读的过程中别的事务是数据变化了，对你没有影响。 +  SERIALIZABLE 串行化——对同一个数据是串行化执行的\n\n61. 黑盒测试和白盒测试  软件测试要经过的步骤： 单元测试 → 集成测试 → 系统测试 → 验收测试\n（1）黑盒测试  黑盒测试指测试人员通过各种输入和观察软件的各种输出结果来发现软件的缺陷，而不关心程序具体如何实现的一种测试方法。\n\n黑盒测试用例设计方法：等价类划分   边界值划分  错误推测法  因果图法  正交表试验法  场景图  功能图\n\n（2）白盒测试  白盒测试又叫做结构测试，把程序看成装在一个透明的白盒子里，按照程序内部的逻辑测试程序，检测程序中的主要执行通路是否都能按预定要求正确工作。\n\n白盒测试常用测试用例设计方法：逻辑覆盖法（逻辑驱动测试）  基本路径测试方法\n\n   白盒测试法的覆盖标准有逻辑覆盖、循环覆盖和基本路径测试。其中逻辑覆盖包括语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖和路径覆盖。六种覆盖标准发现错误的能力呈由弱到强的变化。 \n\n语句覆盖每条语句至少执行一次。+ 判定覆盖每个判定的每个分支至少执行一次。+ 条件覆盖每个判定的每个条件应取到各个可能的值。+ 判定/条件覆盖的同时满足判定覆盖条件覆盖+ 条件组合覆盖每个判定中各条件的每一种组合至少出现一次。+ 路径覆盖使程序中每一条可能的路径至少执行一次。\n\n62. 关于 5G  第五代移动通信技术（英语：5th Generation Mobile Communication Technology, 简称 5G）是具有高速率、低时延和大连接特点的新一代宽带移动通信技术，是实现人机物互联的网络基础设施。\n  5G 作为一种新型移动通信网络，不仅要解决人与人通信，为用户提供增强现实、虚拟现实、超高清 (3D) 视频等更加身临其境的极致业务体验，更要解决人与物、物与物通信问题，满足移动医疗、车联网、智能家居、工业控制、环境监测等物联网应用需求。最终，5G 将渗透到经济社会的各行业各领域，成为支撑经济社会数字化、网络化、智能化转型的关键新型基础设施。\n63. 云计算、云存储、物联网的概念（1）云计算  云计算（cloud computing）是分布式计算的一种，指的是通过网络“云”将巨大的数据计算处理程序分解成无数个小程序，然后，通过多部服务器组成的系统进行处理和分析这些小程序得到结果并返回给用户。云计算早期，简单地说，就是简单的分布式计算，解决任务分发，并进行计算结果的合并。因而，云计算又称为网格计算。通过这项技术，可以在很短的时间内（几秒钟）完成对数以万计的数据的处理，从而达到强大的网络服务。\n  现阶段所说的云服务已经不单单是一种分布式计算，而是分布式计算、效用计算、负载均衡、并行计算、网络存储、热备份冗杂和虚拟化等计算机技术混合演进并跃升的结果。\n（2）云存储  云存储是一种网上在线存储（英语：Cloud storage）的模式，即把数据存放在通常由第三方托管的多台虚拟服务器，而非专属的服务器上。托管（hosting）公司运营大型的数据中心，需要数据存储托管的人，则透过向其购买或租赁存储空间的方式，来满足数据存储的需求。数据中心营运商根据客户的需求，在后端准备存储虚拟化的资源，并将其以存储资源池（storage pool）的方式提供，客户便可自行使用此存储资源池来存放文件或对象。实际上，这些资源可能被分布在众多的服务器主机上。\n（3）物联网  物联网即物物相连的互联网。物联网是由 Kevin Ashton 教授首次提出，它的基础与核心依旧是互联网，是在互联网的基础上延伸及拓展的网络。\n  物联网的用户端延伸和拓展到任何的物品与物品之间，进行通信以及交换信息，即物物相息。物联网广泛应用在网络融合中，它是通过识别技术、智能感知以及普适计算等通信感知的技术来应用的。物联网是继计算机、互联网之后世界信息产业发展的第三次浪潮。\n64. 输入网址点击转到之后发生的事\n用户在浏览器（客户端）里输入或者点击一个连接； +  浏览器向服务器发送 HTTP 请求； +  服务器处理请求，如果查询字符串或者请求体里含有参数，服务器也会把这些参数信息考虑进去； +  服务器更新、获取或者转换数据库里的数据； +  浏览器接受 HTTP 响应； +  浏览器以 HTML 或者其他格式（比如 JPEG、XML 或者 JSON）把 HTTP 响应呈现给用户。\n\n或：\n\n第一步：对网址进行 DNS 解析 DNS 解析的过程就是寻找在哪台主机上有你需要的资源的过程，我们通常使用机器的域名来访问这台机器，而不是直接使用其 IP 地址，而将机器的域名转换为 IP 地址就需要域名查询服务，这个过程称为 DNS 解析，它主要充当一个翻译的角色，实现网址到 IP 地址的转换。 +  第二步：进行 TCP 连接 TCP 连接也就是我们常说的三次握手，首先客户端向服务器端发送是否可以连接的请求，服务器端接受到请求后确认客户的 SYN，并向客户端发送自己的 SYN 包，客户端接收到服务器发来的包之后向服务器发送确认包从而完成三次握手。 +  第三步：发送 HTTP 请求 在完成 TCP 连接后，接下来做的事情就是客户端向服务器端发送 HTTP 请求。 +  第四步：服务器处理请求并返回 HTTP 报文 服务器端接到HTTP请求后在会作出响应。 +  第五步：浏览器解析渲染页面 浏览器在收到 HTML, CSS, JS 文件后，它将这些信息渲染到客户端页面上。 浏览器是一个边解析边渲染的过程。首先浏览器解析 HTML 文件构建 DOM 树，然后解析 CSS 文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。这个过程比较复杂，涉及到两个概念: reflow (回流)和 repain (重绘)。DOM 节点中的各个元素都是以盒模型的形式存在，这些都需要浏览器去计算其位置和大小等，这个过程称为 relow; 当盒模型的位置,大小以及其他属性，如颜色,字体,等确定下来之后，浏览器便开始绘制内容，这个过程称为 repain。页面在首次加载时必然会经历 reflow 和 repain。reflow 和 repain 过程是非常消耗性能的，尤其是在移动设备上，它会破坏用户体验，有时会造成页面卡顿。所以我们应该尽可能少的减少 reflow 和 repain。 +  第六步：连接结束，关闭连接请求\n\n65. TCP/IP，TCP 和 UDP 的区别\nTCP/IP 协议 (Transmission Control Protocol / Internet Protocol) 叫做传输控制/网际协议，又叫网络通讯协议，这个协议是 Internet 国际互联网络的基础。 +  TCP/IP 是网络中使用的基本的通信协议。虽然从名字上看 TCP/IP 包括两个协议，传输控制协议 (TCP) 和网际协议 (IP)，但 TCP/IP 实际上是一组协议，它包括上百个各种功能的协议，如：远程登录、文件传输和电子邮件等，而 TCP 协议和 IP 协议是保证数据完整传输的两个基本的重要协议。通常说 TCP/IP 是 Internet 协议族，而不单单是 TC P和 IP。 +  TCP/IP 是用于计算机通信的一组协议，我们通常称它为 TCP/IP 协议族。它是 70 年代中期美国国防部为其 ARPANET 广域网开发的网络体系结构和协议标准，以它为基础组建的 INTERNET 是目前国际上规模最大的计算机网络，正因为 INTERNET 的广泛使用，使得 TCP/IP 成了事实上的标准。 +  之所以说 TCP/IP 是一个协议族，是因为 TCP/IP 协议包括 TCP、IP、UDP、ICMP、RIP、TELNET、FTP、SMTP、ARP、TFTP 等许多协议，这些协议一起称为 TCP/IP 协议。以下我们对协议族中一些常用协议英文名： +  TCP/IP 是供已连接因特网的计算机进行通信的通信协议。 +  TCP/IP 指传输控制协议/网际协议 (Transmission Control Protocol / Internet Protocol)。 +  TCP/IP 定义了电子设备（比如计算机）如何连入因特网，以及数据如何在它们之间传输的标准。\n\n66. aloha，CSMA/CA，以太网和 Internet 区别，有了以太网为什么还有 Internet？  以太网只是组成互联网的一个子集，以太网是现在主流的局域网标准，而互联网是指将大量的局域网连接起来，进行资源的分享。\n或：\n  以太网（英语：Ethernet）是为了实现局域网通信而设计的一种技术，它规定了包括物理层的连线、电子信号和介质访问层协议的内容。以太网是目前应用最普遍的局域网技术，取代了其他局域网标准如令牌环、FDDI 和 ARCNET。\n  互联网（英语：Internet）是一个网络的网络，它是由从地方到全球范围内几百万个私人的，政府的，学术界的，企业的和政府的网络所构成，通过电子，无线和光纤网络技术等等一系列广泛的技术联系在一起。简单地说，以太网是一直为了实现局域网通信而设计的一系列方法，包括物理层传输媒介和 CSMA/CD 协议等内容，而互联网是计算机网络。\n67. 流量控制在哪一层起作用？  数据链路层、传输层\n68. 解释下什么是 DMA，介绍下 DMA 流程  通过在 I/O 设备和内存之间开启一个可以直接传输数据的通路，采用 DMA 控制器来控制一个数据块的传输，CPU 只需在一个数据块传输开始阶段设置好传输所需的控制信息，并在传输结束阶段做进一步处理。\n69. 程序的编译执行过程  构建 C 程序需要 4 个步骤，分别使用 4 个工具完成： preprocessor, compiler, assembler, and linker. 四步完成后生成一个可执行文件。\n\n第一步，预处理. 这一步处理 头文件、条件编译指令和宏定义。 +  第二步，编译. 将第一步产生的文件连同其他源文件一起编译成汇编代码。 +  第三步，汇编。将第二步产生的汇编源码转换为 object file. +  第四步，链接. 将第三步产生的一些 object file 链接成一个可执行的文件。\n\n  \n或：\n  C 语言的编译链接过程要把我们编写的一个 C 程序（源代码）转换成可以在硬件上运行的程序（可执行代码），需要进行编译和链接。编译就是把文本形式源代码翻译为机器语言形式的目标文件的过程。链接是把目标文件、操作系统的启动代码和用到的库文件进行组织，形成最终生成可执行代码的过程。\n  从图上可以看到，整个代码的编译过程分为编译和链接两个过程，编译对应图中的大括号括起的部分，其余则为链接过程。   \n70. 说说你对编译原理的理解  “编译原理课程”讲述高级程序设计语言源程序转换成汇编语言或机器语言的程序时使用的技术、数据结构和算法(即编译程序原理)。\n  编译器就是将“一种语言(通常为高级语言)”翻译为“另一种语言(通常为低级语言)”的程序。一个现代编译器的主要工作流程:源代码 (source code) → 预处理器 (preprocessor) → 编译器 (compiler) → 目标代码 (object code) → 链接器(Linker) → 可执行程序 (executables)。\n71. Top k 问题1) 排序（选取前 k 个数）2) 快排  快排的 partition 划分思想可以用于计算某个位置的数值等问题，例如用来计算中位数；显然，也适用于计算 TopK 问题\n  每次经过划分，如果中间值等于 K ，那么其左边的数就是 Top K 的数据；当然，如果不等于，只要递归处理左边或者右边的数即可。\n  该方法的时间复杂度是 ，简单分析就是第一次划分时遍历数组需要花费 ，而往后每一次都折半（当然不是准确地折半），粗略地计算就是 ，因此显然时间复杂度是 。\n  缺点：在海量数据的情况下，我们很有可能没办法一次性将数据全部加载入内存，这个时候这个方法就无法完成使命了\n3) 利用分布式思想处理海量数据  面对海量数据，我们就可以往分布式的方向去思考了。\n  我们可以将数据分散在多台机器中，然后每台机器并行计算各自的 TopK 数据，最后汇总，再计算得到最终的 TopK 数据。\n4) 利用最经典的方法（堆），一台机器也能处理海量数据  其实提到 Top K 问题，最经典的解法还是利用堆。\n  维护一个大小为 K 的小顶堆，依次将数据放入堆中，当堆的大小满了的时候，只需要将堆顶元素与下一个数比较：如果大于堆顶元素，则将当前的堆顶元素抛弃，并将该元素插入堆中。遍历完全部数据，Top K 的元素也自然都在堆里面了。\n  当然，如果是求前 K 个最小的数，只需要改为大顶堆即可。\n  对于海量数据，我们不需要一次性将全部数据取出来，可以一次只取一部分，因为我们只需要将数据一个个拿来与堆顶比较。\n  另外还有一个优势就是对于动态数组，我们可以一直都维护一个 K 大小的小顶堆，当有数据被添加到集合中时，我们就直接拿它与堆顶的元素对比。这样，无论任何时候需要查询当前的前 K 大数据，我们都可以里立刻返回给他。\n  整个操作中，遍历数组需要  的时间复杂度，一次堆化操作需要 ，加起来就是  的复杂度，换个角度来看，如果  远小于  的话，  其实就接近于  了，甚至会更快，因此也是十分高效的。\n  最后，对于 Java，我们可以直接使用优先队列 PriorityQueue 来实现一个小顶堆。\n72. 如何写代码计算根号 n1) 袖珍计算器算法  \n2) 二分法  \n3) 牛顿迭代法  \n73. 如何一次写出正确的程序？\\ 如何知道你写的程序是对的？74. 微信红包随机金额怎么实现？1) 关于分配算法，红包里的金额怎么算？为什么出现各个红包金额相差很大？答：随机，额度在 0.01 和剩余平均值 2 之间。\n  例如：发 100 块钱，总共 10 个红包，那么平均值是 10 块钱一个，那么发出来的红包的额度在 0.01元～20 元之间波动。当前面 3 个红包总共被领了 40 块钱时，剩下 60 块钱，总共 7 个红包，那么这 7 个红包的额度在：0.01～（60 / 7 * 2）= 17.14之间。\n  注意：这里的算法是每被抢一个后，剩下的会再次执行上面的这样的算法（Tim 老师也觉得上述算法太复杂，不知基于什么样的考虑）。这样算下去，会超过最开始的全部金额，因此到了最后面如果不够这么算，那么会采取如下算法：保证剩余用户能拿到最低1分钱即可。如果前面的人手气不好，那么后面的余额越多，红包额度也就越多，因此实际概率一样的。\n2) 微信的金额什么时候算？答：微信金额是拆的时候实时算出来，不是预先分配的，采用的是纯内存计算，不需要预算空间存储。\n  为什么采取实时计算金额？原因是：实时效率更高，预算才效率低下。预算还要占额外存储。因为红包只占一条记录而且有效期就几天，所以不需要多大空间。就算压力大时，水平扩展机器是。\n75. 概率计算题：一副扑克牌平均分成三堆，大小王同时在一堆的概率  假设有 1 2 3 三组，我们先求大王小王在同在 1 组的概率：\n\n大王在 1 组 P(B)：18/54 +  大王已经在1组的条件下小王在 1 组 P(A|B)：17/53（因为把大王放在 1 组用掉了一个空位） +  那么大王小王同在 1 组的概率 P：P(A,B) = P(B)*P(A|B) = 18/54 * 17/53\n\n  1，2，3 组都有可能选择，3 * 18/54 * 17/53 = 17/53\n76. 命题逻辑的联结词有哪些？  非、析取、合取、蕴涵、等价\n","slug":"计算机复试常见问题整理","date":"2023-06-18T10:34:03.000Z","categories_index":"计算机专业课","tags_index":"学习笔记,转载","author_index":"以太工坊"},{"id":"23652f54d2e04c40370b3c92df2611e1","title":"机器学习复习笔记","content":"参考笔记一 代码向 \n1. 绪论机器学习的概念不需要确定性编程就可以赋予机器某项技能Performance Task Experience，程序使用E在T上获得了P的提升，就是学习按照任务种类分：回归、分类、聚类、降维按照学习方式分：有监督、无监督、强化学习\n2. 模型的评估与选择\n\n\n\n\n\n\n\n\n重点章节各种评价指标，包括写代码、调用库函数例题如协方差矩阵、查准、混淆矩阵、ROC曲线基本知识点如过拟合问题与解决方案\n经验误差empirical error:在训练集上的误差（训练误差）泛化误差generalization error：在未来样本上的误差泛化误差越小越好，但经验误差并不是。\n评估方法留出法hold-outX_train,X_test,y_train,y_test=train_test_split()\n\n保持数据分布一致\n多次随机划分、重复实验取平均值\n合适的测试集比例\n\n交叉验证法cross validation先将数据集划分为k个大小相同的互斥子集，保证每个子集的数据分布一致，在选取k-1个子集作为训练集，余下的作为测试集。这样就可以获得k组训练/测试集，可进行k次训练和测试。\npythonmodel = linear_model.Lasso()\ncv_results = sklearn.model_selection.cross_validate(model,X,y,cv=3)\n# 第二种\nkf = KFold(3)\nfor train_idx,test_idx iin kf.split(X):\n    X_train,X_test = X[train_idx],X[test_idx]\n    y_train,y_test = y[train_idx],y[test_idx]特别地，如果则交叉验证变为留一法Leave One Out：\n\n不受随机样本划分方式的影响，因为只有一种划分方式——每个子集一个样本；\n训练集包含了尽可能多的样本，使得实际被评估的模型与期望评估的模型很相似；\n训练开销大\n估计结果也不一定比其它评估方法准确\n\n自助法bootstrap使用有放回重复采样构建数据集，会有的原始数据永远不会被采样，这一部分就作为测试集。\n性能度量ROC曲线横轴是假负例率，纵轴是真正例率，围成的面积为AOC，越大越好。\n比较检验在测试集上的性能不能反映模型的真正性能，需要进行统计假设检验，推断在统计意义上是否更优。原因：\n\n测试性能不等于泛化性能\n测试性能随测试集的变化而变化\n机器学习算法本身就有一定的随机性偏差与方差对回归任务，泛化误差可以分解为偏差bias、方差variance、噪声之和。在训练的过程中，一般逐渐从偏差主导转向方差主导。\n\npython//留出法\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n//k折交叉验证\nkf=KFold(n_split=3)\n//重复p次k折交叉验证\nrkf=RepeateKFold(n_split=3,n_repeats=2)\n//分层k折交叉验证\nskf=StratifiedKFold(n_split=4)\n//留一法\nloo=LeaveOneOut()\n//性能度量\nmetrics.mean_squared_error(y_true,y_pred)\nnp.sqrt(metrics.mean_squared_error(y_true,y_pred))\nmetrics.mean_absolute_error(y_true,y_pred)\n//混淆矩阵\nconfusion_matrix(y_true,y_pred,labels=[0,1,2])\n//绘制P-R图\nprecision, recall, thresholds = precision_recall_curve(y_true, y _pred)\nplt.plot(recall, precision)3. 线性模型\n\n\n\n\n\n\n\n\n梯度（协方差）的概念、计算、求解（手工、代码）\n最小二乘法：对损失函数求导，令导数=0，解得：对数几率回归：利用线性模型做分类任务，对数几率函数(sigmoid)线性判别分析LDA:  给定训练样例集，设法将样例投影到一条直线上，使得同类点尽可能接近、异类点尽可能远离，通过协方差，优化目标为最大化瑞利商。多分类学习：一对一（)个分类器、一对其余（n个分类器）、多对多（ECOC)\npythondef train(epoches = 1 ,l r = 0.01):\n    for epoch in range(epoches):\n        # 前向传播\n        output = inputs.mv(w) # 计算输出y'=wx\n        loss = (target - output).pow(2).sum()\n        loss.backward()\n        w.data -=  lr* w.grad\n        w.grad.zero_()\nsklearn.linear_model.LinearRegression()梯度下降：\npythona = np.array([1,3,4,5])\nb = np.array([2,6,2,2])\nz = np.stack((a,b))\nnp.cov(z)4. 神经网络\n\n\n\n\n\n\n\n\n重点章节BP推导、计算、误差计算、算法\n感知机原始形式其中即是损失函数，它与所有误分类的点到超平面的距离有关，训练的过程就是使损失函数收敛的过程。感知机算法是收敛的：当数据线性可分时，感知机经过有限次的搜索可以找到将训练数据完全正确分开的分离超平面。\n对偶形式\n神经网络反向传播算法步骤：初始化-前向计算样本输出-计算输出层梯度-计算隐层梯度-更新连接权值与阈值前向计算：偏置值是要减去的反向传播：输出层节点的梯度：其中是计算的输出值，而是期望值（真实值、标签）隐层的节点梯度：\n过拟合应对策略：早停与正则化早停\n\n训练误差连续几轮的变化较小，则停止训练\n使用验证集：若训练误差降低但验证误差升高，则停止训练正则化在误差目标函数中增加一项描述网络的复杂度，使网络偏好较小的连接权值和阈值，使网络的输出更加平滑。Local minima模拟退火、随机扰动、遗传算法、动量机制….\n\n激活函数作用是增加网络的非线性表达能力。要求：\n\n连续并可导的非线性函数\n函数及导数要尽可能简单，利于计算\n导数的值域应该位于合适的区间，否则会影响训练的效率与稳定性\n\n5. 最优化理论与方法\n\n\n\n\n\n\n\n\n证明凸集、凸函数，图解法，对偶问题\n引言凸集：n维欧式空间内，如果任意两点的连线都仍然位于此空间内，则为凸集。形式化描述为凸函数： 在定义域内，对任意的都有 为凸函数，凸函数是凹的，凹函数是凸的。 Hesse矩阵半正定，函数为凸函数，正定为严格凸函数。凸规划：求解凸函数在凸集上的极小点。凸规划的局部极小点就是全局极小点，且极小点的集合是凸集。目标函数是严格凸函数+极小点存在=极小点唯一。\n线性规划线性规划的标准形式为:\n\n图解法\n基本性质\n\n\n线性规划的可行域是凸集\n若存在最优解，一定在极点取到\n\n\n可行解在线性规划的标准形式中，设矩阵A的秩为m，又假设 ，其中B是m阶可逆矩阵，则是一个基本解。B是基矩阵，其分量为基变量，若基本解中不含负数，则为基本可行解。例题可以方便理解。\n\n6. 支持向量机\n\n\n\n\n\n\n\n\n重点章节核函数、函数间隔、几何间隔、支持向量、三种形式与对偶问题sklearn调用支持向量机\n函数间隔： 超平面关于所有训练集的函数间隔，是与所有样本点的函数间隔的最小值。几何间隔：  \n线性可分SVM\n线性SVM\n非线性SVM-核技巧\n支持向量\nSVM特性■优点\n\n具有较好的泛化能力，特别是在小样本训练集上能够得到比其他算法好很多的结果。这是因为其优化目标是结构风险最小，而不是经验风险最小，因此通过margin,可以得到对数据分布的结构化描述,从而降低了数据规模和数据分布的要求。\n具有较强的数学理论支撑,基本不涉及概率测度和大数定律等。\n引入核函数可以解决非线性分类问题。■缺点\n不方便解决多分类问题。\n存在对结果影响较大的超参数，比如采用rbf核函数时，惩罚项C和核参数gamma,只能通过穷举或经验推测获得。\n\npythonimport numpy as np\nfrom sklearn.svm import SVC\n\nx = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])  # 自变量\ny = np.array([1, 1, 2, 2])  # 因变量\nmodel = SVC()  # 定义模型\nmodel.fit(x, y)  # 根据数据训练模型\npred = model.predict([[-0.8, -1]])  # 预测x=[-0.8,-1]的结果\nprint(pred)  # 输出y=[1]7. 集成学习Adaboost算法输入训练集 ，输出最终分类器，具体步骤如下：\n\n设定弱分类器数目为,令，使用均匀分布初始化的训练集样本权重分布，令维向量 表示第一次需要更新的样本权重，的初始值设为\n使用权重分布为的训练样本集学习到第个弱分类器\n计算在训练样本集上的错误分类率 ，如果则丢弃\n确定弱学习器的组合权重 ,错误率越小的，其权重应该越大，有\n依据弱分类器对训练样本集的分类错误率，更新样本权重:\n若，令 ，并返回步骤2，否则执行步骤7\n对个分类器分别按照每个权重进行组合，得到最终分类器\n\nBagging算法步骤\n多样性增强方式\n数据样本扰动通常基于采样法，如Bagging使用自助采样，AdaBoost采用序列采样\n\n输入属性扰动随机子空间：从初始属性集中抽取若干个属性子集，再基于每个属性子集训练一个基学习器\n\n输出表示扰动对输出表示进行操纵可以增强多样性。翻转法：随机改变一些训练样本的标记对输出表示进行转化输出调制法：分类输出转换为回归输出，构建个体学习器求解子任务ECOC法：利用纠错输出码将多分类任务拆解为一系列二分类来训练基学习器\n\n算法参数扰动随机设置不同的参数。负相关法：显示地通过正则化项来强制个体神经网络使用不同的参数。\n\n\n20级真题一、10分中科院研究生考试原题，两问共10分\n二、10分（1） 什么是留一法？（2） 给出如下数据，使用线性模型 ，用留一法计算（总体）均方误差。\n\n\n\nx\ny\n\n\n\n0\n2\n\n\n1\n1\n\n\n2\n2\n\n\n（反正是三组，但具体数据可能不是这个）\n三、判断下面的是否是凸函数 10分(1) (2) （都是这种形式，具体数字不记得了）\n四、证明凸集 10分已知,是上的凸集，现有 其中是 的矩阵，证明为凸集。\n五、图解法求线性规划最小值。10分\n六、写出极小问题的对偶形式。10分\n七、 15分（1）描述AdaBoost算法（2）描述Bagging算法（3）简述多样性增强的方式\n八、 25分给一个神经网络，维输入，单隐层共个隐层节点，输出层个节点，输出为（1） 写出隐层的输入和输出层的输入（2）写出均方损失函数（3）给定学习率 ,求(体现出推导过程)（4）给出反向传播的伪代码（5）解释梯度下降与一些常见的变种，并比较他们的不同\n","slug":"机器学习复习笔记","date":"2023-05-24T12:51:11.000Z","categories_index":"机器学习","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"261aff93f4c2c215eea5cbd52db7f4cd","title":"Pyinstaller打包问题","content":"1 Windows7 适配问题txtLoadLibrary: PyInstaller FormatMessageW failed.python 3.9 开始不再适配win 7，如果软件要在 win 7上运行，python环境最高是3.8\n2 win7 缺失的动态运行加载库txt无法启动此程序,因为计算机中丢失api-ms-win-core-path-l1-1-0.dll尝试重新安装该程序以解决此问题。缺啥补啥，把DLL文件放入程序根目录文件夹，或者放到C:/windows/System32下。不过一般这个问题不会单独出现，是由于pyinstaller打包的时候，一些动态加载的库没被放进来。\n3 QT动态加载的部分缺失txtImportError: DLL load failed while import ing QtGui:解决方法一：把环境中Sitepackages/QtGui放到程序根文件夹解决方法二：使用打包命令pyinstaller main.py --noconsole --hidden-import PySide6.QtXml -F -p C:\\Windows\\System32\\downlevel -p C:\\Windows\\System32 通过指定hidden-import手动加载缺少的模块\n4 pyinstaller could not get source code在报错日志里倒着找，把缺少的环境包手动复制到程序根目录，也可以hidden-import在打包时指定导入缺失的这些包\n","slug":"Pyinstaller打包问题","date":"2023-05-14T05:14:15.000Z","categories_index":"技术帖子","tags_index":"技术帖子","author_index":"以太工坊"},{"id":"339231bc7dd528f94b3eb2f74a68d4df","title":"并行计算复习课","content":"复习课第一章 Amdal 定律 对定律的理解（任务不变的情况下，速度的提升、加速比）、加速的极限应用题  6’*5网格和线程块的布局，计算全局id并行、并发、线程束、全局id、CPU多核与GPU众核程序分析题  10*2给代码写结果、分析为什么会有这种结果CPU多核  10*2数据划分：明确每个部分处理的数据范围任务并行：线程池实验CUDA编程    15*2具体的问题，设计网格与线程块，或者给了线程块，只需要设计网格；主函数中的固定流程；关键在写核函数；\n并行计算并发与并行串行：单机单核，指令顺序执行。并发：单机单核，指令在时间上并行执行，同一时间间隔发生。并行：单机多核，多机单&#x2F;多核，指令在空间上并行，同一时刻发生。并行计算就是在并行计算机或者分布式系统等高性能计算系统上做的超级计算。并行计算可以降低单个问题求解的时间，增加求解规模与精度，提高吞吐率等。\n三种分类：计算模式：时间并行（流水线）、空间并行（多处理器）程序逻辑：任务并行、数据并行应用角度：计算密集、数据密集、网络密集\nFlynn分类法依据指令流(instruction stream)和数据流(data stream)的执行方式对并行计算机体系结构分类的一种方法。包含SISD(早期串行机）,SIMD（单核计算机）,MISD（很少用）,MIMD（多核计算机，并行）;\nAmdahl定律假定任务数量一定，通过计算性能加速比，揭示了一个程序中无法并行化的部分会限制整个程序的性能提升的规律。$$S&#x3D;\\frac{W_{s}+W_{p}}{W_{s}+W_{p}&#x2F;p}$$其中$W_{s}$为串行任务数量，$W_{p}$为并行任务数量，$p$为处理器数目，$S$为加速比。依据串行分量的占比$f&#x3D;W_{s}&#x2F;W$，将上式同时除以$W$可得下面的式子：$$S&#x3D;\\frac{f+(1-f)}{f+\\frac{1-f}{p}} &#x3D;\\frac{p}{1+f(p-1)}$$$\\lim_{x\\rightarrow \\infty}S&#x3D;1&#x2F;f$，当处理器的数目无限增大时，系统能达到的加速比受制于程序中的串行部分。\ntxt1.一个串行应用程序中，有20%的比例必须串行执行，现在需要实现3倍的性能提升，为实现这个目标，需要多少个CPU？如果要实现5倍的加速比，需要多少个CPU？\n2.一个运行在5个计算机上的并行程序，有10%的并行部分。相对于在一个计算机上的串行执行，加速比是多少？如果我们想将加速比提升2倍，需要多少个CPU？\n3.将一个不可并行部分占5%的应用程序修改为并行程序。目前市场上有两种并行计算机：计算机X有4个CPU，每个CPU可以在1个小时内完成该应用程序的执行；计算机Y有16个CPU，每个CPU可以在2个小时内执行完该应用程序。如果需要最小化运行时间，请问你该买哪个计算机？CUDA概述异构计算GPU的并行计算是一种异构计算，分为主机端（CPU）和设备端（GPU），二者关系从来都不是平等的，CUDA甚至需要明确标识代码需要在哪运行。\nCPU和GPU的差异\n\n\n\n\n\n\n\n\n直观来说，CPU更多资源用于缓存与控制流，GPU则是更多的数据计算。\n\n在GPU环境下，GPU的核心负责所有计算任务的执行，但工作指令总是来自CPU。\n在GPU情况下，GPU核心从不自己获取数据，数据总是来自CPU端，计算结果再传回CPU端。因此，GPU在后台只是扮演计算加速器的角色，为CPU完成某些外包任务。\n这种类型的体系架构只有在有着大量的并行处理单元，而不是仅有2个或4个时，才会非常有效。\n线程束的概念对GPU的体系结构有重大影响。数据必须以同样大小的数据块为单位输入GPU，数据块是半个线程束，即16个元素。\n数据必须以半个线程束的大小传输给GPU核心的事实意味着负责将数据传入GPU的存储系统应该每次输入16个数据。这需要一次能够传输16个数的并行存储子系统。这就是为什么GPU的DRAM存储器是由DDR5构成的，因为它是并行存储器。\n由于GPU核心和CPU核心是完全不同的处理单元，因此可以预见它们具有不同的ISA（指令集架构）。即：它们说的是不同的语言。GPU线程与CPU线程也有所不同，创建开销极低。CPU通过多级cache缩减延迟，而GPU是通过流水线提高吞吐量来缩减延迟的。由于其设计目标的不同，CPU需要很强的通用性来处理各种不同的数据类型，同时逻辑判断又会引入大量的分支跳转和中断的处理。而GPU面对的则是类型统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。\n\n\nCUDA线程组织形式Thread：并行的基本单位Thread Block：互相合作的线程组允许彼此同步通过快速共享内存交换数据以1维、2维或3维组织最多包含1024个线程Grid：一组线程块以1维、2维组织，也可3维共享全局变量Kernel：在GPU上执行的核心程序One kernel             One Grid\nCUDA主机&#x2F;设备编程模型函数限界符\n_ device _:在device端执行，并且也只能从device端调用，即作为device端的子函数来使用。\n_ host _:在host端执行，也只能从host端调用，与一般的C函数相同。不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。\n_ global _ :即kernel函数，它在设备上执行，但是要从host端调用。\n\nCUDA核函数的限制\n只能访问设备内存\n必须返回void类型\n不支持可变数量的参数\n不支持静态变量\n显示异步行为，意味着host不会等待kernel执行完就执行下一步\n\n并行计算模型SIMT线程块是程序启动的基本单位，线程束是程序执行的单位；\n\n\n\n\n\n\n\n\n\n例如，我们说一个块大小是256个线程时，也就是意味着线程块大小为8个线程束。每个线程束总是包含32个线程。这个参数表明：虽然启动程序时，每个线程块有256个线程，但这并不意味着它们会立即执行，也就是说这256个线程并不会在同一时刻都被执行或完成执行。相反，GPU的执行硬件会用8个线程束来执行这些线程。\nSIMT属于SIMD的范畴，因为它也是在多个数据上执行相同的指令。但是，SIMT允许由用户来分配线程，具体来说就是CUDA为每个线程指定了标识符（编号）。一个关键的区别就是SIMD要求同一个向量中的所有元素要在一个统一的同步组中一起执行，而SIMT则允许属于同一个线程束的多个线程独立执行，这几个线程可以有不同的行为。因此SIMT允许线程级并发，也就是在统一线程束下的线程可以同时做不同的事情。三个不同：\n\n每个线程都有自己的指令地址计数器\n每个线程都有自己的寄存器状态\n每个线程可以有一个独立的执行路径\n\nGPU架构流式多处理器SM一个线程块只能在一个SM上被调度，但一个SM可以对应多个线程块。当SM指定了一个或多个要计算的线程块时，这些线程块会被分为多个warp，等待调度。线程束中的线程都在不同的数据上执行相同的命令。SM容纳线程块的数量，取决于SM内的共享内存和寄存器以及线程占用的资源。线程块里的所有线程在逻辑上并行运行，但并不是所有的线程都可以同时在物理层面执行。（一个SM同时只调度一个warp，其余warp等待，不同的warp间的切换是零开销的因为warp的执行上下文在warp的整个生命周期都会被SM维护）\n\n\n\n\n\n\n\n\n\nNVIDIA GeForce RTX 3090的Compute Capabilities是8.6，其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，求：理论上同一时刻并行执行线程数量为多少？并发执行线程数量为多少？其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，即最多可以存在48个warp，由于warp是通过warp调度器并发执行，warp中32条线程是并行执行，因此笼统上可以认为，同一时刻并行执行线程数量为82*32&#x3D;2624，并发执行线程数量为82*32*48&#x3D;125952。\n内存模型\n\n\n存储器\n位置\n是否缓存\n访问权限\n生存周期\n\n\n\n寄存器\n片上\n无\ndevice\n与线程、核函数相同\n\n\n共享内存\n片上\n无\ndevice\n与block相同\n\n\n本地内存\n板载\n无\ndevice\n与线程、核函数相同\n\n\n全局内存\n板载\n无\ndevice&amp;host\n程序\n\n\n纹理内存、常量内存\n板载\n有\ndevice&amp;host\n程序\n\n\n\n\n\n\n\n\n\n\n\n定义在CUDA核函数中的变量，什么时候是寄存器变量，什么时候是本地变量呢？\n以下三种情况是本地变量，其余则寄存器变量\n\n编译阶段无法确定的数组\n数组或结构体占用的空间很大\n核函数中定义了很多的变量，寄存器装不下、从寄存器溢出到本地内存的，本质上与全局内存在同一个存储区域\n\n\n内存访问模式全局内存通过缓存来实现加载&#x2F;存储。所有对全局内存的访问都会通过L2 cache（一般128字节）。对齐访问第一个地址是缓存粒度（一般32字节）的偶数倍（cache line取数据开始位置就是如此）合并访问一个线程束中的全部线程访问一个连续的内存块。合并访问指的是线程束对全局内存的一次访问请求导致最少的数据传输（合并度&#x3D;100%），否则是非合并访问。\n5种访问方式，合并度的计算？？ \n如果说读取和写入都不能合并访问，那么应该优先保证合并写入。只读数据的非合并访问，可以用__ldg()函数做缓存，也可以用共享内存转换为合并地。\n共享内存与bank conflict共享内存可以被程序员直接操控。共享内存被划分为许多的banks.\n\n一个warp中的所有线程访问同一bank同一地址-广播\n一个warp中的不同线程访问一个bank的不同地址-bank conflict\n多个线程访问同一bank同一地址-多播\n\nMemory Padding 内存填充解决Bank confilctPadding操作：在sData的第二维+1，即sData[BS][BS+1]填充的部分不能用于数据存储，导致可用的共享内存数量减少。\n代码图像翻转CPU多线程翻转图像，同时手动维护缓存。\ncvoid * MTFlipHM(void * tid)&#123;\n        struct Pixel pix; //temp swap pixel\n        int row, col;\n        int id = *((int *) tid);\n        int start = id * ip.Vpixels/NumThreads;\n        int end = start + ip.Vpixels/NumThreads;\n        unsigned char buffer[16384];\n        for (row = st ; row &lt; ed; row++)\n        &#123;\n            memcpy(buffer, TheImage[row], ip.Hbytes);\n            col = 0;\n            while (col &lt; ip.Hpixels * 3 /2)&#123;\n            pix.B = buffer[col];\n            pix.G = buffer[col+1];\n            pix.R = buffer[col+2];\n            buffer[col]   = buffer[ip.Hpixels*3 - col -3];\n            buffer[col+1] = buffer[ip.Hpixels*3 - col -2];\n            buffer[col+2] = buffer[ip.Hpixels*3 - col -1];\n            buffer[ip.Hpixels*3 - col -3] = pix.B;\n            buffer[ip.Hpixels*3 - col -2] = pix.G;\n            buffer[ip.Hpixels*3 - col -1] = pix.R;\n            col += 3;\n            &#125;\n        &#125;\n        memcpy(TheImage[row],buffer,ip.Hbytes);\n        pthread_exit(NULL);\n&#125;\n\nvoid * MTFlipVM(void * tid)&#123;\n        struct Pixel pix; //temp swap pixel\n        int row, col;\n        int id = *((int *) tid);\n        int start = id * ip.Vpixels/NumThreads;\n        int end = start + ip.Vpixels/NumThreads;\n        unsigned char buffer1[16384], buffer2[16384];\n        for (row = start; row &lt; end; row ++)\n        &#123;\n            memcpy(buffer1,TheImage[row],ip.Hbytes);\n            int  mirrow = ip.Vpixels - 1 - row;\n            memcpy(buffer2,TheImage[mirrow],ip.Hbytes);\n            // 再错位拷贝即完成交换\n            memcpy(TheImage[row],buffer2,ip.Hbytes);\n            memcpy(TheImage[mirrow],buffer1,ip.Hbytes);\n        &#125;\n&#125;\n\npthread_create(&amp;ThHandle[i], &amp;ThAttr, MTFlipFunc, (void *)&amp;ThParam[i]);\nfor(i=0; i&lt;NumThreads; i++)\n                pthread_join(ThHandle[i], NULL);数组相加cppconst int a=1, b=2, c=3;\n__global__ void add(double *x, double *y, double* z)&#123;\n    const int n = blockIdx.x * blockDim.x + threadIdx.x;\n    if (n&lt;N)  z[n] = x[n] + y[n];\n&#125;\nint main()&#123;\n    const int N = 1e9;\n    const int M = sizeof(double) * N;\n    double *h_x = (double*) malloc(M);\n    double *h_y = (double*) malloc(M);\n    double *h_z = (double*) malloc(M);\n    for (int i=0; i&lt;N; i++)\n    &#123;\n        h_x[i] = a;\n        h_y[i] = b;\n    &#125;\n    double *d_x, *d_y, *d_z;\n    cudaMalloc((void**) &amp;d_x, M);\n    cudaMalloc((void**) &amp;d_y, M);\n    cudaMalloc((void**) &amp;d_z, M);\n\n    const int block_size =  128;\n    int grid_size = (N+block_size-1) / block_size;\n    add&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, d_z);\n    cudaMemcpy(h_z, d_z, M, cudaMemcpyDeviceToHost);\n    free(h_x),free(h_y),free(h_z);\n    cudaFree(d_x),cudaFree(d_y),cudaFree(d_z);\n&#125;图像翻转cpp__global__ void Vflip(uch *ImgDst, uch *ImgSrc, ui Hpixels, ui Vpixels)&#123;\nui ThrPerBlk = blockDim.x;\nui MYbid = blockIdx.x;\nui MYtid = threadIdx.x;\nui MYgtid = ThrPerBlk * MYbid + MYtid;\nui BlkPerRow = (Hpixels + ThrPerBlk - 1) / ThrPerBlk; // ceil\nui RowBytes = (Hpixels * 3 + 3) &amp; (~3);\nui MYrow = MYbid / BlkPerRow;\nui MYcol = MYgtid - MYrow*BlkPerRow*ThrPerBlk;\nif (MYcol &gt;= Hpixels) return;// col out of range\nui MYmirrorrow = Vpixels - 1 - MYrow;\nui MYsrcOffset = MYrow * RowBytes;\nui MYdstOffset = MYmirrorrow * RowBytes;\nui MYsrcIndex = MYsrcOffset + 3 * MYcol;\nui MYdstIndex = MYdstOffset + 3 * MYcol;\n// swap pixels RGB @MYcol , @MYmirrorcol\nImgDst[MYdstIndex] = ImgSrc[MYsrcIndex];\nImgDst[MYdstIndex + 1] = ImgSrc[MYsrcIndex + 1];\nImgDst[MYdstIndex + 2] = ImgSrc[MYsrcIndex + 2];&#125;\n\n__global__ void Hflip(uch *ImgDst, uch *ImgSrc, ui Hpixels)&#123;\nui ThrPerBlk = blockDim.x;\nui MYbid = blockIdx.x;\nui MYtid = threadIdx.x;\nui MYgtid = ThrPerBlk * MYbid + MYtid;\nui BlkPerRow = (Hpixels + ThrPerBlk -1 ) / ThrPerBlk; // ceil\nui RowBytes = (Hpixels * 3 + 3) &amp; (~3);\nui MYrow = MYbid / BlkPerRow;\nui MYcol = MYgtid - MYrow*BlkPerRow*ThrPerBlk;\nif (MYcol &gt;= Hpixels) return;// col out of range\nui MYmirrorcol = Hpixels - 1 - MYcol;\nui MYoffset = MYrow * RowBytes;\nui MYsrcIndex = MYoffset + 3 * MYcol;\nui MYdstIndex = MYoffset + 3 * MYmirrorcol;\n// swap pixels RGB @MYcol , @MYmirrorcol\nImgDst[MYdstIndex] = ImgSrc[MYsrcIndex];\nImgDst[MYdstIndex + 1] = ImgSrc[MYsrcIndex + 1];\nImgDst[MYdstIndex + 2] = ImgSrc[MYsrcIndex + 2];&#125;矩阵转置cpp__global__ void transpose(int a[], int b[], int N)&#123;\n    //分配共享内存\n    __shared__ int S[TILE][TILE + 1];\n    int bx = blockIdx.x * TILE;\n    int by = blockIdx.y * TILE;\n    int ix = bx + threadIdx.x;\n    int iy = by + threadIdx.y;\n    if (ix &lt; N &amp;&amp; iy &lt; N)// 读入共享内存\n        S[threadIdx.y][threadIdx.x] = a[iy * N + ix];\n    __syncthreads();//同步，这是必不可少的\n    int ix2 = bx + threadIdx.y;\n    int iy2 = by + threadIdx.x;\n    if (ix2 &lt;N &amp;&amp; iy2 &lt; N)// 写回\n        b[ix2 * N + iy2 ] = S[threadIdx.x][threadIdx.y];\n&#125;方阵相乘cpp__shared__ float Mds[WIDTH][TILE_WIDTH];\n__shared__ float Nds[TILE_WIDTH][WIDTH];\nint bx=blockIdx.x ; int by = blockIdx.y;\nint tx=threadIdx.x ; int ty = threadIdx.y;\nint Row = by *TILE_WIDTH +ty;\nint Col = bx*TILE_WIDTH + tx;\nfloat Pvalue = 0;\nfor(int m=0; m&lt;WIDTH/TILE_WIDTH; ++m)\n    &#123;\n    // 每个线程载入M的子矩阵的一个元素\n    Mds[ty][tx] = Md[Row*width+(m*TILE_WIDTH+tx)];\n    //每个线程载入N的子矩阵的一个元素\n    Nds[ty][tx] = Nd[(m*TILE_WIDTH+ty)*width+Col];\n     __syncthreads();\n     for (int k = 0; k &lt; TILE_WIDTH; ++k)\n        Pvalue += Mds[ty][k] * Nds[k][tx];\n     __syncthreads();\n     &#125;\nPd[Row*WIDTH+Col] = Pvalue;//将结果写回P矩阵直方图cpp#define SIZE (100*1024*1024)\n//通过工具函数big_random_block()来生成随机的字节流\nunsigned char *buffer =(unsigned char*)big_random_block( SIZE );\nunsigned int histo[256];\nfor (int i = 0; i&lt;256; i++)\n    histo[i] = 0;\nfor (int i = 0; i &lt; SIZE; i++)\n    histo[buffer[i]]++;\nlong histoCount = 0;\nfor (int i = 0; i&lt;256; i++) &#123;\n    histoCount += histo[i]; &#125;\n\n__global__ void histo_kernel(unsigned char *buffer, long size, unsigned int *histo)&#123;\n__shared__ unsigned int temp[256];\ntemp[threadIdx.x] = 0;\n__syncthreads();\nint i = threadIdx.x + blockIdx.x * blockDim.x;\nint offset = blockDim.x *gridDim.x;\nwhile (i&lt;size)&#123;\n    atomicAdd(&amp;temp[buffer[i]], 1);\n    i += offset;\n&#125;\n__syncthreads();\natomicAdd(&amp;(histo[threadIdx.x]), temp[threadIdx.x]);\n&#125;规约求和规约求和与TOP K类似，下面的代码为官方代码，理解参考这篇文章 \ncpp__global__ void _sum_gpu(int *input, int count, int *output)\n&#123;\n    __shared__ int sum_per_block[BLOCK_SIZE];\n\n    int temp = 0;\n    for (int idx = threadIdx.x + blockDim.x * blockIdx.x;\n         idx &lt; count; idx += gridDim.x * blockDim.x\n    )\n    &#123;// 跨网格循环，一个线程加多个数据，应对海量数据\n        temp += input[idx];\n    &#125;\n\n    sum_per_block[threadIdx.x] = temp;  //the per-thread partial sum is temp!\n    __syncthreads();\n\n    //**********shared memory summation stage***********\n    for (int length = BLOCK_SIZE / 2; length &gt;= 1; length /= 2)\n    &#123;\n        int double_kill = -1;\n    if (threadIdx.x &lt; length)\n    &#123;\n        double_kill = sum_per_block[threadIdx.x] + sum_per_block[threadIdx.x + length];\n    &#125;\n    __syncthreads();  //why we need two __syncthreads() here, and,\n    \n    if (threadIdx.x &lt; length)\n    &#123;\n        sum_per_block[threadIdx.x] = double_kill;\n    &#125;\n    __syncthreads();  //....here ?\n    \n    &#125; //the per-block partial sum is sum_per_block[0]\n\n    if (blockDim.x * blockIdx.x &lt; count) //in case that our users are naughty\n    &#123;\n        //the final reduction performed by atomicAdd()\n        if (threadIdx.x == 0) atomicAdd(output, sum_per_block[0]);\n    &#125;\n&#125;\nTOP K具体实现流程如下：\n\n将数据复制到GPU显存中 float *d_data; cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);\n将数据存储到二元组中\n\ncpptypedef struct &#123;     float value;     int index; &#125; Tuple;  \nTuple *d_tuples; \nint threadsPerBlock = 256; \nint blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\ninitializeTuples&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_data, d_tuples, n);\n对二元组进行归约操作，得到前K个最大&#x2F;最小值的索引\n\ncppint *d_indices;\nkReduceKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_tuples, d_indices, n, k);\n__global__ void kReduceKernel(Tuple *input, int *output, int n, int k) &#123;\n    extern __shared__ Tuple shared[];\n    int tid = threadIdx.x;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    shared[tid] = (i &lt; n) ? input[i] : Tuple&#123;0, 0&#125;;\n    __syncthreads();\n    for (int s = blockDim.x / 2; s &gt; 0; s &gt;&gt;= 1) &#123;\n        if (tid &lt; s)\n            shared[tid] = (shared[tid].value &gt; shared[tid + s].value) ? shared[tid] : shared[tid + s];\n        __syncthreads();\n    &#125;\n\n    if (tid == 0)\n        output[blockIdx.x] = shared[0].index;\n&#125;\n在CPU中恢复原始数据并按照索引排序，得到前K个最大&#x2F;最小值\n\ncppcudaMemcpy(h_indices, d_indices, size, cudaMemcpyDeviceToHost);  \nfor (int i = 0; i &lt; k; ++i) &#123;     \n    int index = h_indices[i];     \n    h_result[i] = h_data[index]; &#125;  \nstd::sort(h_result, h_result + k);完成以上步骤后，就可以得到排序后的前K个最大&#x2F;最小值了。\n实验实验一：PI的三种求法、线程池实验二：矩阵相乘、转置、规约、TOP K 问题全局内存、共享内存优化、bank冲突优化手写并行计算报告3-4页纸 cpu pi三种求法 生产者消费者模式 GPU 主程序流程明确一次即可，核函数不同，重点全局内存与共享内存实现， 矩阵相乘直方图(跨网格循环)规约100w数组中的最大值 报告在考试时上交\n20级真题简答题Amdel定律，处理器n个，串行40%，求加速比极限。给RGB图像680*480，分4个线程（没说怎么分），每个线程处理的像素范围和字节范围；PPT线程束并行并发数量的例题原题；\n\n\n\n\n\n\n\n\n\nNVIDIA GeForce RTX 3090的Compute Capabilities是8.6，其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，求：理论上同一时刻并行执行线程数量为多少？并发执行线程数量为多少？其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，即最多可以存在48个warp，由于warp是通过warp调度器并发执行，warp中32条线程是并行执行，因此笼统上可以认为，同一时刻并行执行线程数量为82*32&#x3D;2624，并发执行线程数量为82*32*48&#x3D;125952。\n矩阵转置过程的某个元素全局id；问元素3的全局id可不可以一边复制数据，一边转置（CUDA流）；\n程序分析题第一题，课堂练习原题；&lt;4,4&gt;改成了&lt;5,5&gt;；要说明过程；第二题，少了原子操作的直方图规约，问有什么问题；\nCPU编程求数组a[2,1000000]中的素数，要求10个线程等分；线程池伪代码：客户端、服务端（邮件功能、导出功能、流量统计等一堆功能）；\nGPU编程全局内存的矩阵相乘；向量a,b内积，维数&#x3D;1024000000；定死blockdim.x &#x3D; blockdim.y &#x3D;16; 设计Grid；要求用共享内存优化、解决bank冲突、输出结果回到CPU做最终合并。\n感受：非代码题宝宝巴士，代码题重拳出击，根本写不完。\n","slug":"并行计算复习课","date":"2023-05-11T08:38:15.000Z","categories_index":"大数据","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"e17b6e9deb446fd76186e024fdae4f45","title":"并行编程实验二","content":"实验目的\n掌握CUDA网格和线程块的设计\n实践CUDA运行时API的使用\n通过编写核函数，掌握利用GPU众核对大规模问题的求解加速的方法\n体会CPU多核与GPU众核这两种不同体系结构带来的程序设计上的差异\n\n实验内容矩阵转置算法流程\n将需要转置的矩阵存储到GPU内存中。\n在GPU上分配空间存储转置后的矩阵。\n定义CUDA核函数来实现矩阵转置。该核函数应该使用线程块和线程格的概念来处理矩阵中的所有元素。在每个线程块中，线程可以使用共享内存来处理数据。最后，利用全局内存将结果写回到GPU。\n调用CUDA核函数以执行矩阵转置。\n将转置后的矩阵从GPU内存复制到主机内存中。\n释放GPU内存\n\n代码实现在传统代码的基础上，利用共享内存优化访问全局内存的方式，同时使用padding操作，避免bank冲突。\ncppconst int N = 10000;\nconst int TILE_DIM = 32;\nconst int grid_size_x = (N + TILE_DIM - 1) / TILE_DIM;\nconst int grid_size_y = grid_size_x;\nconst dim3 block_size(TILE_DIM, TILE_DIM);\nconst dim3 grid_size(grid_size_x, grid_size_y);\n__global__ void transpose(const float *A, float *B, const int N)&#123;  \n    __shared__ float S[TILE_DIM][TILE_DIM+1];\n    int bx = blockIdx.x * TILE_DIM;\n    int by = blockIdx.y * TILE_DIM;\n    //顺序读\n    int nx1 = bx + threadIdx.x;\n    int ny1 = by + threadIdx.y;\n    if (nx1 &lt; N &amp;&amp; ny1 &lt; N)\n        S[threadIdx.y][threadIdx.x] = A[ny1 * N + nx1];\n    __syncthreads();\n    //顺序写\n    int nx2 = bx + threadIdx.y;\n    int ny2 = by + threadIdx.x;\n    if (nx2 &lt; N &amp;&amp; ny2 &lt; N)\n        B[nx2 * N + ny2] = S[threadIdx.x][threadIdx.y];\n&#125;\n\nint main()&#123;  \n    int nn = N * N;\n    int nBytes = nn * sizeof(float);\n    float a = 1.1;\n    float b = 2.2;\n    //cpu空间分配\n    float* A = (float*)malloc(nBytes);\n    float* B = (float*)malloc(nBytes);\n    //矩阵初始化\n    for (int i = 1; i &lt;= nn; i++) &#123;\n        if (i % 2 == 0)\n            A[i-1] = a;\n        else\n            A[i-1] = b;\n    &#125;\n    //gpu空间分配（需要先定义）\n    float* d_A, * d_B;\n    cudaMalloc((void**)&amp;d_A, nBytes);\n    cudaMalloc((void**)&amp;d_B, nBytes);\n    cudaMemcpy(d_A, A, nBytes, cudaMemcpyHostToDevice);\n    transpose&lt;&lt;&lt;grid_size, block_size &gt;&gt;&gt; (d_A, d_B, N);\n    cudaMemcpy(B, d_B, nBytes, cudaMemcpyDeviceToHost);\n    free(A);\n    free(B);\n    cudaFree(d_A);\n    cudaFree(d_B);\n    return 0;\n&#125;矩阵相乘核函数设计共享内存的使用：应该将两个原始矩阵的一部分抽取出来，当作瓦片，放入共享内存，减少对全局内存的访问，从而提高程序性能。非方阵处理：非方阵的两个矩阵相乘，需要调整共享内存中瓦片的尺寸，同时需要添加判断语句，防止发生越界错误。\n代码实现cpp__global__ void matrixmul(const float *A, const float *B, float *C,const int N,const int M,const int K)&#123;   //N*M x M*K\n    __shared__ float A_S[TILE_DIM][TILE_DIM];\n    __shared__ float B_S[TILE_DIM][TILE_DIM];\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int row = by * TILE_DIM + ty;\n    int col = bx * TILE_DIM + tx;\n    float value = 0;\n    for (int ph = 0; ph &lt; M / TILE_DIM+1; ph++) &#123;\n        if (row &lt; N &amp;&amp; ph * TILE_DIM + tx &lt; M)\n            A_S[ty][tx] = A[row * M + ph * TILE_DIM + tx];\n        else\n            A_S[ty][tx] = 0.0;\n        if (col &lt; K &amp;&amp; ph * TILE_DIM + ty &lt; M) \n            B_S[ty][tx] = B[(ph * TILE_DIM + ty) * K + col];\n        else\n            B_S[ty][tx] = 0.0;\n        __syncthreads();\n\n        for (int k = 0; k &lt; TILE_DIM; k++)\n            value += A_S[ty][k] * B_S[k][tx];\n        __syncthreads();\n    &#125;\n\n    if (row &lt; N &amp;&amp; col &lt; K)\n        C[row*K+col]=value;\n&#125;统计直方图共享内存的使用：在共享内存开辟临时数组，减少对全局内存的访问，从而提高程序性能。跨网格循环：数据量很大，一个线程要处理多个数据。原子操作：无论是共享内存还是全局内存的结果，都需要使用原子操作，避免冲突\ncpp__global__ void histo_kernel(unsigned char *buffer, long size, unsigned int *histo)&#123;\n    __shared__ unsigned int temp[256];\n    temp[threadIdx.x] = 0;\n    __syncthreads();\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int offset = blockDim.x *gridDim.x;\n    while (i&lt;size)&#123;\n        atomicAdd(&amp;temp[buffer[i]], 1);\n        i += offset;\n    &#125;\n    __syncthreads();\n    atomicAdd(&amp;(histo[threadIdx.x]), temp[threadIdx.x]);\n&#125;规约求和跨网格循环：对于海量数据(&gt;100w)，即使是GPU众核，也做不到这么多的线程，因此一个线程要处理多个数据。共享内存优化：将每个线程对多个元素求和的结果存于共享内存，可以减少对全局内存的访问。交错配对法：利用交错配对法进行规约，可以缓解一部分的线程束分化现象。原子操作:将结果累加到全局内存中，可能会发生冲突，需要使用原子操作。\ncpp__global__ void _sum_gpu(int *input, int count, int *output)\n&#123;\n    __shared__ int sum_per_block[BLOCK_SIZE];\n\n    int temp = 0;\n    for (int idx = threadIdx.x + blockDim.x * blockIdx.x;\n         idx &lt; count; idx += gridDim.x * blockDim.x\n    )\n        temp += input[idx];\n    sum_per_block[threadIdx.x] = temp;\n    __syncthreads();\n\n    //**********shared memory summation stage***********\n    for (int length = BLOCK_SIZE / 2; length &gt;= 1; length /= 2)\n    &#123;\n        int double_kill = -1;\n    if (threadIdx.x &lt; length)\n        double_kill = sum_per_block[threadIdx.x] + sum_per_block[threadIdx.x + length];\n    __syncthreads();  //why we need two __syncthreads() here, and,\n    \n    if (threadIdx.x &lt; length)\n        sum_per_block[threadIdx.x] = double_kill;\n    __syncthreads(); \n    &#125; //the per-block partial sum is sum_per_block[0]\n\n    if (threadIdx.x == 0) atomicAdd(output, sum_per_block[0]);\nTOP K 问题TOP K问题是指在一组数据中，找到前K个最大或最小的元素。利用CUDA规约计算可以高效地解决TOP K问题。以下是利用CUDA规约计算来实现排序和选择前K个最大&#x2F;最小元素的详细步骤：\n\n定义一个二元组类型，包含值和索引，用于存储原始数据及其索引（为了在排序后恢复原始数据）\n对原始数据进行遍历，将数据存储到二元组中\n对二元组进行归约操作，得到前K个最大&#x2F;最小值的索引\n恢复原始数据并按照索引排序，得到前K个最大&#x2F;最小值\n\n具体实现流程如下：\n\n将数据复制到GPU显存中 float *d_data; cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);\n将数据存储到二元组中\n\ncpptypedef struct &#123;     float value;     int index; &#125; Tuple;  \nTuple *d_tuples; \nint threadsPerBlock = 256; \nint blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\ninitializeTuples&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_data, d_tuples, n);\n对二元组进行归约操作，得到前K个最大&#x2F;最小值的索引\n\ncppint *d_indices;\nkReduceKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_tuples, d_indices, n, k);\n__global__ void kReduceKernel(Tuple *input, int *output, int n, int k) &#123;\n    extern __shared__ Tuple shared[];\n    int tid = threadIdx.x;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    shared[tid] = (i &lt; n) ? input[i] : Tuple&#123;0, 0&#125;;\n    __syncthreads();\n    for (int s = blockDim.x / 2; s &gt; 0; s &gt;&gt;= 1) &#123;\n        if (tid &lt; s)\n            shared[tid] = (shared[tid].value &gt; shared[tid + s].value) ? shared[tid] : shared[tid + s];\n        __syncthreads();\n    &#125;\n\n    if (tid == 0)\n        output[blockIdx.x] = shared[0].index;\n&#125;\n在CPU中恢复原始数据并按照索引排序，得到前K个最大&#x2F;最小值\n\ncppcudaMemcpy(h_indices, d_indices, size, cudaMemcpyDeviceToHost);  \nfor (int i = 0; i &lt; k; ++i) &#123;     \n    int index = h_indices[i];     \n    h_result[i] = h_data[index]; &#125;  \nstd::sort(h_result, h_result + k);完成以上步骤后，就可以得到排序后的前K个最大&#x2F;最小值了。\n实验感受","slug":"并行编程实验二","date":"2023-05-08T12:14:19.000Z","categories_index":"大数据","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"243ac045dab981a42c4921f3f7cacfa2","title":"概率论","content":"主要参考\n贝叶斯公式\n\n\n\n\n\n\n\n\n贝叶斯学派认为没有什么是随机的，如果有，那一定是信息不够（香农信息论）；贝叶斯学派（统计学）-&gt; 贝叶斯学习(机器学习)\n贝叶斯公式给了我们一种能力，即在事件发生后，通过事件发生前的各种概率进行推理的能力。\n\n\n\n\n\n\n\n\n\n无意中使用贝叶斯的例子：一个笑话——水是剧毒的，因为罹患癌症的人都喝过水。无意中被贝叶斯欺骗的例子：检出率很高的诊疗方法（准确率99.9%），误诊率是极高的(&gt;50%)。因为自然人群中患病率(&lt;1%)。概率论统计学真是任人装扮的小姑娘。\n从机器学习的角度来理解贝叶斯公式（朴素贝叶斯分类器)读作P c given x, 左侧是后验概率，是先验概率prior， 是似然值(likelihood)，是模型重点学习的部分。对于所有的输入样本都是一样的，是用来归一化的（计算时用全概率公式展开）；对的估计可以采用极大似然估计Maximum Likelihood Estimation的方法。(西瓜书P148)从一般的角度来理解（可能不太准确)是一件事的原始概率，当发生了一些事之后（或是我们知道它发生了，这就跑到贝叶斯学派和频率学派的分歧点了），是被修正的概率，修正因子就是 。\n太深了，浅看就一公式，深层竟然是世界观方法论，越看越迷糊\nFAQ\n什么是先验概率？事情未发生，只根据以往数据统计，分析事情发生的可能性，即先验概率。指根据以往经验和分析。在实验或采样前就可以得到的概率。先验概率是指根据以往经验和分析得到的概率，如全概率公式，它往往作为”由因求果”问题中的”因”出现。\n\n什么是后验概率？与先验概率的关系？\n\n\n\n后验概率事情已发生，已有结果，求引起这事发生的因素的可能性，由果求因，即后验概率。指某件事已经发生，想要计算这件事发生的原因是由某个因素引起的概率。后验概率是指依据得到”结果”信息所计算出的最有可能是那种事件发生,如贝叶斯公式中的,是”执果寻因”问题中的”因”。\n与先验概率的关系后验概率的计算，是以先验概率为前提条件的。如果只知道事情结果，而不知道先验概率（没有以往数据统计），是无法计算后验概率的。后验概率的计算需要应用到贝叶斯公式。\n\n\n全概率公式、贝叶斯公式与先验、后验概率的关系？全概率公式，总结几种因素，事情发生的概率的并集。由因求果。贝叶斯公式，事情已经发生，计算引起结果的各因素的概率，由果寻因。同后验概率。全概率是用原因推结果，贝叶斯是用结果推原因\n\n","slug":"概率论","date":"2023-04-21T12:10:13.000Z","categories_index":"数学","tags_index":"学习笔记,统计学","author_index":"以太工坊"},{"id":"ac8a9fab2e0576f4044deb8564018f33","title":"并行编程实验一","content":"实验内容实验内容一：以数据划分的方式并行计算PI值\n实验内容二：CPU多核编程——线程池开发要求基于生产者—消费者模式进行框架开发，具体工作需求可以简化，但需要有线程管理和同步。\n计算Pi思路简述依据莱布尼兹公式，通过多线程计算较多的次数，逼近$\\pi$ 。用多线程的方式进行数据划分、即每个线程分担处理部分数据，从而进行加速。同时由于多线程访问全局的结果可能会有冲突，因此使用互斥量和信号量组织线程有序将局部结果加到全局结果中。\n代码实现c#include &lt;pthread.h&gt;  \n#include &lt;stdio.h&gt;  \n#include &lt;stdlib.h&gt;  \n#include &lt;math.h&gt;  \n\nconst int BLOCK_SIZE = 100000;  \ndouble sum = 0;  \nint num_threads;  \n// 定义互斥量和条件变量  \npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;  \npthread_cond_t cond = PTHREAD_COND_INITIALIZER;  \nvoid *calculate_block(void *thread_id)  \n&#123;  \n    long id = (long)thread_id;  \n    int start = id * BLOCK_SIZE;  \n    int end = start + BLOCK_SIZE;  \n    double block_sum = 0;  \n    for (int i = start; i &lt; end; i++) &#123;  \n        double term = pow(-1, i) / (2 * i + 1);  \n        block_sum += term;  \n    &#125;  \n    pthread_mutex_lock(&amp;mutex);  \n    sum += block_sum;    \n    pthread_mutex_unlock(&amp;mutex);  \n    pthread_cond_signal(&amp;cond);  \n&#125;  \n\nint main()  \n&#123;  \n    num_threads = 8;  \n    pthread_t threads[num_threads];  \n    for (long i = 0; i &lt; num_threads; i++)\n        pthread_create(&amp;threads[i], NULL, calculate_block, (void *)i);  \n    for(int i = 0; i &lt; num_threads; i ++)\n        pthread_join(threads[i], NULL);\n    printf(&quot;%lf&quot;, sum * 4);\n&#125;线程池设计线程池实现使用一个任务队列作为生产者和消费者之间的缓冲区，任务队列中的每一个元素包含要执行的函数和函数参数，对应代码如下:\nctypedef struct task_t &#123;\n    void (*func)(void *);\n    void *arg;\n&#125; task_t;线程池包含一个任务队列、若干线程、互斥量与信号量以及其它关键属性，定义如下：\nctypedef struct thread_pool_t &#123;\n    pthread_t threads[MAX_THREADS];\n    int num_threads;\n    task_t queue[MAX_QUEUE];\n    int front, rear, size;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n    bool shutdown;\n&#125; thread_pool_t;在生产者方面，thread_pool_enqueue函数用于将任务添加到任务队列中。当生产者生产了一个任务后，它首先会通过线程池的互斥锁pool-&gt;mutex来保护任务队列，防止多个线程同时修改任务队列，然后使用条件变量pool-&gt;cond来通知消费者有新的任务到达。\ncbool thread_pool_enqueue(thread_pool_t *pool, void (*func)(void *), void *arg)&#123;\n    pthread_mutex_lock(&amp;pool-&gt;mutex);\n    if (pool-&gt;size == MAX_QUEUE) &#123;\n        pthread_mutex_unlock(&amp;pool-&gt;mutex);\n        return false;\n    &#125;\n    task_t task = &#123; .func = func, .arg = arg &#125;;\n    pool-&gt;queue[pool-&gt;rear] = task;\n    pool-&gt;rear = (pool-&gt;rear + 1) % MAX_QUEUE;\n    pool-&gt;size++;\n    pthread_cond_signal(&amp;pool-&gt;cond);\n    pthread_mutex_unlock(&amp;pool-&gt;mutex);\n    return true;\n&#125;在消费者方面，thread_pool_worker函数用于从任务队列中取出任务并执行。当消费者从任务队列中取出一个任务时，它会使用互斥锁pool-&gt;mutex来保护任务队列。如果任务队列为空，消费者将会被条件变量pool-&gt;mutex阻塞，等待生产者添加新的任务到任务队列中。\ncvoid *thread_pool_worker(void *arg)&#123;\n    thread_pool_t *pool = (thread_pool_t *)arg;\n    while (true) &#123;\n        pthread_mutex_lock(&amp;pool-&gt;mutex);\n        while (pool-&gt;size == 0 &amp;&amp; !pool-&gt;shutdown)\n            pthread_cond_wait(&amp;pool-&gt;cond, &amp;pool-&gt;mutex);\n        if (pool-&gt;size == 0 &amp;&amp; pool-&gt;shutdown) &#123;\n            pthread_mutex_unlock(&amp;pool-&gt;mutex);\n            pthread_exit(NULL);\n        &#125;\n        task_t task = pool-&gt;queue[pool-&gt;front];\n        pool-&gt;front = (pool-&gt;front + 1) % MAX_QUEUE;\n        pool-&gt;size--;\n        pthread_mutex_unlock(&amp;pool-&gt;mutex);\n        task.func(task.arg);\n    &#125;\n&#125;线程池的启动包括初始化任务队列、信号量、启动消费者线程；线程池的关闭最重要的是等待所有线程运行结束；两者实现如下：\ncvoid thread_pool_init(thread_pool_t *pool, int num_threads) &#123;\n    pool-&gt;num_threads = num_threads;\n    pool-&gt;front = pool-&gt;rear = pool-&gt;size = 0;\n    pool-&gt;shutdown = false;\n    pthread_mutex_init(&amp;pool-&gt;mutex, NULL);\n    pthread_cond_init(&amp;pool-&gt;cond, NULL);\n    for (int i = 0; i &lt; num_threads; i++)\n        pthread_create(&amp;pool-&gt;threads[i], NULL, thread_pool_worker, pool);\n&#125;\n\nvoid thread_pool_shutdown(thread_pool_t *pool) &#123;\n    pthread_mutex_lock(&amp;pool-&gt;mutex);\n    pool-&gt;shutdown = true;\n    pthread_cond_broadcast(&amp;pool-&gt;cond);\n    pthread_mutex_unlock(&amp;pool-&gt;mutex);\n    for (int i = 0; i &lt; pool-&gt;num_threads; i++)\n        pthread_join(pool-&gt;threads[i], NULL);\n    pthread_mutex_destroy(&amp;pool-&gt;mutex);\n    pthread_cond_destroy(&amp;pool-&gt;cond);\n&#125;设计一个简单的任务，输出任务id与线程id，并放到线程池运行：\ncvoid my_task(void *arg)&#123;\n    int *num = (int *)arg;\n    printf(&quot;Task %d by thread %lu\\n&quot;, *num, pthread_self());\n    free(num);\n&#125;\n\nint main() &#123;\n    thread_pool_t pool;\n    thread_pool_init(&amp;pool, 8);\n    for (int i = 0; i &lt; 20; i++) &#123;\n        int *num = malloc(sizeof(int));\n        *num = i;\n        thread_pool_enqueue(&amp;pool, my_task, num);\n    &#125;\n    printf(&quot;main thread %lu\\n&quot;, pthread_self());\n    thread_pool_shutdown(&amp;pool);\n    return 0;\n&#125;运行结果在ubuntu 20中编译gcc tp.c -o tp -lpthread，运行结果描述如下：\ntxtTask 0 by thread 140422668744478\nTask 4 by thread 140422668744456\nTask 5 by thread 140422668744434\n...线程池使用线程池完成矩阵相加$a+b&#x3D;c$，相应的任务函数如下：\ncvoid add_matrix(void *arg) &#123;\n    int *num = (int *)arg;\n    int st = *num, ed = st + 5;\n    for (int i = st; i &lt; ed; i++)\n        c[i] = a[i] + b[i];\n    printf(&quot;Task [add_matrix] %d by thread %lu, range = %d ~ %d \\n&quot;, *num /5, pthread_self(), st, ed);\n    free(num);\n&#125;","slug":"并行编程实验一","date":"2023-04-17T14:35:33.000Z","categories_index":"大数据","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"895af0f03f87247c5b74532216cc5f3b","title":"Essence of Linear Algebra","content":"中英对照表\n\n\nEnglish\n中文\n\n\n\ncross production\n叉积\n\n\ndeterminantion\n行列式\n\n\neigenvalue\n特征值\n\n\nVector\n\n\n\n\n\n\n\n\nThe introduction of numbers as coordinates is an act of violence.\nAND on the flip side, it gives people a language to descrbie space and the manipulation of space using numbers that can be crunched and run through a computer.暴论：线代让程序员可以操纵空间。\n与是基向量（basis vector）,任何向量都可以看成其线性组合。共线的向量，线性相关(Linearly dependent)，张成的空间就是一条线（或原点）；不共线的向量，线性无关(Linearly independent)，张成空间就是所有向量的集合；\nMatrix\n\n\n\n\n\n\n\n\nkind of Linear transformation\n好在线性代数只涉及线性变换； 矩阵可以理解为一种变换；ac表示一个基变换后的位置，bd也是，因此1001等价于没变换；知道基是怎样变换的，就知道了所有向量是怎么变换的；正交变换是基向量保持长度且相互正交的变换（刚体运动）;\nMatrix Multiply单个矩阵是线性变换，那矩阵相乘就是复合变换。矩阵相乘的集合意义就在于使两个线性变换相继作用(apply one transformation then another)非方阵代表跨纬度的变换；\nDeterminant  这就是行列式determinant！👆1x1的小格子，经过矩阵变换后的面积等于对应行列式的值。如果行列式为0，全都压扁了，是一个不可逆的变换，矩阵也是不可逆的。行列式的值可以是负的，你的面积也能是负的吗？面积等于绝对值，负数代表空间orientation发生了改变（一张纸翻转了）；\n不过面积不能说明一切，高维是其它东西；\nInverse matrices &amp; Column space &amp; Rank\n\n\n\n\n\n\n\n\n矩阵不只是操纵空间，还可以用来解方程组。\n把方程组(equation system)转换成矩阵相乘，自然又回到操作空间的传统艺能来了；在矩阵的作用下变换成，那用逆变换找到原来的就是求解方程组的过程；当行列式不为0时，求逆矩阵即可解方程组；\n当行列式为0时，方程组仍然可能有解，前提是幸存于压缩后的空间(列空间）里；\n关于秩的解释，视频 8分钟左右真的太精妙了。秩代表变换后（列）空间的维度；（在方程组中，矩阵的秩刚好就是约束条件的个数）所有可能的的集合就是列空间Column space;变换后落在原点的向量集合，就是零空间null space 或者叫做 核kernel;SVM中的核方法？\nDuality of Dot Product\n\n\n\n\n\n\n\n\n传统理解向量点积的方式为投影，但为了理解对偶性，先忘掉。对偶性指的是自然而又出乎意料的对应关系。Vector is the physical embodiment of a linear transformation.(向量是线性变换的载体)对偶性的理解对理解希尔伯特空间、PCA IDA至关重要。\n\n向量和对应的1×n矩阵之间有奇妙的关系，1×n矩阵代表的变换等价于与n×1的向量做点积；每一个向量都是某个矩阵的化身；每一个矩阵都与某个向量对应着；\nCross Product传统的解释如上图\nChange of Basis\n\n\n\n\n\n\n\n\n两个处于不同坐标系的人，该怎样交流？把他人的基向量放到自己的坐标系，得到变换矩阵即可。\n对于另一个坐标系中的向量，先用一个变换转换（左三）成我们自己坐标系的向量，再在我们自己的坐标系中进行变换（左中），最后把变换结果转换成他的坐标（左一）；表达式代表着一种转移作用，这种矩阵的乘积仍然是一种变换，是对于其他人来说的。\nEigenvectors &amp; Eigenvalues\n作用：特征值为1的特征向量就是旋转轴计算：，移项之后，即,即找到一个可以压缩空间的向量旋转变换特征向量在复向量空间中，剪切变换仅一个特征向量；也有特征值唯一，特征向量不共线的情况（如将所有向量拉伸两倍）\n对角矩阵，所有的基向量都是特征向量，对角线上的值就是对应的特征值如果有一天，想把两个不共线的特征向量[1 0] [0 1]作为新的坐标系的基，这个基变换的过程就是相似对角化；得到的矩阵必然是对角矩阵，且值为特征值。这样的特征向量也叫做特征基(eigenbasis)；为什么要大费周章去进行特征基变换呢，比如说上面这个 ，计算100次这样的变换会非常复杂，变换一下后可以快速得到结果 ，再变回来就是了。\nVector Spaces\n\n\n\n\n\n\n\n\n行列式、特征向量等与所选的坐标系无关…函数求导也可以用矩阵完成…所以向量究竟是什么？\n向量不是个东西。公理不是什么自然法则，是数学家定义的规则，联系了数学家与使用数学工具的人；向量可以是任何东西，点、箭头、函数、奇怪的生物…，只要他们满足这些公理定义的规则。问向量是什么，就相当于问“1”是什么，是没有意义的。\nCramer Rule\n\n\n\n\n\n\n\n\n求解行列式，计算机使用克莱姆法则，人用高斯消元法；但克莱姆法则有意思的多。\n一种独特的表示坐标的方法： y = area/1 ,  x = area / 1;\n\n这样变换之后的y就还是以绿色基为底的四边形的面积，这正好契合行列式的几何意义；这时四边形的面积，绿色的基不变（行列式第一列)，高度变为变换后的42.这就是克莱姆法则的几何意义。\n","slug":"Essence-of-Linear-Algebra","date":"2023-04-12T06:47:45.000Z","categories_index":"数学","tags_index":"学习笔记,线性代数","author_index":"以太工坊"},{"id":"25e546c45e26ec097339018184d9d5d1","title":"算法基础模板","content":"图论\n动态规划\n基础算法排序快速排序算法模板—— 模板题 AcWing 785. 快速排序\ncppvoid quick_sort(int q[], int l, int r)\n{\n    if (l &gt;= r) return;\n\n    int i = l - 1, j = r + 1, x = q[l + r &gt;&gt; 1];\n    while (i &lt; j)\n    {\n        do i ++ ; while (q[i] &lt; x);\n        do j -- ; while (q[j] &gt; x);\n        if (i &lt; j) swap(q[i], q[j]);\n    }\n    quick_sort(q, l, j), quick_sort(q, j + 1, r);\n}归并排序算法模板—— 模板题 AcWing 787. 归并排序\ncppvoid merge_sort(int q[], int l, int r)\n{\n    if (l &gt;= r) return;\n\n    int mid = l + r &gt;&gt; 1;\n    merge_sort(q, l, mid);\n    merge_sort(q, mid + 1, r);\n\n    int k = 0, i = l, j = mid + 1;\n    while (i &lt;= mid &amp;&amp; j &lt;= r)\n        if (q[i] &lt;= q[j]) tmp[k ++ ] = q[i ++ ];\n        else tmp[k ++ ] = q[j ++ ];\n\n    while (i &lt;= mid) tmp[k ++ ] = q[i ++ ];\n    while (j &lt;= r) tmp[k ++ ] = q[j ++ ];\n\n    for (i = l, j = 0; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];\n}二分整数二分算法模板—— 模板题 AcWing 789. 数的范围\ncppbool check(int x) {/* ... */} // 检查x是否满足某种性质\n\n// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：\nint bsearch_1(int l, int r)\n{\n    while (l &lt; r)\n    {\n        int mid = l + r &gt;&gt; 1;\n        if (check(mid)) r = mid;    // check()判断mid是否满足性质\n        else l = mid + 1;\n    }\n    return l;\n}\n// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：\nint bsearch_2(int l, int r)\n{\n    while (l &lt; r)\n    {\n        int mid = l + r + 1 &gt;&gt; 1;\n        if (check(mid)) l = mid;\n        else r = mid - 1;\n    }\n    return l;\n}浮点数二分算法模板—— 模板题 AcWing 790. 数的三次方根\ncppbool check(double x) {/* ... */} // 检查x是否满足某种性质\n\ndouble bsearch_3(double l, double r)\n{\n    const double eps = 1e-6;   // eps 表示精度，取决于题目对精度的要求\n    while (r - l &gt; eps)\n    {\n        double mid = (l + r) / 2;\n        if (check(mid)) r = mid;\n        else l = mid;\n    }\n    return l;\n}高精度高精度加法—— 模板题 AcWing 791. 高精度加法\ncpp// C = A + B, A &gt;= 0, B &gt;= 0\nvector&lt;int&gt; add(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B)\n{\n    if (A.size() &lt; B.size()) return add(B, A);\n\n    vector&lt;int&gt; C;\n    int t = 0;\n    for (int i = 0; i &lt; A.size(); i ++ )\n    {\n        t += A[i];\n        if (i &lt; B.size()) t += B[i];\n        C.push_back(t % 10);\n        t /= 10;\n    }\n\n    if (t) C.push_back(t);\n    return C;\n}高精度减法—— 模板题 [AcWing 792. 高精度减法]https://www.acwing.com/problem/content/794/\ncpp// C = A - B, 满足A &gt;= B, A &gt;= 0, B &gt;= 0\nvector&lt;int&gt; sub(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B)\n{\n    vector&lt;int&gt; C;\n    for (int i = 0, t = 0; i &lt; A.size(); i ++ )\n    {\n        t = A[i] - t;\n        if (i &lt; B.size()) t -= B[i];\n        C.push_back((t + 10) % 10);\n        if (t &lt; 0) t = 1;\n        else t = 0;\n    }\n\n    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();\n    return C;\n}高精度乘低精度—— 模板题 AcWing 793. 高精度乘法\ncpp// C = A * b, A &gt;= 0, b &gt;= 0\nvector&lt;int&gt; mul(vector&lt;int&gt; &amp;A, int b)\n{\n    vector&lt;int&gt; C;\n\n    int t = 0;\n    for (int i = 0; i &lt; A.size() || t; i ++ )\n    {\n        if (i &lt; A.size()) t += A[i] * b;\n        C.push_back(t % 10);\n        t /= 10;\n    }\n\n    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();\n\n    return C;\n}高精度除以低精度—— 模板题 AcWing 794. 高精度除法\ncpp// A / b = C ... r, A &gt;= 0, b &gt; 0\nvector&lt;int&gt; div(vector&lt;int&gt; &amp;A, int b, int &amp;r)\n{\n    vector&lt;int&gt; C;\n    r = 0;\n    for (int i = A.size() - 1; i &gt;= 0; i -- )\n    {\n        r = r * 10 + A[i];\n        C.push_back(r / b);\n        r %= b;\n    }\n    reverse(C.begin(), C.end());\n    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();\n    return C;\n}前缀与差分\n\n\n\n\n\n\n\n\n前缀：快速求取某一段的和差分：快速对某一段+c，与前缀互为逆运算\n一维前缀和—— 模板题 AcWing 795. 前缀和\ncppS[i] = a[1] + a[2] + ... a[i]\na[l] + ... + a[r] = S[r] - S[l - 1]二维前缀和—— 模板题 AcWing 796. 子矩阵的和\ncppS[i, j] = 第i行j列格子左上部分所有元素的和\n以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵的和为：\nS[x2, y2] - S[x1 - 1, y2] - S[x2, y1 - 1] + S[x1 - 1, y1 - 1]一维差分—— 模板题 AcWing 797. 差分给区间[l, r]中的每个数加上c：B[l] += c, B[r + 1] -= c\n二维差分—— 模板题 AcWing 798. 差分矩阵\ncpp给以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵中的所有元素加上c：\nS[x1, y1] += c, S[x2 + 1, y1] -= c, S[x1, y2 + 1] -= c, S[x2 + 1, y2 + 1] += c位运算—— 模板题 AcWing 801. 二进制中1的个数\ncpp求n的第k位数字: n &gt;&gt; k &amp; 1\n返回n的最后一位1：lowbit(n) = n &amp; -n双指针算法—— 模板题 AcWIng 799. 最长连续不重复子序列, AcWing 800. 数组元素的目标和\ncppfor (int i = 0, j = 0; i &lt; n; i ++ )\n{\n    while (j &lt; i &amp;&amp; check(i, j)) j ++ ;\n\n    // 具体问题的逻辑\n}\n常见问题分类：\n    (1) 对于一个序列，用两个指针维护一段区间\n    (2) 对于两个序列，维护某种次序，比如归并排序中合并两个有序序列的操作离散化—— 模板题 AcWing 802. 区间和\ncppvector&lt;int&gt; alls; // 存储所有待离散化的值\nsort(alls.begin(), alls.end()); // 将所有值排序\nalls.erase(unique(alls.begin(), alls.end()), alls.end());   // 去掉重复元素\n\n// 二分求出x对应的离散化的值\nint find(int x) // 找到第一个大于等于x的位置\n{\n    int l = 0, r = alls.size() - 1;\n    while (l &lt; r)\n    {\n        int mid = l + r &gt;&gt; 1;\n        if (alls[mid] &gt;= x) r = mid;\n        else l = mid + 1;\n    }\n    return r + 1; // 映射到1, 2, ...n\n}区间合并—— 模板题 AcWing 803. 区间合并\ncpp// 将所有存在交集的区间合并\nvoid merge(vector&lt;PII&gt; &amp;segs)\n{\n    vector&lt;PII&gt; res;\n\n    sort(segs.begin(), segs.end());\n\n    int st = -2e9, ed = -2e9;\n    for (auto seg : segs)\n        if (ed &lt; seg.first)\n        {\n            if (st != -2e9) res.push_back({st, ed});\n            st = seg.first, ed = seg.second;\n        }\n        else ed = max(ed, seg.second);\n\n    if (st != -2e9) res.push_back({st, ed});\n\n    segs = res;\n}数据结构链表与邻接表：树与图的存储单链表—— 模板题 AcWing 826. 单链表\ncpp// head存储链表头，e[]存储节点的值，ne[]存储节点的next指针，idx表示当前用到了哪个节点\nint head, e[N], ne[N], idx;\n\n// 初始化\nvoid init()\n{\n    head = -1;\n    idx = 0;\n}\n\n// 在链表头插入一个数a\nvoid insert(int a)\n{\n    e[idx] = a, ne[idx] = head, head = idx ++ ;\n}\n\n// 将头结点删除，需要保证头结点存在\nvoid remove()\n{\n    head = ne[head];\n}双链表—— 模板题 AcWing 827. 双链表\ncpp// e[]表示节点的值，l[]表示节点的左指针，r[]表示节点的右指针，idx表示当前用到了哪个节点\nint e[N], l[N], r[N], idx;\n\n// 初始化\nvoid init()\n{\n    //0是左端点，1是右端点\n    r[0] = 1, l[1] = 0;\n    idx = 2;\n}\n\n// 在节点a的右边插入一个数x\nvoid insert(int a, int x)\n{\n    e[idx] = x;\n    l[idx] = a, r[idx] = r[a];\n    l[r[a]] = idx, r[a] = idx ++ ;\n}\n\n// 删除节点a\nvoid remove(int a)\n{\n    l[r[a]] = l[a];\n    r[l[a]] = r[a];\n}栈与队列：单调队列、单调栈栈—— 模板题 AcWing 828. 模拟栈\ncpp// tt表示栈顶\nint stk[N], tt = 0;\n\n// 向栈顶插入一个数\nstk[ ++ tt] = x;\n\n// 从栈顶弹出一个数\ntt -- ;\n\n// 栈顶的值\nstk[tt];\n\n// 判断栈是否为空，如果 tt &gt; 0，则表示不为空\nif (tt &gt; 0)\n{\n\n}队列—— 模板题 AcWing 829. 模拟队列\n\n普通队列：\n\ncpp// hh 表示队头，tt表示队尾\nint q[N], hh = 0, tt = -1;\n\n// 向队尾插入一个数\nq[ ++ tt] = x;\n\n// 从队头弹出一个数\nhh ++ ;\n\n// 队头的值\nq[hh];\n\n// 判断队列是否为空，如果 hh &lt;= tt，则表示不为空\nif (hh &lt;= tt)\n{\n}\n循环队列\n\ncpp// hh 表示队头，tt表示队尾的后一个位置\nint q[N], hh = 0, tt = 0;\n\n// 向队尾插入一个数\nq[tt ++ ] = x;\nif (tt == N) tt = 0;\n\n// 从队头弹出一个数\nhh ++ ;\nif (hh == N) hh = 0;\n\n// 队头的值\nq[hh];\n\n// 判断队列是否为空，如果hh != tt，则表示不为空\nif (hh != tt)\n{\n}单调栈—— 模板题 AcWing 830. 单调栈常见模型：找出每个数左边离它最近的比它大/小的数\ncppint tt = 0;\nfor (int i = 1; i &lt;= n; i ++ )\n{\n    while (tt &amp;&amp; check(stk[tt], i)) tt -- ;\n    stk[ ++ tt] = i;\n}单调队列—— 模板题 AcWing 154. 滑动窗口常见模型：找出滑动窗口中的最大值/最小值\ncppint hh = 0, tt = -1;\nfor (int i = 0; i &lt; n; i ++ )\n{\n    while (hh &lt;= tt &amp;&amp; check_out(q[hh])) hh ++ ;  // 判断队头是否滑出窗口\n    while (hh &lt;= tt &amp;&amp; check(q[tt], i)) tt -- ;\n    q[ ++ tt] = i;\n}KMP—— 模板题 AcWing 831. KMP字符串\ncpp// s[]是长文本，p[]是模式串，n是s的长度，m是p的长度\n求模式串的Next数组：\nfor (int i = 2, j = 0; i &lt;= m; i ++ )\n{\n    while (j &amp;&amp; p[i] != p[j + 1]) j = ne[j];\n    if (p[i] == p[j + 1]) j ++ ;\n    ne[i] = j;\n}\n\n// 匹配\nfor (int i = 1, j = 0; i &lt;= n; i ++ )\n{\n    while (j &amp;&amp; s[i] != p[j + 1]) j = ne[j];\n    if (s[i] == p[j + 1]) j ++ ;\n    if (j == m)\n    {\n        j = ne[j];\n        // 匹配成功后的逻辑\n    }\n}//C的库函数 strstr()即是如此Trie树—— 模板题 AcWing 835. Trie字符串统计\ncppint son[N][26], cnt[N], idx;\n// 0号点既是根节点，又是空节点\n// son[][]存储树中每个节点的子节点\n// cnt[]存储以每个节点结尾的单词数量\n\n// 插入一个字符串\nvoid insert(char *str)\n{\n    int p = 0;\n    for (int i = 0; str[i]; i ++ )\n    {\n        int u = str[i] - 'a';\n        if (!son[p][u]) son[p][u] = ++ idx;\n        p = son[p][u];\n    }\n    cnt[p] ++ ;\n}\n\n// 查询字符串出现的次数\nint query(char *str)\n{\n    int p = 0;\n    for (int i = 0; str[i]; i ++ )\n    {\n        int u = str[i] - 'a';\n        if (!son[p][u]) return 0;\n        p = son[p][u];\n    }\n    return cnt[p];\n}//可以用map&lt;string,int&gt;，但时间是两倍以上并查集—— 模板题[ AcWing 836. 合并集合](https://www.acwing.com/problem/content/838/, AcWing 837. 连通块中点的数量(1)朴素并查集：\ncpp    int p[N]; //存储每个点的祖宗节点\n\n    // 返回x的祖宗节点\n    int find(int x)\n    {\n        if (p[x] != x) p[x] = find(p[x]);\n        return p[x];\n    }\n\n    // 初始化，假定节点编号是1~n\n    for (int i = 1; i &lt;= n; i ++ ) p[i] = i;\n\n    // 合并a和b所在的两个集合：\n    p[find(a)] = find(b);(2)维护size的并查集：\ncpp    int p[N], size[N];\n    //p[]存储每个点的祖宗节点, size[]只有祖宗节点的有意义，表示祖宗节点所在集合中的点的数量\n\n    // 返回x的祖宗节点\n    int find(int x)\n    {\n        if (p[x] != x) p[x] = find(p[x]);\n        return p[x];\n    }\n\n    // 初始化，假定节点编号是1~n\n    for (int i = 1; i &lt;= n; i ++ )\n    {\n        p[i] = i;\n        size[i] = 1;\n    }\n\n    // 合并a和b所在的两个集合：\n    size[find(b)] += size[find(a)];\n    p[find(a)] = find(b);(3)维护到祖宗节点距离的并查集：\ncpp    int p[N], d[N];\n    //p[]存储每个点的祖宗节点, d[x]存储x到p[x]的距离\n\n    // 返回x的祖宗节点\n    int find(int x)\n    {\n        if (p[x] != x)\n        {\n            int u = find(p[x]);\n            d[x] += d[p[x]];\n            p[x] = u;\n        }\n        return p[x];\n    }\n\n    // 初始化，假定节点编号是1~n\n    for (int i = 1; i &lt;= n; i ++ )\n    {\n        p[i] = i;\n        d[i] = 0;\n    }\n\n    // 合并a和b所在的两个集合：\n    p[find(a)] = find(b);\n    d[find(a)] = distance; // 根据具体问题，初始化find(a)的偏移量堆—— 模板题[ AcWing 838. 堆排序](https://www.acwing.com/problem/content/840/, AcWing 839. 模拟堆\ncpp// h[N]存储堆中的值, h[1]是堆顶，x的左儿子是2x, 右儿子是2x + 1\n// ph[k]存储第k个插入的点在堆中的位置\n// hp[k]存储堆中下标是k的点是第几个插入的\nint h[N], ph[N], hp[N], size;\n\n// 交换两个点，及其映射关系\nvoid heap_swap(int a, int b)\n{\n    swap(ph[hp[a]],ph[hp[b]]);\n    swap(hp[a], hp[b]);\n    swap(h[a], h[b]);\n}\n\nvoid down(int u)\n{\n    int t = u;\n    if (u * 2 &lt;= size &amp;&amp; h[u * 2] &lt; h[t]) t = u * 2;\n    if (u * 2 + 1 &lt;= size &amp;&amp; h[u * 2 + 1] &lt; h[t]) t = u * 2 + 1;\n    if (u != t)\n    {\n        heap_swap(u, t);\n        down(t);\n    }\n}\n\nvoid up(int u)\n{\n    while (u / 2 &amp;&amp; h[u] &lt; h[u / 2])\n    {\n        heap_swap(u, u / 2);\n        u &gt;&gt;= 1;\n    }\n}\n\n// O(n)建堆\nfor (int i = n / 2; i; i -- ) down(i);哈希一般哈希—— 模板题 AcWing 840. 模拟散列表\ncpp(1) 拉链法\n    int h[N], e[N], ne[N], idx;\n\n    // 向哈希表中插入一个数\n    void insert(int x)\n    {\n        int k = (x % N + N) % N;\n        e[idx] = x;\n        ne[idx] = h[k];\n        h[k] = idx ++ ;\n    }\n\n    // 在哈希表中查询某个数是否存在\n    bool find(int x)\n    {\n        int k = (x % N + N) % N;\n        for (int i = h[k]; i != -1; i = ne[i])\n            if (e[i] == x)\n                return true;\n\n        return false;\n    }\n\n(2) 开放寻址法\n    int h[N];\n\n    // 如果x在哈希表中，返回x的下标；如果x不在哈希表中，返回x应该插入的位置\n    int find(int x)\n    {\n        int t = (x % N + N) % N;\n        while (h[t] != null &amp;&amp; h[t] != x)\n        {\n            t ++ ;\n            if (t == N) t = 0;\n        }\n        return t;\n    }字符串哈希—— 模板题 AcWing 841. 字符串哈希核心思想：将字符串看成P进制数，P的经验值是131或13331，取这两个值的冲突概率低小技巧：取模的数用2^64，这样直接用unsigned long long存储，溢出的结果就是取模的结果\ncpptypedef unsigned long long ULL;\nULL h[N], p[N]; // h[k]存储字符串前k个字母的哈希值, p[k]存储 P^k mod 2^64\n\n// 初始化\np[0] = 1;\nfor (int i = 1; i &lt;= n; i ++ )\n{\n    h[i] = h[i - 1] * P + str[i];\n    p[i] = p[i - 1] * P;\n}\n\n// 计算子串 str[l ~ r] 的哈希值\nULL get(int l, int r)\n{\n    return h[r] - h[l - 1] * p[r - l + 1];\n}C++ STL简介cppvector, 变长数组，倍增的思想\n    size()  返回元素个数\n    empty()  返回是否为空\n    clear()  清空\n    front()/back()\n    push_back()/pop_back()\n    begin()/end()\n    []\n    支持比较运算，按字典序\n\npair&lt;int, int&gt;\n    first, 第一个元素\n    second, 第二个元素\n    支持比较运算，以first为第一关键字，以second为第二关键字（字典序）\n\nstring，字符串\n    size()/length()  返回字符串长度\n    empty()\n    clear()\n    substr(起始下标，(子串长度))  返回子串\n    c_str()  返回字符串所在字符数组的起始地址\n\nqueue, 队列\n    size()\n    empty()\n    push()  向队尾插入一个元素\n    front()  返回队头元素\n    back()  返回队尾元素\n    pop()  弹出队头元素\n\npriority_queue, 优先队列，默认是大根堆\n    size()\n    empty()\n    push()  插入一个元素\n    top()  返回堆顶元素\n    pop()  弹出堆顶元素\n    定义成小根堆的方式：priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q;\n\nstack, 栈\n    size()\n    empty()\n    push()  向栈顶插入一个元素\n    top()  返回栈顶元素\n    pop()  弹出栈顶元素\n\ndeque, 双端队列\n    size()\n    empty()\n    clear()\n    front()/back()\n    push_back()/pop_back()\n    push_front()/pop_front()\n    begin()/end()\n    []\n\nset, map, multiset, multimap, 基于平衡二叉树（红黑树），动态维护有序序列\n    size()\n    empty()\n    clear()\n    begin()/end()\n    ++, -- 返回前驱和后继，时间复杂度 O(logn)\n\n    set/multiset\n        insert()  插入一个数\n        find()  查找一个数\n        count()  返回某一个数的个数\n        erase()\n            (1) 输入是一个数x，删除所有x   O(k + logn)\n            (2) 输入一个迭代器，删除这个迭代器\n        lower_bound()/upper_bound()\n            lower_bound(x)  返回大于等于x的最小的数的迭代器\n            upper_bound(x)  返回大于x的最小的数的迭代器\n    map/multimap\n        insert()  插入的数是一个pair\n        erase()  输入的参数是pair或者迭代器\n        find()\n        []  注意multimap不支持此操作。 时间复杂度是 O(logn)\n        lower_bound()/upper_bound()\n\nunordered_set, unordered_map, unordered_multiset, unordered_multimap, 哈希表\n    和上面类似，增删改查的时间复杂度是 O(1)\n    不支持 lower_bound()/upper_bound()， 迭代器的++，--\n\nbitset, 圧位\n    bitset&lt;10000&gt; s;\n    ~, &amp;, |, ^\n    &gt;&gt;, &lt;&lt;\n    ==, !=\n    []\n\n    count()  返回有多少个1\n\n    any()  判断是否至少有一个1\n    none()  判断是否全为0\n\n    set()  把所有位置成1\n    set(k, v)  将第k位变成v\n    reset()  把所有位变成0\n    flip()  等价于~\n    flip(k) 把第k位取反搜索与图论DFS与BFS树与图的存储树是一种特殊的图，与图的存储方式相同。对于无向图中的边ab，存储两条有向边a-&gt;b, b-&gt;a。因此我们可以只考虑有向图的存储。(1) 邻接矩阵：g[a][b] 存储边a-&gt;b(2) 邻接表：\ncpp// 对于每个点k，开一个单链表，存储k所有可以走到的点。h[k]存储这个单链表的头结点\nint h[N], e[N], ne[N], idx;\n\n// 添加一条边a-&gt;b\nvoid add(int a, int b)\n{\n    e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ;\n}\n\n// 初始化\nidx = 0;\nmemset(h, -1, sizeof h);树与图的遍历时间复杂度 O(n+m), n表示点数，m 表示边数(1) 深度优先遍历 —— 模板题 AcWing 846. 树的重心\ncppint dfs(int u)\n{\n    st[u] = true; // st[u] 表示点u已经被遍历过\n\n    for (int i = h[u]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j]) dfs(j);\n    }\n}(2) 宽度优先遍历 —— 模板题 AcWing 847. 图中点的层次\ncppqueue&lt;int&gt; q;\nst[1] = true; // 表示1号点已经被遍历过\nq.push(1);\n\nwhile (q.size())\n{\n    int t = q.front();\n    q.pop();\n\n    for (int i = h[t]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j])\n        {\n            st[j] = true; // 表示点j已经被遍历过\n            q.push(j);\n        }\n    }\n}树与图的遍历 拓扑排序—— 模板题 AcWing 848. 有向图的拓扑序列时间复杂度 O(n+m), n 表示点数，m表示边数\ncppbool topsort()\n{\n    int hh = 0, tt = -1;\n\n    // d[i] 存储点i的入度\n    for (int i = 1; i &lt;= n; i ++ )\n        if (!d[i])\n            q[ ++ tt] = i;\n\n    while (hh &lt;= tt)\n    {\n        int t = q[hh ++ ];\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (-- d[j] == 0)\n                q[ ++ tt] = j;\n        }\n    }\n\n    // 如果所有点都入队了，说明存在拓扑序列；否则不存在拓扑序列。\n    return tt == n - 1;\n}最短路径朴素dijkstra算法—— 模板题 AcWing 849. Dijkstra求最短路 I时间复杂是 O(n2+m), n 表示点数，m表示边数\ncppint g[N][N];  // 存储每条边\nint dist[N];  // 存储1号点到每个点的最短距离\nbool st[N];   // 存储每个点的最短路是否已经确定\n\n// 求1号点到n号点的最短路，如果不存在则返回-1\nint dijkstra()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    for (int i = 0; i &lt; n - 1; i ++ )\n    {\n        int t = -1;     // 在还未确定最短路的点中，寻找距离最小的点\n        for (int j = 1; j &lt;= n; j ++ )\n            if (!st[j] &amp;&amp; (t == -1 || dist[t] &gt; dist[j]))\n                t = j;\n\n        // 用t更新其他点的距离\n        for (int j = 1; j &lt;= n; j ++ )\n            dist[j] = min(dist[j], dist[t] + g[t][j]);\n\n        st[t] = true;\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}堆优化版dijkstra—— 模板题 AcWing 850. Dijkstra求最短路 II时间复杂度 O(mlogn), n 表示点数，m表示边数\ncpptypedef pair&lt;int, int&gt; PII;\n\nint n;      // 点的数量\nint h[N], w[N], e[N], ne[N], idx;       // 邻接表存储所有边\nint dist[N];        // 存储所有点到1号点的距离\nbool st[N];     // 存储每个点的最短距离是否已确定\n\n// 求1号点到n号点的最短距离，如果不存在，则返回-1\nint dijkstra()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n    priority_queue&lt;PII, vector&lt;PII&gt;, greater&lt;PII&gt;&gt; heap;\n    heap.push({0, 1});      // first存储距离，second存储节点编号\n\n    while (heap.size())\n    {\n        auto t = heap.top();\n        heap.pop();\n\n        int ver = t.second, distance = t.first;\n\n        if (st[ver]) continue;\n        st[ver] = true;\n\n        for (int i = h[ver]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] &gt; distance + w[i])\n            {\n                dist[j] = distance + w[i];\n                heap.push({dist[j], j});\n            }\n        }\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}Bellman-Ford算法—— 模板题 AcWing 853. 有边数限制的最短路时间复杂度 O(nm), n表示点数，m表示边数注意在模板题中需要对下面的模板稍作修改，加上备份数组，详情见模板题。\ncppint n, m;       // n表示点数，m表示边数\nint dist[N];        // dist[x]存储1到x的最短路距离\n\nstruct Edge     // 边，a表示出点，b表示入点，w表示边的权重\n{\n    int a, b, w;\n}edges[M];\n\n// 求1到n的最短路距离，如果无法从1走到n，则返回-1。\nint bellman_ford()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    // 如果第n次迭代仍然会松弛三角不等式，就说明存在一条长度是n+1的最短路径，由抽屉原理，路径中至少存在两个相同的点，说明图中存在负权回路。\n    for (int i = 0; i &lt; n; i ++ )\n    {\n        for (int j = 0; j &lt; m; j ++ )\n        {\n            int a = edges[j].a, b = edges[j].b, w = edges[j].w;\n            if (dist[b] &gt; dist[a] + w)\n                dist[b] = dist[a] + w;\n        }\n    }\n\n    if (dist[n] &gt; 0x3f3f3f3f / 2) return -1;\n    return dist[n];\n}spfa 算法（队列优化的Bellman-Ford算法）—— 模板题 AcWing 851. spfa求最短路时间复杂度 平均情况下 O(m)，最坏情况下 O(nm), n表示点数，m表示边数\ncppint n;      // 总点数\nint h[N], w[N], e[N], ne[N], idx;       // 邻接表存储所有边\nint dist[N];        // 存储每个点到1号点的最短距离\nbool st[N];     // 存储每个点是否在队列中\n\n// 求1号点到n号点的最短路距离，如果从1号点无法走到n号点则返回-1\nint spfa()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    queue&lt;int&gt; q;\n    q.push(1);\n    st[1] = true;\n\n    while (q.size())\n    {\n        auto t = q.front();\n        q.pop();\n\n        st[t] = false;\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] &gt; dist[t] + w[i])\n            {\n                dist[j] = dist[t] + w[i];\n                if (!st[j])     // 如果队列中已存在j，则不需要将j重复插入\n                {\n                    q.push(j);\n                    st[j] = true;\n                }\n            }\n        }\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}spfa判断图中是否存在负环—— 模板题 AcWing 852. spfa判断负环时间复杂度是 O(nm), n表示点数，m表示边数\ncppint n;      // 总点数\nint h[N], w[N], e[N], ne[N], idx;       // 邻接表存储所有边\nint dist[N], cnt[N];        // dist[x]存储1号点到x的最短距离，cnt[x]存储1到x的最短路中经过的点数\nbool st[N];     // 存储每个点是否在队列中\n\n// 如果存在负环，则返回true，否则返回false。\nbool spfa()\n{\n    // 不需要初始化dist数组\n    // 原理：如果某条最短路径上有n个点（除了自己），那么加上自己之后一共有n+1个点，由抽屉原理一定有两个点相同，所以存在环。\n\n    queue&lt;int&gt; q;\n    for (int i = 1; i &lt;= n; i ++ )\n    {\n        q.push(i);\n        st[i] = true;\n    }\n\n    while (q.size())\n    {\n        auto t = q.front();\n        q.pop();\n\n        st[t] = false;\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] &gt; dist[t] + w[i])\n            {\n                dist[j] = dist[t] + w[i];\n                cnt[j] = cnt[t] + 1;\n                if (cnt[j] &gt;= n) return true;       // 如果从1号点到x的最短路中包含至少n个点（不包括自己），则说明存在环\n                if (!st[j])\n                {\n                    q.push(j);\n                    st[j] = true;\n                }\n            }\n        }\n    }\n\n    return false;\n}floyd算法—— 模板题 AcWing 854. Floyd求最短路时间复杂度是 O(n3), n 表示点数\ncpp初始化：\n    for (int i = 1; i &lt;= n; i ++ )\n        for (int j = 1; j &lt;= n; j ++ )\n            if (i == j) d[i][j] = 0;\n            else d[i][j] = INF;\n\n// 算法结束后，d[a][b]表示a到b的最短距离\nvoid floyd()\n{\n    for (int k = 1; k &lt;= n; k ++ )\n        for (int i = 1; i &lt;= n; i ++ )\n            for (int j = 1; j &lt;= n; j ++ )\n                d[i][j] = min(d[i][j], d[i][k] + d[k][j]);\n}最小生成树朴素版prim算法—— 模板题 AcWing 858. Prim算法求最小生成树时间复杂度是 O(n2+m), n 表示点数，m表示边数\ncppint n;      // n表示点数\nint g[N][N];        // 邻接矩阵，存储所有边\nint dist[N];        // 存储其他点到当前最小生成树的距离\nbool st[N];     // 存储每个点是否已经在生成树中\n\n\n// 如果图不连通，则返回INF(值是0x3f3f3f3f), 否则返回最小生成树的树边权重之和\nint prim()\n{\n    memset(dist, 0x3f, sizeof dist);\n\n    int res = 0;\n    for (int i = 0; i &lt; n; i ++ )\n    {\n        int t = -1;\n        for (int j = 1; j &lt;= n; j ++ )\n            if (!st[j] &amp;&amp; (t == -1 || dist[t] &gt; dist[j]))\n                t = j;\n\n        if (i &amp;&amp; dist[t] == INF) return INF;\n\n        if (i) res += dist[t];\n        st[t] = true;\n\n        for (int j = 1; j &lt;= n; j ++ ) dist[j] = min(dist[j], g[t][j]);\n    }\n\n    return res;\n}Kruskal算法—— 模板题 AcWing 859. Kruskal算法求最小生成树时间复杂度是 O(mlogm), n表示点数，m表示边数\ncppint n, m;       // n是点数，m是边数\nint p[N];       // 并查集的父节点数组\n\nstruct Edge     // 存储边\n{\n    int a, b, w;\n\n    bool operator&lt; (const Edge &amp;W)const\n    {\n        return w &lt; W.w;\n    }\n}edges[M];\n\nint find(int x)     // 并查集核心操作\n{\n    if (p[x] != x) p[x] = find(p[x]);\n    return p[x];\n}\n\nint kruskal()\n{\n    sort(edges, edges + m);\n\n    for (int i = 1; i &lt;= n; i ++ ) p[i] = i;    // 初始化并查集\n\n    int res = 0, cnt = 0;\n    for (int i = 0; i &lt; m; i ++ )\n    {\n        int a = edges[i].a, b = edges[i].b, w = edges[i].w;\n\n        a = find(a), b = find(b);\n        if (a != b)     // 如果两个连通块不连通，则将这两个连通块合并\n        {\n            p[a] = b;\n            res += w;\n            cnt ++ ;\n        }\n    }\n\n    if (cnt &lt; n - 1) return INF;\n    return res;\n}二分图染色法判别二分图—— 模板题 AcWing 860. 染色法判定二分图时间复杂度是 O(n+m), n表示点数，m表示边数\ncppint n;      // n表示点数\nint h[N], e[M], ne[M], idx;     // 邻接表存储图\nint color[N];       // 表示每个点的颜色，-1表示未染色，0表示白色，1表示黑色\n\n// 参数：u表示当前节点，c表示当前点的颜色\nbool dfs(int u, int c)\n{\n    color[u] = c;\n    for (int i = h[u]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (color[j] == -1)\n        {\n            if (!dfs(j, !c)) return false;\n        }\n        else if (color[j] == c) return false;\n    }\n\n    return true;\n}\n\nbool check()\n{\n    memset(color, -1, sizeof color);\n    bool flag = true;\n    for (int i = 1; i &lt;= n; i ++ )\n        if (color[i] == -1)\n            if (!dfs(i, 0))\n            {\n                flag = false;\n                break;\n            }\n    return flag;\n}匈牙利算法—— 模板题 AcWing 861. 二分图的最大匹配时间复杂度是 O(nm), n表示点数，m 表示边数\ncppint n1, n2;     // n1表示第一个集合中的点数，n2表示第二个集合中的点数\nint h[N], e[M], ne[M], idx;     // 邻接表存储所有边，匈牙利算法中只会用到从第一个集合指向第二个集合的边，所以这里只用存一个方向的边\nint match[N];       // 存储第二个集合中的每个点当前匹配的第一个集合中的点是哪个\nbool st[N];     // 表示第二个集合中的每个点是否已经被遍历过\n\nbool find(int x)\n{\n    for (int i = h[x]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j])\n        {\n            st[j] = true;\n            if (match[j] == 0 || find(match[j]))\n            {\n                match[j] = x;\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n\n// 求最大匹配数，依次枚举第一个集合中的每个点能否匹配第二个集合中的点\nint res = 0;\nfor (int i = 1; i &lt;= n1; i ++ )\n{\n    memset(st, false, sizeof st);\n    if (find(i)) res ++ ;\n}数学知识质数试除法判定质数—— 模板题 AcWing 866. 试除法判定质数\ncppbool is_prime(int x)\n{\n    if (x &lt; 2) return false;\n    for (int i = 2; i &lt;= x / i; i ++ )\n        if (x % i == 0)\n            return false;\n    return true;\n}试除法分解质因数—— 模板题 AcWing 867. 分解质因数\ncppvoid divide(int x)\n{\n    for (int i = 2; i &lt;= x / i; i ++ )\n        if (x % i == 0)\n        {\n            int s = 0;\n            while (x % i == 0) x /= i, s ++ ;\n            cout &lt;&lt; i &lt;&lt; ' ' &lt;&lt; s &lt;&lt; endl;\n        }\n    if (x &gt; 1) cout &lt;&lt; x &lt;&lt; ' ' &lt;&lt; 1 &lt;&lt; endl;\n    cout &lt;&lt; endl;\n}朴素筛法求素数—— 模板题 AcWing 868. 筛质数\ncppint primes[N], cnt;     // primes[]存储所有素数\nbool st[N];         // st[x]存储x是否被筛掉\n\nvoid get_primes(int n)\n{\n    for (int i = 2; i &lt;= n; i ++ )\n    {\n        if (st[i]) continue;\n        primes[cnt ++ ] = i;\n        for (int j = i + i; j &lt;= n; j += i)\n            st[j] = true;\n    }\n}线性筛法求素数—— 模板题 AcWing 868. 筛质数\ncppint primes[N], cnt;     // primes[]存储所有素数\nbool st[N];         // st[x]存储x是否被筛掉\n\nvoid get_primes(int n)\n{\n    for (int i = 2; i &lt;= n; i ++ )\n    {\n        if (!st[i]) primes[cnt ++ ] = i;\n        for (int j = 0; primes[j] &lt;= n / i; j ++ )\n        {\n            st[primes[j] * i] = true;\n            if (i % primes[j] == 0) break;\n        }\n    }\n}约数试除法求所有约数—— 模板题 AcWing 869. 试除法求约数\ncppvector&lt;int&gt; get_divisors(int x)\n{\n    vector&lt;int&gt; res;\n    for (int i = 1; i &lt;= x / i; i ++ )\n        if (x % i == 0)\n        {\n            res.push_back(i);\n            if (i != x / i) res.push_back(x / i);\n        }\n    sort(res.begin(), res.end());\n    return res;\n}约数个数和约数之和—— 模板题 [AcWing 870. 约数个数](https://www.acwing.com/problem/content/872/, AcWing 871. 约数之和\ncpp如果 N = p1^c1 * p2^c2 * ... *pk^ck\n约数个数： (c1 + 1) * (c2 + 1) * ... * (ck + 1)\n约数之和： (p1^0 + p1^1 + ... + p1^c1) * ... * (pk^0 + pk^1 + ... + pk^ck)欧几里得算法—— 模板题 AcWing 872. 最大公约数\ncppint gcd(int a, int b)\n{\n    return b ? gcd(b, a % b) : a;\n}欧拉函数求欧拉函数—— 模板题 AcWing 873. 欧拉函数\ncppint phi(int x)\n{\n    int res = x;\n    for (int i = 2; i &lt;= x / i; i ++ )\n        if (x % i == 0)\n        {\n            res = res / i * (i - 1);\n            while (x % i == 0) x /= i;\n        }\n    if (x &gt; 1) res = res / x * (x - 1);\n\n    return res;\n}筛法求欧拉函数—— 模板题 AcWing 874. 筛法求欧拉函数\ncppint primes[N], cnt;     // primes[]存储所有素数\nint euler[N];           // 存储每个数的欧拉函数\nbool st[N];         // st[x]存储x是否被筛掉\n\n\nvoid get_eulers(int n)\n{\n    euler[1] = 1;\n    for (int i = 2; i &lt;= n; i ++ )\n    {\n        if (!st[i])\n        {\n            primes[cnt ++ ] = i;\n            euler[i] = i - 1;\n        }\n        for (int j = 0; primes[j] &lt;= n / i; j ++ )\n        {\n            int t = primes[j] * i;\n            st[t] = true;\n            if (i % primes[j] == 0)\n            {\n                euler[t] = euler[i] * primes[j];\n                break;\n            }\n            euler[t] = euler[i] * (primes[j] - 1);\n        }\n    }\n}快速幂—— 模板题 AcWing 875. 快速幂求 m^k mod p，时间复杂度 O(logk)。\ncppint qmi(int m, int k, int p)\n{\n    int res = 1 % p, t = m;\n    while (k)\n    {\n        if (k&amp;1) res = res * t % p;\n        t = t * t % p;\n        k &gt;&gt;= 1;\n    }\n    return res;\n}扩展欧几里得算法—— 模板题 AcWing 877. 扩展欧几里得算法\ncpp// 求x, y，使得ax + by = gcd(a, b)\nint exgcd(int a, int b, int &amp;x, int &amp;y)\n{\n    if (!b)\n    {\n        x = 1; y = 0;\n        return a;\n    }\n    int d = exgcd(b, a % b, y, x);\n    y -= (a/b) * x;\n    return d;\n}高斯消元—— 模板题 AcWing 883. 高斯消元解线性方程组\ncpp// a[N][N]是增广矩阵\nint gauss()\n{\n    int c, r;\n    for (c = 0, r = 0; c &lt; n; c ++ )\n    {\n        int t = r;\n        for (int i = r; i &lt; n; i ++ )   // 找到绝对值最大的行\n            if (fabs(a[i][c]) &gt; fabs(a[t][c]))\n                t = i;\n\n        if (fabs(a[t][c]) &lt; eps) continue;\n\n        for (int i = c; i &lt;= n; i ++ ) swap(a[t][i], a[r][i]);      // 将绝对值最大的行换到最顶端\n        for (int i = n; i &gt;= c; i -- ) a[r][i] /= a[r][c];      // 将当前行的首位变成1\n        for (int i = r + 1; i &lt; n; i ++ )       // 用当前行将下面所有的列消成0\n            if (fabs(a[i][c]) &gt; eps)\n                for (int j = n; j &gt;= c; j -- )\n                    a[i][j] -= a[r][j] * a[i][c];\n\n        r ++ ;\n    }\n\n    if (r &lt; n)\n    {\n        for (int i = r; i &lt; n; i ++ )\n            if (fabs(a[i][n]) &gt; eps)\n                return 2; // 无解\n        return 1; // 有无穷多组解\n    }\n\n    for (int i = n - 1; i &gt;= 0; i -- )\n        for (int j = i + 1; j &lt; n; j ++ )\n            a[i][n] -= a[i][j] * a[j][n];\n\n    return 0; // 有唯一解\n}组合计数递推法求组合数—— 模板题 AcWing 885. 求组合数 I\ncpp// c[a][b] 表示从a个苹果中选b个的方案数\nfor (int i = 0; i &lt; N; i ++ )\n    for (int j = 0; j &lt;= i; j ++ )\n        if (!j) c[i][j] = 1;\n        else c[i][j] = (c[i - 1][j] + c[i - 1][j - 1]) % mod;通过预处理逆元的方式求组合数—— 模板题 AcWing 886. 求组合数 II首先预处理出所有阶乘取模的余数fact[N]，以及所有阶乘取模的逆元infact[N]如果取模的数是质数，可以用费马小定理求逆元\ncppint qmi(int a, int k, int p)    // 快速幂模板\n{\n    int res = 1;\n    while (k)\n    {\n        if (k &amp; 1) res = (LL)res * a % p;\n        a = (LL)a * a % p;\n        k &gt;&gt;= 1;\n    }\n    return res;\n}\n\n// 预处理阶乘的余数和阶乘逆元的余数\nfact[0] = infact[0] = 1;\nfor (int i = 1; i &lt; N; i ++ )\n{\n    fact[i] = (LL)fact[i - 1] * i % mod;\n    infact[i] = (LL)infact[i - 1] * qmi(i, mod - 2, mod) % mod;\n}Lucas定理—— 模板题 AcWing 887. 求组合数 III\ncpp若p是质数，则对于任意整数 1 &lt;= m &lt;= n，有：\n    C(n, m) = C(n % p, m % p) * C(n / p, m / p) (mod p)\n\nint qmi(int a, int k, int p)  // 快速幂模板\n{\n    int res = 1 % p;\n    while (k)\n    {\n        if (k &amp; 1) res = (LL)res * a % p;\n        a = (LL)a * a % p;\n        k &gt;&gt;= 1;\n    }\n    return res;\n}\n\nint C(int a, int b, int p)  // 通过定理求组合数C(a, b)\n{\n    if (a &lt; b) return 0;\n\n    LL x = 1, y = 1;  // x是分子，y是分母\n    for (int i = a, j = 1; j &lt;= b; i --, j ++ )\n    {\n        x = (LL)x * i % p;\n        y = (LL) y * j % p;\n    }\n\n    return x * (LL)qmi(y, p - 2, p) % p;\n}\n\nint lucas(LL a, LL b, int p)\n{\n    if (a &lt; p &amp;&amp; b &lt; p) return C(a, b, p);\n    return (LL)C(a % p, b % p, p) * lucas(a / p, b / p, p) % p;\n}分解质因数法求组合数—— 模板题 AcWing 888. 求组合数 IV当我们需要求出组合数的真实值，而非对某个数的余数时，分解质因数的方式比较好用：    1. 筛法求出范围内的所有质数    2. 通过 C(a, b) = a! / b! / (a - b)! 这个公式求出每个质因子的次数。 n! 中p的次数是 n / p + n / p^2 + n / p^3 + …    3. 用高精度乘法将所有质因子相乘\ncppint primes[N], cnt;     // 存储所有质数\nint sum[N];     // 存储每个质数的次数\nbool st[N];     // 存储每个数是否已被筛掉\n\n\nvoid get_primes(int n)      // 线性筛法求素数\n{\n    for (int i = 2; i &lt;= n; i ++ )\n    {\n        if (!st[i]) primes[cnt ++ ] = i;\n        for (int j = 0; primes[j] &lt;= n / i; j ++ )\n        {\n            st[primes[j] * i] = true;\n            if (i % primes[j] == 0) break;\n        }\n    }\n}\n\n\nint get(int n, int p)       // 求n！中的次数\n{\n    int res = 0;\n    while (n)\n    {\n        res += n / p;\n        n /= p;\n    }\n    return res;\n}\n\n\nvector&lt;int&gt; mul(vector&lt;int&gt; a, int b)       // 高精度乘低精度模板\n{\n    vector&lt;int&gt; c;\n    int t = 0;\n    for (int i = 0; i &lt; a.size(); i ++ )\n    {\n        t += a[i] * b;\n        c.push_back(t % 10);\n        t /= 10;\n    }\n\n    while (t)\n    {\n        c.push_back(t % 10);\n        t /= 10;\n    }\n\n    return c;\n}\n\nget_primes(a);  // 预处理范围内的所有质数\n\nfor (int i = 0; i &lt; cnt; i ++ )     // 求每个质因数的次数\n{\n    int p = primes[i];\n    sum[i] = get(a, p) - get(b, p) - get(a - b, p);\n}\n\nvector&lt;int&gt; res;\nres.push_back(1);\n\nfor (int i = 0; i &lt; cnt; i ++ )     // 用高精度乘法将所有质因子相乘\n    for (int j = 0; j &lt; sum[i]; j ++ )\n        res = mul(res, primes[i]);博弈论卡特兰数—— 模板题 AcWing 889. 满足条件的01序列给定n个0和n个1，它们按照某种顺序排成长度为2n的序列，满足任意前缀中0的个数都不少于1的个数的序列的数量为： Cat(n) = C(2n, n) / (n + 1)NIM游戏 —— 模板题 AcWing 891. Nim游戏给定N堆物品，第i堆物品有Ai个。两名玩家轮流行动，每次可以任选一堆，取走任意多个物品，可把一堆取光，但不能不取。取走最后一件物品者获胜。两人都采取最优策略，问先手是否必胜。\n我们把这种游戏称为NIM博弈。把游戏过程中面临的状态称为局面。整局游戏第一个行动的称为先手，第二个行动的称为后手。若在某一局面下无论采取何种行动，都会输掉游戏，则称该局面必败。所谓采取最优策略是指，若在某一局面下存在某种行动，使得行动后对面面临必败局面，则优先采取该行动。同时，这样的局面被称为必胜。我们讨论的博弈问题一般都只考虑理想情况，即两人均无失误，都采取最优策略行动时游戏的结果。NIM博弈不存在平局，只有先手必胜和先手必败两种情况。\n定理： NIM博弈先手必胜，当且仅当 A1 ^ A2 ^ … ^ An != 0\n公平组合游戏ICG若一个游戏满足：由两名玩家交替行动；在游戏进程的任意时刻，可以执行的合法行动与轮到哪名玩家无关；不能行动的玩家判负；则称该游戏为一个公平组合游戏。NIM博弈属于公平组合游戏，但城建的棋类游戏，比如围棋，就不是公平组合游戏。因为围棋交战双方分别只能落黑子和白子，胜负判定也比较复杂，不满足条件2和条件3。\n有向图游戏给定一个有向无环图，图中有一个唯一的起点，在起点上放有一枚棋子。两名玩家交替地把这枚棋子沿有向边进行移动，每次可以移动一步，无法移动者判负。该游戏被称为有向图游戏。任何一个公平组合游戏都可以转化为有向图游戏。具体方法是，把每个局面看成图中的一个节点，并且从每个局面向沿着合法行动能够到达的下一个局面连有向边。\nMex运算设S表示一个非负整数集合。定义mex(S)为求出不属于集合S的最小非负整数的运算，即：mex(S) = min{x}, x属于自然数，且x不属于S\nSG函数在有向图游戏中，对于每个节点x，设从x出发共有k条有向边，分别到达节点y1, y2, …, yk，定义SG(x)为x的后继节点y1, y2, …, yk 的SG函数值构成的集合再执行mex(S)运算的结果，即：SG(x) = mex({SG(y1), SG(y2), …, SG(yk)})特别地，整个有向图游戏G的SG函数值被定义为有向图游戏起点s的SG函数值，即SG(G) = SG(s)。\n有向图游戏的和—— 模板题 AcWing 893. 集合-Nim游戏设G1, G2, …, Gm 是m个有向图游戏。定义有向图游戏G，它的行动规则是任选某个有向图游戏Gi，并在Gi上行动一步。G被称为有向图游戏G1, G2, …, Gm的和。有向图游戏的和的SG函数值等于它包含的各个子游戏SG函数值的异或和，即：SG(G) = SG(G1) ^ SG(G2) ^ … ^ SG(Gm)定理有向图游戏的某个局面必胜，当且仅当该局面对应节点的SG函数值大于0。有向图游戏的某个局面必败，当且仅当该局面对应节点的SG函数值等于0。\n数据范围一般ACM或者笔试题的时间限制是1秒或2秒。在这种情况下，C++代码中的操作次数控制在∼为最佳。下面给出在不同数据范围下，代码的时间复杂度和算法该如何选择：, 指数级别, dfs+剪枝，状态压缩dp，floyd，dp，高斯消元，，dp，二分，朴素版Dijkstra、朴素版Prim、Bellman-Ford，块状链表、分块、莫队=&gt;各种sort，线段树、树状数组、set/map、heap、拓扑排序、dijkstra+heap、prim+heap、Kruskal、spfa、求凸包、求半平面交、二分、CDQ分治、整体二分、后缀数组、树链剖分、动态树, 以及常数较小的O(nlogn)算法=&gt;单调队列、hash、双指针扫描、并查集，kmp、AC自动机，常数比较小的O(nlogn)的做法：sort、树状数组、heap、dijkstra、spfa，双指针扫描、kmp、AC自动机、线性筛素数，判断质数，最大公约数，快速幂，数位DP，高精度加减乘除，k表示位数，FFT/NTT\n清风的算法主页\n","slug":"算法基础模板","date":"2023-03-07T13:14:24.000Z","categories_index":"算法编程","tags_index":"算法","author_index":"以太工坊"},{"id":"26698f911e325cfba7ac154843c0d927","title":"SSH通道转发端口","content":"\n\n\n\n\n\n\n\n\n背景：有一台服务器，仅能访问ssh服务端口，其余端口处于安全考虑均不可访问。如果想与服务器的其他端口通信，该怎么办？ 参考文章\n利用ssh通道，即可任意通信，下面这张图很直观。\n基本命令基本命令如下，利用：\nbashssh -L 本地端口X:主机C:主机C端口Z username@hostB利用本机与hostB的SSH隧道，通过访问本机的X端口实现对主机C Z端口的访问。本质是B访问了C，再经由通道与本机连接。\n可选参数\n-N 表示不登录ssh，只进行端口转发。\n-f 表示将 SSH 进程放到后台运行。\n-L 表示进行本地端口转发，格式为：本地端口:目标主机:目标端口。一条命令可以有多个-L参数代表多条规则。\n-R 反向转发，但本地主机与C的位置要调换。如ssh -R 8000:localhost:8080 user@ssh_server 是将服务器的8000转发到本地的8080端口。\n-D 流量SOCKS5代理。\n\n应用场景突破防火墙\n\n\n\n\n\n\n\n\n即背景介绍。防火墙阻止了主机A对主机B一些端口的连接，但主机B仍有部分端口是对主机A开放的。这时主机A如果需要访问主机B上被防火墙阻挡的端口，就可以通过SSH连接主机B＋端口转发来进行。需注意，这时所谓的主机C就是主机B。\nbash ssh -L 5000:localhost:5000 root@MLB -p 4701 -N这样访问本机的5000端口，就可以访问到服务器的5000端口，而实际上5000端口被防火墙阻止了。\n网络分区\n\n\n\n\n\n\n\n\n主机B与主机C处于同一内网中，主机B能够与外界联系而主机C不能。这时不处于内网中的主机A如果想要访问主机C，就可以通过SSH连接主机B＋端口转发来进行。\nbashssh -L 22022:10.0.2.15:22 desktop_user@192.168.1.11主机B的ip为192.168.1.11，10.0.2.15是B中的一个虚拟机C,主机B执行这条命令即可经本地22022端口访问到虚拟机的22端口。\n访问非公网端口\n\n\n\n\n\n\n\n\n处于内网之中的主机A可以访问公网，但不具有公网IP；公网中的主机B无法找到A，但为A开放各个端口的访问（A可以直接连接B，反之则不行）。这时A想要让B访问自己，就可以通过SSH连接主机B＋端口转发来进行。需注意，这时所谓的主机C就是主机A。\n见-R 的参数说明。\n动态端口转发一般可用作代理，用于在本地计算机上创建一个 SOCKS 代理服务器。通过 -D 参数创建的 SOCKS 代理服务器可以将本地计算机上的网络流量通过 SSH 隧道转发到远程服务器，从而实现本地计算机上的应用程序通过远程服务器访问互联网的功能。-D 参数的语法如下：\nbashssh -D [bind_address:]port user@ssh_server其中，bind_address 表示绑定的 IP 地址，可以省略；port 表示要创建的 SOCKS 代理服务器监听的端口号。该命令将在本地计算机上启动一个 SOCKS 代理服务器，并将该服务器绑定到指定的端口上。例如，如果想要在本地计算机上创建一个 SOCKS 代理服务器，将所有网络流量通过远程服务器转发到互联网上，可以使用以下命令：\nbashssh -D 1080 user@ssh_server在执行该命令后，可以将本地计算机上的应用程序（如浏览器）的代理设置为 127.0.0.1:1080，从而将所有网络流量通过 SSH 隧道转发到远程服务器上，并从远程服务器访问互联网。请注意，为了保护数据的安全性，建议使用加密的 SSH 连接进行 SOCKS 代理。\n","slug":"SSH通道转发端口","date":"2023-02-27T12:45:44.000Z","categories_index":"技术帖子","tags_index":"技术贴士,网络","author_index":"以太工坊"},{"id":"d876e899186b5d29f08ac1246c03fe0f","title":"医学超声质控系统简介","content":"\n\n\n\n\n\n\n\n\n系统仍在开发中，不代表最终品质，本文仅用于大创项目前期准备。术语通俗化解释：标准切面——对某种器官的超声成像，需要包含指定的结构、部位，比如心脏标准切面需要包含左心房、左心室、右心房、右心室、主动脉。图像分割——也叫语义分割。输入给神经网络（我们用的是BiSeNet,原作者用于遥感图像，我们做了修改）一张图像，他会标出图中每一种目标的位置。\n\n\n整体介绍整个质控系统的核心功能有二：\n\n标准切面识别（即将完成）\n分割图像并测距（已完成）\n\n系统界面中间的大图像是输入的原始图像。左上为切面识别结果，会显示识别到的切面部位。比如，如果是心脏标准切面中，应该用5个方框标出对应的结构。左中为图像分割与测距的结果。大面积上色的部分就是语义分割的结果，经过语义分割，我们能得到心脏结构的完整的图形学信息。黄色的框就是基于语义分割做的测距。右上是识别到的切面信息，依据结构是否完整，可以判断是否是标准切面。右下是基于语义分割进行的测距结果，可与输入的测距信息对比、打分。系统演示视频\n系统用途\n辅助培训超声检查医生\n帮助门诊医生筛查阳性病例\n嵌入超声检查设备，实时识别标准切面\n….\n\n未来展望\n批量导入图片与医生的测距信息\n拓展切面种类，胸腔、腹腔、胸骨、血管…\nOCR识别医生标注好的信息，并生成检查报告\n…\n\n","slug":"CVP_demo","date":"2023-02-22T11:32:50.000Z","categories_index":"","tags_index":"科研项目","author_index":"以太工坊"},{"id":"11049db348f99a08b5c18bbc7e510d06","title":"数据挖掘笔记","content":"第1章 认识数据挖掘数据挖掘的定义技术角度：利用计算机技术，从数据中自动分析并提取信息的处理过程；目的是发掘数据中潜在的有价值的信息；一般使用机器学习、统计学、模式识别等多种方法来实现。学科角度：交叉学科，设计人工智能、统计学、可视化、并行计算等。商业角度：揭示隐藏的、未知的或验证已知的规律；\n有指导学习和无指导学习\n\n\n\n\n\n\n\n\n机器学习中的基本方法有：概念学习、归纳学习、有指导学习和无指导学习。\n有指导学习：通过对大量已知分类或输出的实例进行训练，调整分类模型的结构，达到建立准确分类或预测位置模型的目的；这种基于归纳的概念学习过程被称为有指导学习。无指导学习：在学习训练之前，无预先定义好分类的实例。数据实例按照某种相似度度量方法，计算相似程度，将最为相似的实例聚类在一个簇中，再解释和理解每个簇的含义，从中发现聚类的意义。（K-Means，凝聚聚类，概念分层Cobweb，EM算法）\n数据挖掘的过程四个步骤：\n\n准备数据，包括训练数据和检验数据；\n选择一种数据挖掘技术或算法，将数据提交给挖掘软件；\n解释和评估模型；\n模型应用；准备数据可从数据库、数据仓库、平面文件收集；选择技术与算法需要考虑：\n\n\n判断学习是有指导还是无指导的；\n数据集中怎样划分训练、测试、检验数据；\n如何设置数据挖掘算法的参数；\n\n数据挖掘的作用（种类分类，非技术）\n有指导学习\n分类\n估计\n预测\n\n\n无指导聚类\n关联关系分析\n\n第2章 基本数据挖掘技术决策树\n\n\n\n\n\n\n\n\n1、决策树概念和C 4.5算法的一般过程2、决策树关键技术：最大增益率3、决策树规则：决策树，产生式规则，正确率和覆盖率\n概念决策树是一个树状结构的模型，每个节点表示对象的某个属性，分支表示属性的某个可能取值，叶节点的取值就是决策树的输出结果。\nC4.5算法（1）给定一个表示为“属性-值”格式的数据集T。数据集由多个具有多个输入属性和一个输出属性的实例组成。（2）选择一个最能区别T中实例的输入属性，C4.5使用增益率来选择该属性。（3）使用该属性创建一个树节点，同时创建该节点的分支，每个分支为该节点的所有可能取值。（4）使用这些分支，将数据集中的实例进行分类，成为细分的子类。（5）将当前子类的实例集合设为T，对数据集中的剩余属性重复（2）（3）步，直到满足以下两个条件之一时，该过程终止。创建一个叶子节点，该节点为沿此分支所表达的分类类别，其值为输出属性的值。\n\n该子类中的实例满足预定义的标准，如全部分到一个输出类中，或者分到一个输出类中的实例达到某个比例；\n没有剩余属性。\n\n关键技术选择最能区分实例属性的方法优先选择具有最大增益率的属性来使数据的概化程度最大（层次和节点数最小）。信息熵熵是不确定程度的度量，越大则信息量越大，传输的信息越多；信息增益增益越大，熵降越快，越利于分类。出现在类中的数量实例总数出现在类中的数量实例总数为当前数据集所有实例表达的信息总量；出现在类中的实例个数所有实例总数类为根据属性A的k个取值分类I后的信息量；出现在类中的实例个数所有实例总数出现在类中的实例个数所有实例总数是对A属性的增益值的标准化；\n剪枝方法检验方法\n百分比检验\n交叉验证  k折  留出  留一\n\n决策树规则将决策树翻译成规则，计算正确率与覆盖率；\ntxtIF Courses &lt;≤5 and Weather = Rain THEN Play = No\n正确率：3/5 = 60% 覆盖率：3/8 = 37.5%\n正确率:满足整句/满足前半句 覆盖率：满足整句/满足后半句优缺点（了解）优点（1）容易被理解和被解释，并且可以被映射到一组更具吸引力的产生式规则。（2）不需要对数据的性质作预先的假设。（3）能够使用数值型数据和分类类型数据的数据集建立模型。局限性（1）输出属性必须是分类类型，且输出属性必须为一个。（2）决策树算法是不稳定（Unstable）的。（3）用数值型数据集创建的树较为复杂（如例2.3中的未剪枝的决策树），因为数值型数据的属性分裂通常是二元分裂。\n关联规则Apriori算法的基本思想\n生成条目集。条目集是符合一定的支持度要求的“属性-值”的组合。那些不符合支持度要求的组合被丢弃，因此规则的生成过程可以在合理的时间内完成。\n使用生成的条目集依据置信度创建一组关联规则。\n\n关联规则及其置信度和支持度支持度：满足整句/满足后句置信度：满足整句/满足前句\n在实际使用时，依次生成单项、双项、三项条目集，以生成的条目集为基础创建关联规则。\ntxt以双项条目集中的第一条条目生成的两条规则——\nIF Book =1 THEN Earphone = 1 （置信度：4/5 = 80%，保留）\nIF Earphone = 1 THEN Book =1（置信度：4/7 = 57.1%，删除）\n以三项条目集中的第一条条目生成的三条规则——\nIF Book =1 &amp; Earphone = 1 THEN DVD = 1（置信度：4/4 = 100%，保留）\nIF Book =1 &amp; DVD = 1 THEN Earphone = 1（置信度：4/4 = 100%，保留）\nIF Earphone = 1 &amp; DVD = 1 THEN Book =1（置信度：4/6 = 66.7%，删除）聚类技术K-means算法的基本思想\n随机选择一个K值，用以确定簇的总数。\n在数据集中任意选择K个实例，将他们作为初始的簇中心。\n计算这K个簇中心与其他剩余实例的简单欧式距离。用这个距离作为实例之间相似性的度量，将与某个簇相似度高的实例划分到该簇中，成为其成员。\n使用每个簇中的实例来计算新的簇中心。\n如果得到的新的簇中心等于上次迭代的簇中心，终止算法。否则，用新的簇中心重复3~5. \n\nK-means聚类分析实例优缺点优势非常受欢迎的算法，容易理解，实现简单。局限性（1）只能处理数值型数据，若数据集中有分类类型的属性，要么将该属性删除，要么将其转换成等价的数值数据。（2）算法开始前，需要随机选择K值作为初始的簇个数（带有随意性，错误的选择将影响聚类效果）。通常选择不同的K值进行重复实验，期望找到最佳K值。（3）当簇的大小近似相等时，K-means算法的效果最好。（4）对于聚类贡献不大的属性可能会对聚类效果造成影响（孤立点）。在聚类之前需对属性进行选择。（5）簇的解释困难。可使用有指导的挖掘工具对无指导聚类算法所形成簇的性质作进一步的解释。\n第3章 数据库中的知识发现KDD的定义(了解)Knowledge Discovery in Data，从数据集中提取可信的、新颖的、具有潜在价值的、能被人理解的、非繁琐的处理过程（大部分步骤由系统自动执行）。\nKDD过程模型经典模型CRISP-DM商业模型联机模型OLAM数据预处理：直方图归约、数据规范化和数据平滑分箱法：（噪声处理-&gt;数据平滑）将==数据排序==，如3，6，12，22，24，26，27，30，30“等高度”划分成三个箱，每个箱子中的数据个数相同；“等宽度”，每个箱子跨越的范围固定；均值、最值、保留最值做边界其余靠拢等方式平滑。\n直方图规约划分等宽或等深的桶，计数，画直方图\n数据标准化\n\n最小-最大缩放（Min-Max Scaling）：将数据缩放到0-1之间的范围，通过对原始数据进行线性变换来实现。具体来说，最小-最大缩放将原始数据v缩放到新的取值范围v’，计算公式为，其中b-a是区间长度，a是区间起始点，这样可以把规范化的结果映射到某一段区间内，如果没有说明，可以忽略区间的参数。\n\nZ-score标准化（Z-score normalization）：将数据缩放为均值为0、标准差为1的分布，使得数据分布在以0为均值，1为标准差的正态分布中。具体来说，Z-score标准化将原始数据x标准化为新的取值范围y，计算公式为y = (x - μ) / σ，其中μ和σ分别是原始数据的均值和标准差。\n\n小数定标标准化（十进制缩放）（Decimal scaling）：通过移动小数点的位置，将数据缩放到[-1,1]或[-0.5,0.5]之间的范围。具体来说，小数定标标准化将原始数据x乘以10的k次方，得到新的取值范围y，计算公式为y = x / 10^k，其中k是满足10^(k-1) ≤ |x| &lt; 10^k的整数。根据最大值决定移动的位数。\n\n对数标准化是一种将数据转换为对数的数据预处理方法，常用于将非负数数据进行平滑处理，使其更易于比较和分析。具体来说，对数标准化将原始数据x取对数，得到新的取值范围y，计算公式为y = log(x)。\n\n归一化（Normalization）：将数据缩放到单位长度或者单位范围内，常用的归一化方法包括L1范数归一化和L2范数归一化。具体来说，L1范数归一化将原始数据x缩放为新的取值范围y，计算公式为y = x / (|x1| + |x2| + … + |xn|)；L2范数归一化将原始数据x缩放为新的取值范围y，计算公式为y = x / sqrt(x1^2 + x2^2 + … + xn^2)。\n\n\n第5章 评估技术评估分类类型输出模型\n\n\n\n真正例\n真反例\n\n\n\n预测正例\nTP\nFP\n\n\n预测反例\nFN\nTN\n\n\n正确率\n\n\n\n\n错误率\n\n\n\n\n查准率\n\n\n\n\n查全率\n\n\n\n\n评估数值型输出模型\n第6章 神经网络人工神经元模型R个输入，即R维输入矢量pn: net input, 。    R个权值，即R维权矢量w    阈值b输出a=f(n),  f: transfer function常用的激活函数Sigmoid函数最重要的特征就是无限可微。\nBP神经网络BP神经网络结构，前向计算过程注意，每一个神经元都与后一层全连接，同一层之间不连接。\nBP算法的一般过程B-P算法的学习过程如下：（1）选择一组训练样例，每一个样例由输入信息和期望的输出结果两部分组成。（2）从训练样例集中取一样例，把输入信息输入到网络中。（3）分别计算经神经元处理后的各层节点的输出。（4）计算网络的实际输出和期望输出的误差。（5）从输出层反向计算到第一个隐层，并按照某种能使误差向减小方向发展的原则，调整网络中各神经元的连接权值。（6）对训练样例集中的每一个样例重复（2）—（5）的步骤，直到对整个训练样例集的误差达到要求时为止。\nCNN卷积第一种神器叫做局部感受野。因为在一个图像中，距离较近的像素联系较为紧密，而距离较远的像素相关性则较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。第二级神器，即权值共享。怎么理解权值共享呢？我们可以把卷积操作看成是提取特征的方式，该方式与位置无关。这其中隐含的原理则是：图像的一部分的统计特性与其他部分是一样的。这也意味着我们在这一部分学习的特征也能用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。权重共享有什么好处呢？一方面，重复单元能够对特征进行识别，而不考虑它在可视域中的位置。另一方面，权值 共享使得我们能更有效的进行特征抽取，因为它极大的减少了需要学习的自由变量的个数。通过控制模型的规模，卷积网络对视觉问题可以具有很好的泛化能力。解释卷积层的最好方式是想象一个手电筒正在图像的左上方进行照射，假设手电照射的区域是5 x 5的范围。再想象下这个手电筒在输入图像的各个区域进行滑动。在机器学习术语中，这个手电筒叫做滤波器（有时候也称为神经元或者卷积核），它照射着的区域被称为感受野。这个滤波器也是一系列的数据（这些数据被称为权重或者参数）。\n池化/采样最大池化就是选择池化窗口中的最大值作为采样值平均池化就是将池化窗口中所有值相加取平均，以平均值作为采样值。池化可以降低参数量、减少过拟合的风险。\n第7章 统计技术回归分析回归分析是一种统计分析方法，用来确定两个或两个以上变量之间的定量的依赖关系，并建立一个数学方程来概化一组数值数据。最小二乘法构造误差函数做目标函数（一般是二阶的），对自变量求偏导\n贝叶斯分析一种参数估计方法，将关于未知参数的先验信息与样本信息结合（列表），根据贝叶斯公式，计算条件概率，得出后验信息，从而推断未知参数；存在的问题：\n\n概率为0–加小常数\n数据缺失–简单忽略，概率记为1\n\n聚类技术\n\n\n\n\n\n\n\n\n聚类有划分聚类（K-Means）、分层聚类(凝聚、分裂）、模型聚类（EM算法）三大种；\n凝聚聚类算法一种无指导聚类算法。开始时，每个实例在不同的分类中，各自单独成一簇；找两个最相似的簇，合并，直到满足要求或合并成一类为止\nCobweb分层聚类一种增量式分层聚类算法。使用分类树对实例进行分类，分类树的构造过程是一种概念分层的过程。树的根节点是概念最高层次，包含所有域实例的汇总信息；除了叶节点，其他节点都是树的基层节点，表达了概念划分的层次。使用评价函数来度量概念层次的质量。分类对象必须是分类类型的。算法：\n\n建立一个类，使用第一个实例作为它的唯一成员；\n对于剩余实例。在每个树层次（概念分层）上，用评价函数决定执行下列动作之一：\n将新的实例放到一个已存在的簇中；\n创建一个只有这个新实例的新概念簇；\n\n\n\nCU值的计算：表示在类的全体成员中，属性取值为的概率表示在整个数据集中，属性取值为的概率表示每个类的概率\n优势：能够自动调整类（簇）的个数，不会因为随机选择分类个数的不合理性而造成聚类结果的不理想。局限性：\n\n对实例顺序敏感，需要引入两种附加操作——合并和分解降低敏感性。\n假设每个属性的概率分布是彼此独立的，而实际这个假设不总是成立；\n类（簇）的概率分布的表示、更新和存储的复杂程度，取决于每个属性取值个数。当属性取值较多时，算法的时间和空间复杂度会很大。\n偏斜的实例数据会造成概念分层树的高度不平衡，也会导致时间和空间复杂度的剧烈变化。\n\n","slug":"数据挖掘复习笔记","date":"2023-02-20T08:00:00.000Z","categories_index":"机器学习","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"99230992a5d996b8504b4e44c8a0c83b","title":"大数据存储笔记","content":"第一章产生背景横向拓展，水平拓展；用更多的节点支持更大量的请求。纵向拓展，垂直拓展；扩展一个节点的能力支撑更大量的请求。大数据的特点：volume，velocity，variety，value横向拓展需求、系统可靠可用、一致性需求在传统的关系模型下无法有效解决\n大数据需要怎样的存储大数据存储的集群系统，需要满足：\n\n能够对集群内的计算机及存储资源进行统一管理、调度和监控\n能够对集群内的数据进行分散存储和统一管理\n集群内的计算机可以共同完成一个任务，分工协作、负载均衡\n当集群中某一台计算机发生故障，集群可以保证功能的有效性、且数据不会丢失（分区容错性）\n可以用简单的方式部署集群、扩展集群以及替换故障节点（伸缩性）\n\n技术分类• 按元信息管理方式划分：对等节点的策略，由于没有中心节点的束缚有更高的可用性。中心节点的策略，更好的可扩展性。• 按数据模型划分：针对不同业务模型出现的不同数据模型的数据库• 分布式架构Partition All -分库分表Partition Engine -Share NothingPartition Storage -Share Storage 存算分离\nNoSQL与newSQLNoSQL是非关系型的数据库，主要用于解决SQL的可扩展性问题。不保证ACID特性，没有事务管理，无需多余操作就可以横向扩展；NewSQL是关系型数据库，兼具Nosql数据库的海量存储管理能力和关系数据库的ACID特性和SQL便利性。\n第二章基于C/S的层次结构AP与DPAP是面向用户的应用处理器，用于完成数据处理的软件，能向CM传递用户的请求和数据。DP是数据处理器，负责进行数据管理，类似一个集中式数据库管理系统，接受CM传递的命令和数据并给予反馈。 \nAP功能的变化 集中库 -不存储数据，相当于输入，主机运行了所有软件 多客户/单服务器 -应用、客户端服务（查询）、通信 多客户/多服务器 -应用、客户端服务（目录管理、缓存管理、查询处理、提交协议）、通信 瘦客户端/服务器 -客户端Server2Sever 上述功能转移给服务器，仅保留SQL接口与程序接口；AP是计算相关内容：目录管理、缓存管理、查询处理、事务处理、锁管理、访问控制。此外服务端还有存储相关功能：日志回放、故障恢复、索引设计、物理存储。\n三种架构\n\n\n\n\n\n\n\n\n个人理解，正确性不能保证。 参考文章\n\n基于Server-to-server瘦客户端/服务器架构讨论的这三种分布式架构\nserver-搜索引擎 -查询、优化、提取；并发控制；事务提交； engine-事务部分（针对于恢复，因为需要日志，有状态）、索引、日志、故障恢复、物理存储的部分\n三种架构的定义\n各部分的可拓展性与兼容性特点\n\n三种架构本质是newSQL想兼有SQL的强一致性、事务支持与NoSQL的易拓展性的不同实现方式，但又陷入可拓展性与兼容性的拔河比赛中。\n从上到下，依次是Partition ALL(分库分表)，Partition Enginee(share nothing)，Partition Storage（存算分离）；从上到下可拓展性降低，换来生态兼容性的增加。分库分表可拓展性极佳，性能高；但业务耦合大，通常需要根据业务场景设计，需要用户自己处理分片策略、分布式事务、分布式Query，通用性差。每个节点都是完整的DBMS。Share Nothing只在引擎层做分片，节点间相对独立。相对于传统的分库分表，将分布式事务与分布式查询等问题放到了数据库内部处理，向用户屏蔽了分布式事务等细节，提供统一的数据库服务，简化了用户使用。\n\n\n\n\n\n\n\n\n\n尴尬的是，大多数分库分表的实现也会通过中间件（数据处理、数据管理、负载均衡、驱动数据库） 的引入来屏蔽分布式事务等实现细节，同样采用类Multi Paxos这样的一致性协议来保证副本一致，同样对用户提供统一的数据库访问，那么相较而言，Partition Engine的策略优势好像又没有很大。\n继续将分片的分界线下移，到事务及索引系统的下层。这个时候由于Part 1部分保留了完整的事务系统，已经不是无状态的，通常会保留单独的节点来处理服务。这样Part 1主要保留了计算相关逻辑，而Part 2负责了存储相关的像REDO，刷脏以及故障恢复。因此这种结构也就是我们常说的计算存储分离架构，也被称为Share Storage架构。由于保持了完整的计算层，所以相对于传统数据库需要用户感知的变化非常少，能够做到更大程度的生态兼容。同时也因为只有存储层做了分片和打散，可扩展性不如上面提到的两种方案。\nDDBS的组件结构\n– 应用处理器（AP）功能：用户接口：检查用户身份，接受用户命令（如SQL）语义数据控制器：一些约束（视图管理、安全控制、语义完整性控制）全局查询处理器：将用户命令翻译成数据库命令；生成全局查询计划；收集局部查询结果并返回给用户全局执行监控器（全局事务管理器）：调度和监视AP和DP；保证复制数据的一致性；保证全局事务的原子性– 数据处理器（DP）功能：局部查询处理器：全局命令 —&gt; 局部命令；选择最好的访问路径去执行局部事务管理器：以局部子事务为单位进行调度执行局部调度管理器：负责局部场地上的并发控制局部恢复管理器：维护本地数据库一致性的故障恢复存储管理器：访问数据库；控制数据库缓存管理器；返回局部执行结果\nDDBS的模式结构\n\n全局外模式(GES): 全局外模式即全局用户视图，是分布式数据库的全局用户对分布式数据库的最高层抽象。\n全局概念模式(GCS): 全局概念模式即全局概念视图，是分布式数据库的整体抽象，包含了全部数据特性和逻辑结构。全局概念模式再经过分片模式和分配模式映射到局部概念模式。\n分片模式是描述全局数据的逻辑划分视图。即全局数据逻辑结构根据某种条件的划分，将全局数据逻辑结构划分为局部数据逻辑结构。每一个逻辑划分成一个分片。在关系数据库中，一个关系中的一个子关系称该关系的一个片段。\n分配模式是描述局部数据逻辑的局部物理结构，即划分后的分片的物理分配视图。\n局部概念模式(LCS) ：局部概念模式为局部概念视图，是全局概念模式的子集。局部概念模式用于描述局部场地上的局部数据逻辑结构。当全局数据模型与局部数据模型不同时，还涉及数据模型转换等内容。\n局部内模式(LIS) ：定义局部物理视图，是对物理数据库的描述，类似集中数据库的内层。\n\nDDBS的数据透明性\n分片透明性：分片是将一个关系分成几个子关系，每个子关系称为一个分片。用户不必考虑数据属于哪个分片的性质称为分片透明性。位于全局概念模式和分片模式之间。\n分配透明性：分布数据库支持有控制的数据冗余，即数据可重复存储在不同的场地上。用户不必考虑各个片段的存储场地称为分配透明性。位于分片模式和分配模式之间。\n局部映射透明性：用户不必考虑数据的局部存储形式称为局部映射透明性。位于分配模式与局部概念模式之间。\n\ntxtselect . from S --分片透明性\nselect . from S1 &amp; S2 --分配透明性\nselect . from S1 at site1 --局部映射透明性\nExecute:$SUPIMS($SNO,$FOUND,$SNAME) at L1 --不透明MDBS V.S. DDBS 4点分布式数据库系统：是自上而下(top-down) 地设计数据库，可灵活地进行分片和分配设计。但分布式数据库系统具有数据库组件数量的限制，通常不多于数十个数据库组件。多数据库集成系统：数据和数据库已存在，是遵循自下而上(bottom-up) 地集成各局部场地上的数据。数据集成系统通过约束数据管理能力(只支持读) ，可将数据库组件数量扩展到数百个。二者都需要为用户提供统一的存取数据环境，数据都分散存储，区别在于：\n\n数据模式是否预先定义\nDBMS是否同构\n查询优化策略是否自动生成\n是否一定存在局部用户（MDBS是）\n\n第三章3.1 分布式数据库设计（分片，分配，复制）3.1.1 设计的策略与步骤自顶向下，需求分析-&gt;概念设计-&gt;分布设计-&gt;物理设计-&gt;性能调优\n3.1.2 分片的定义及作用分片（Fragmentation)：对全局数据的逻辑划分。分配（Allocation）：对片段的存储场地的指定，称为分配。当片段存储在一个以上场地时，称为数据复制（Replication）。如果每个片段只存储在一个场地，称为数据分割（Partition）存储。\n分片的作用：\n\n减少网络传输数据量\n增大事务处理的局部性\n提高数据的查询效率和系统可靠性\n使负载均衡分片过程是将全局数据进行逻辑划分和实际物理分配的过程。全局数据由分片模式定义成各个片段数据，各个片段数据由分配模式定义存储在各个场地。\n\n分片的原则：完备性（数据不丢）、可重构性（关系不丢）、不相交性（形式化描述）\n分片的种类：水平分片（按元组）、垂直分片（按属性）、混合分片\n3.1.3 水平分片水平分片：选择\n导出式：半联接\n设计依据分片的需求信息，来源于应用因素和数据库因素\n设计准则：定义具有完备性和最小性的一组简单谓词集\n3.1.4 垂直分片分片表示：投影运算\n完备性证明：并运算（属性）\n可重构性证明：连接运算\n不相交性证明：交运算，结果不是空，是主关键字\n3.1.5 分片的表示方法图形表示法（表格）和树形表示法\n\n\n3.1.6 分配设计片段到物理场地存储映射的过程称为分配设计的过程。\n\n非复制分配如果每个片段只存储在一个场地上，称为分割式分布，对 应的分布库，称为全分割式分布库。 \n复制分配如果每个片段在每个场地上存有副本，称为全复制分配，对应的分布库称为全复制分布库。如果每个片段只在部分场地上存有副本，称为部分复制分配，对应的分布库称为部分复制分布库。\n\n3.1.7 数据复制技术同步复制与异步复制；主从复制与对等复制；\n3.2 分布式查询优化(体现关键步骤，分片展开等，∪是二元运算，圈空)\n3.2.1 查询优化的意义3.2.2 查询处理器3.2.3 查询分解基于全局概念模式将演算查询分解为代数查询。得到全局逻辑查询计划树。以下五步：\n\n查询规范化（交换律结合律分配律）\n语法及语义分析（语法错误、无意义的查询、无权限，通过查询图）\n查询约简\n查询重写\n\n3.2.4 数据局部化将全局表利用并运算和连接运算分解为局部表先画出全局树，优化全局树，转换为片段查询树，及时将选择运算、联接运算置空，并将∞下移到∪之前执行（利用分配律）\n3.2.5 片段查询的优化3.3 分布式存取优化3.3.1 基本概念3.3.2 优化的理论基础关系的基： 指关系R包含的元组个数，记为Card(R)• 属性的长度：指属性A定义的取值字节数，记为Length(A)• 元组的长度：关系R中每个元组的字节数，记为Length(R),Length(R)=∑Length(Ai)• 关系的大小：关系R所包含的字节数，记为Size(R)Size(R)=Card(R) Length(R)• 属性的特征值：指关系R中属性A取值不同的属性值个数，记为Val(A)• 属性A的最大值和最小值：记为Max(A)和Min(A)\n选择运算：基数：Card（S）=ρ Card（R）*ρ的计算：仅考虑选择属性A条件的等值情况**，其中A是R的属性，X是常数。 则\nVal(S,B)的计算：当属性B属于选择条件时，Val(S,B)=1当属性B为关键字（主键）时，Val(S,B)=ρ Val(R,B)当属性B不属于选择谓词时，\n联接运算：\n半连接运算：\n3.3.3 半连接优化方法就是看绕这么一圈，半连接付出的代价有没有全连接多。\nmarkdown作业一 分片设计\n存在一个商品购物系统，系统中包含两个全局关系：用户表USER(UID，UNAME，ADDRESS，HOBBY，CITY) 和订单表ORDER(UID，PID，PRICE) ，UID为用户编号，UNAME为用户姓名，CITY为所在城市。PID为商品编号，PRICE为订单总价，UID在USER表中是主键，在ORDER表中是外键。先要进行分布式数据库的建立，分片的规则是：\n（1）关系USER按属性敏感程度垂直分片\nU1包含非敏感属性：UID，UNAME，CITY\nU2包含敏感属性：ADDRESS，HOBBY\n（2）USER中的所有非敏感属性再根据CITY进行水平分片\nU11：CITY IN { 北京，上海，广州，深圳}\nU12：CITY NOT IN { 北京，上海，广州，深圳}\n（3）关系ORDER按照和USER 的连接关系进行分片，得到O1和O2 。\n\n作业二 查询优化\n查询Q： “查询“徐州市”用户购买商品编号为“P1”的所有订单，获取订单中的用户编号、用户姓名、商品编号和订单总价” 。\n（1）写出查询Q的关系代数表达式，并变换到片段查询\n（2）对片段查询树进行优化\n\n作业三 存取优化\n如下图\n第四章 HBaseHDFS的问题\n不支持对数据的随机改写\nHDFS没有数据包的概念\nHDFS无法针对行数统计、过滤扫描等常见的数据查询功能实现快捷操作，一般需要通过Mapreduce实现。\n（优势是大文件存储、多副本、自动分块）\n\nHBase的特点\n底层采用HDFS存储，但文件结构和元数据由自身维护。\n采用面向列+键值对的存储模式\n可实现便捷的横向拓展\n可以实现自动的数据分片\n较为严格的读写一致性和自动故障转移\n对全文的检索与过滤优点在于擅长处理大量数据的写入、高性能、高可靠、可拓展；缺点是不支持表的关联查询分析等。\n\nRegionRegion server是存放Region的容器；Region是表的数据的一部分，一个Region相当于关系数据库中表的一个分片。一个表可能存放于不同的Region中。特点：\n\nRegion不能跨服务器，一个Region Server会有一个或多个Region;\n数据量增大时，Region会发生分裂；\n处于负载均衡的需要，Region会发生迁移；\nRegion所有的数据存取操作都是调用HDFS的客户端接口实现的。\n\n\n\n\n\n\n\n\n同一个表不同行的数据可以存放在不同的服务器，同一个表相同行的数据也可以存放在不同的服务器。这句话如何理解？(我不理解，我觉得后半句有问题。)一个服务器是Region的存储机构，但存储一个Region不代表存储一个表；每个Region都包含若干个Store，一个Store就是一个列族，是把列族作为对象存储的，不一定是一个表的，可能是不同表的分片。\n\n\n预写日志WAL:先写到WAL中（一个Regionserver就一个WAL），在加载到memStore中；每个region内部都有多个store实例，每个store对应一个列族；每个store中有一个memStore实例，当memStore满了，HDFS就会生成一个新的HFile（用LSM树来存储，会在最终刷写之前进行快速排序，使随机写入的数据实现顺序存储，提高读取效率）；memStore可以看作在内存中的缓存，无论读写，都会先看memStore。\n增删改操作\nHBase新增单元格，在HDFS上增加一条数据\nHBase修改单元格，在HDFS上增加一条数据，但版本号比之前的大\nHBase删除单元格，在HDFS上增加一条数据，但是这条数据没有value，类型为Delete，即墓碑标记(Tombstone)，在执行HFile的合并时，会真正删除这些记录。\n\n读写流程参考文章：HBase读写流程Zookeeper(ROOT)-&gt;RegionServer(META)-&gt;Region-&gt;memStoore\n\n客户端访问，zookeeper的/hbase/meta-region-server节点查询到哪台RegionServer上有hbase：meta表\n\n客户端连接含有hbase: meta表的regionserver。Hbase: meta表存储了所有的Regin的行键范围信息，通过这个表可以查询到请求行键所在的Region，以及这个Region所在的RegionServer\n\n客户端在对应的RegionServer上，先从MemStore，再到HFile中找需要的信息。\n\n第一次访问后，客户端会把meta信息缓存起来(BlockCache) ，下次操作直接从BlockCache中查找meta信息。\n\n客户端访问，zookeeper的/hbase/meta-region-server节点查询到哪台RegionServer上有hbase：meta表\n\n客户端连接含有hbase: meta表的regionserver。Hbase: meta表存储了所有的Regin的行键范围信息，通过这个表可以查询到请求行键所在的Region，以及这个Region所在的RegionServer\n\n客户端在对应的RegionServer上，把数据分别写到Hlog和memstore各一份\n\n当memstore达到阈值后把数据刷成一个HFIle文件，当compact后，逐渐形成越来越大的HFIle后触发spilt，把当前的HFIle分成两个，这里相当于把一个大的region分割成两个region\n\n若MemStore中的数据有丢失，则可以从HLog上恢复，当多个HFIle文件达到一定的大小后，会触发Compact合并操作，合并为一个HFIle，这里同时进行版本的合并和数据删除\n\n\nRowkey设计\n三原则：长度原则（越短越好），散列原则（数据均衡分布），唯一原则\n加盐salting，在rowkey前分配随机数；随机前缀可以让他们分不到不同的Region中。\n预分区，解决Region自动拆分带来的热点问题和拆分合并问题（也可预留拓展）；比如生成0-499的随机数，规定0-50，50-100…等Region的范围。\n散列，解决如同一用户同一天数据集中存放的需求；将某一参数(如uid，date)传入哈希，结果模500，余数加到首部，可再结合预分区，就能在满足需求的同时让数据均匀分布到Regionserver中。\n反转，牺牲rowkey的有序性换随机性；解决开头固定结尾变化的热点问题，如手机号；用于时间(Long.MAX_VALUE - timestamp)可满足最近记录优先的需求。\n\n第五章 大数据索引结构\n\n\n\n\n\n\n\n\n三种基本的数据存储引擎分别是哈希（高效随机查找）、B树（高效范围查找）、LSM树(Log-Structured Merge Tree)。HBase的一个列族就是一颗LSM树，内存部分是跳表，外村选择了布隆过滤器来快速判别。\n跳表跳跃表(Skip List)是一种能高效实现插入、删除、查找的内存数据结构，这些操作的复杂度都是。应对场景：快速写入，需要更新代价低，支持区间查询；与B+树的不同就在于更新代价低，因而适用于大数据场景。跳跃表的构建：•1、给定一个有序的链表。•2、选择链表中最大和最小的元素，然后从其他元素中按照一定算法(随机) 随即选出一些元素，将这些元素组成有序链表。这个新的链表称为一层，原链表称为其下一层。•3、为刚选出的每个元素添加一个指针域，这个指针指向下一层中值同自己相等的元素。Top指针指向该层首元素•4、重复2、3步，直到不再能选择出除最大最小元素以外的元素。跳跃表的插入流程：插入跳表时，新入节点要以一定概率在上层生成索引。找到待插入元素的前驱节点-&gt;插入-&gt;随机生成高度值-&gt;按高度值修改索引\nLSM树为什么说LSM树是一种写入友好的数据结构？LSM树对写入更友好，写入操作都是顺序写，利用了HDFS的优点。\n\n顺序写入：LSM树的写入操作是以顺序写的方式进行的。这是因为新数据被追加到磁盘上的顺序日志（SSTables）中，而不是直接写入到原始数据文件中。相比于传统的随机写入操作，顺序写入的开销更小，能够极大地提高写入性能。\n\n延迟合并：LSM树的合并操作通常是延迟执行的，也就是说，多个SSTables之间的合并并不是在每次写入操作之后立即执行的。这样可以避免在写入过程中频繁地进行合并操作，从而减少了写入的延迟和开销。\n\n内存缓存：LSM树通常会在内存中维护一个数据缓存区，用于存储最近写入的数据。即使在刷写flush到硬盘，内存中也会开辟新的memstore来为新的写入服务。这样可以避免每次写入都要访问磁盘，提高了写入性能。同时，内存缓存中的数据也可以通过定期刷新到磁盘上的SSTables中，以保证数据的持久性。应对场景：高吞吐量（顺序）写入，随机查找，可拓展性(LSM树允许数据分区）。compaction：将key值相同的数据全局综合圈起来，选择合适的版本交给用户。主要有两种类型：major compact：不宜频繁使用优点：合并之后只有一个文件，读取性能最高缺点：合并所有的文件需要很长的时间，消耗大量带宽。minor compact：优点：局部的compact操作，少了IO，减少文件个数，提升读取性能。缺点：全局操作，无法在合并过程中完成。\n\n\n布隆过滤器解决问题的类型：有效排除一些肯定不在数据库中的数据；实现原理：通过一个数组和多个哈希函数实现，对与每一个数据，做k次哈希，每次哈希结果对应数组位置置为1；如果查询一个数据，发现所有哈希结果指示的位置都为1，则该数据可能在数据库中，否则一定不在数据库中。\n为什么说HBase是一种“顺序写入，随机查找”的分布式数据库？随机查找：尽管HBase采用了LSM树的索引结构，但HBase的查询操作并不是基于LSM树进行的，而是基于HBase表中的行键（row key）进行的。Region组织的元信息。\n第六章 一致性分布式事务事务是数据库中的一段操作序列，要么全做，要么不做；由三部分组成：开始标识，操作，结束标识（commit or abort）；按照组成结构可以分为平面事务（事务自治、独立）与嵌套事务（一个事务的执行包括另一个事务，内子外父）；\n嵌套事务的特点\n提交依赖性：子事务的提交必须等待父事务的提交；\n废弃依赖性：父事务废弃，子事务必须废弃；\n\n分布式事务的一致性这个问题是由于分布式数据库中存在数据复制造成的(也带来了可靠可用性）；三种级别：\n\n强一致性：更新过即刻访问\n最终一致性：一段时间后可访问\n弱一致性：不可访问（网购评论、广告）\n\nCAP一个分布式系统不可能同时满足一致性、可用性与分区容错性，最多俩；\n\n一致性是数据在多个副本之间保持一致的特性；\n可用性是提供的服务一直处于可用的状态——在有限时间内返回结果；\n分区容错性，在遇到网络分区时，仍然保证可用性和一致性的服务；例如，同时写北京和广州的DB都成功才返回成功且网络故障时提供降级服务（不可访问），满足CP。\n\nBASEBascially Available, Soft State, Eventually consistent; 是对CAP中可用性和一致性权衡的结果；出现故障时允许损失部分可用性；软状态指允许数据存在不一致的中间状态，认为不影响可用性；所有数据副本在经过一段时间后，最终都能达到一致的状态；总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统的事物ACID特性是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。\nHBase的ACID特性(了解)原子性：只保证WAL的原子性；一致性：强一致性；\n2PC（重点）分布式数据库中的全局事务由被分解为在各个场地上执行的子事务所组成。只有当各个场地上的子事务都正确执行后，全局事务才可以提交。只要有一个子事务不能提交，则全局事务应该废弃，接下来所有的子事务也应全部废弃。因此，所有子事务均可以正确提交是分布式事务提交的前提。执行流程决定阶段：有协调者发送预提交(prepare) 命令，然后等待参与者的应答。如果所有的参与者都返回“准备提交(ready) ”。那么协调者做出提交决定；如果至少有一个参与者返回“准备废弃”，那么协调者做出废弃决定。执行阶段：协调者把在决定阶段做出的决定发送给参与者。如果协调者向各个参与者发“提交”(Commit) 命令，各个参与者执行提交；如果协调者向各个参与者发出“废弃”(Abort) 命令，各个参与者执行废弃，取消对数据库的修改。无论是“提交”还是“废弃”，各参与者执行完毕后都要向协调者返回“确认”(Ack) 应答，通知协调者执行结束。存在的问题同步阻塞,单点问题,数据不一致,过于保守协调者故障，参与者占着资源却不能执行事务，进入阻塞状态；可用三段提交协议避免，若已经阻塞，则使用终结协议恢复。步骤1：选择参与者PT作为新的协调者。步骤2： PT向所有参与者发送“访问状态”命令，各参与者返回自身的状态。步骤3： PT 根据各参与者当前的状态做出决定：\n\n若部分参与者处于“初始”状态，部分参与者处于“准备就绪” 状态，则PT 发送abort命令；\n若所有参与者均处于“准备就绪”状态，则PT 发送Commit命令；\n若至少一个参与者处于 “提交”状态，则PT发送Commit命令；\n若至少一个参与者处于“废弃”状态，则PT发送abort命令；\n\nPaxosPrepare-&gt;Accept-&gt;LearnProposer,Accepter,Learner\n第七章 并发控制目的并发控制的主要目的是保证事务的隔离性，最终保证数据的一致性；解决并发带来的丢失修改、不可重复读、读脏数据的问题；并发控制就是利用正确的方式调度并发操作序列，避免数据不一致；保证一个事务的执行不受其他事务的干扰，保证事务并发执行的可串行性。 \n可串行化如果一个事务最后一个操作在另一个事务之前，或反之，则是串行调度。等价判别：冲突操作顺序一致\n可串行化：等价于串行调度分布式事务的可串行化：n个事务在m个场地上的并发序列记为E;当每个场地的局部调度是可串行化的 并且 在总序中如果有，在每一个局部调度中也必须有这样的关系。\ntxt设数据项a，b存放在S1场地，x，y存放在S2场地。有分布式事务T1和T2，判断下面的每个执行是否是局部可串行的，是否是全局可串行的，分别说明理由。\n1、执行1：在S 1场地R 1(a) R 2(a) W 2(b) W 1(a) ，\n        在S 2场地R 1(x) W 1(x) R 2(y) W 2(x) ，\n2、执行2：在S 1场地R 1(a) R 2(a) W 1(a) W 2(b) \n        在S 2场地W 2(x) R 1(x) R 2(y) W 1(x) 。分布式并发控制分布式数据库并发控制是指在分布式数据库系统中，为了保证数据的一致性和完整性，同时满足用户并发访问的需求，采用一定的技术手段对并发访问进行控制的过程。它主要解决的问题包括以下几个方面：\n\n数据一致性问题：在分布式环境下，由于数据可能分散在多个节点上，因此必须采取措施保证多个节点之间数据的一致性，避免数据冲突和不一致的问题。\n\n并发控制问题：多个用户可能同时对同一份数据进行读写操作，因此需要采取并发控制策略，保证数据的正确性和完整性，同时最大化地发挥系统的并发处理能力。\n\n\n三种典型的分布式锁数据库(MySQL)方式：用一张表做锁，加锁是往里面用资源ID做主键插入记录，解锁则删除；Redis分布式锁：setnx，setnx是set if not exists的缩写；若key不存在，则将key的值设置为value；当key存在时，不做任何操作。解锁del key；Zookeeper分布式锁：创建一个目录用于锁管理，加锁在该目录下创建临时顺序节点，如果顺序号最小则获得锁，否则监听目录等待；解锁则删除节点；\n对比：\n\n从理解的难易程度角度（从低到高）数据库 &gt; 缓存 &gt;Zookeeper\n从性能角度（从高到低）缓存 &gt; Zookeeper &gt;= 数据库\n从可靠性角度（从高到低）Zookeeper &gt; 缓存 &gt; 数据库\n\n","slug":"大数据存储复习笔记","date":"2023-02-19T10:00:00.000Z","categories_index":"大数据","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"4b679f8318026349163fd3a282ea69e7","title":"数据挖掘复习课","content":"第1章 认识数据挖掘1、数据挖掘的定义2、有指导学习和无指导学习3、数据挖掘的过程\n第2章 基本数据挖掘技术1、决策树概念和C 4.5算法的一般过程2、决策树关键技术：最大增益率3、决策树规则：决策树，产生式规则，正确率和覆盖率4、Apriori算法的基本思想5、关联规则及其置信度和支持度6、K-means算法的基本思想7、K-means聚类分析实例\n第3章 数据库中的知识发现1、KDD的定义(了解)2、数据预处理：直方图归约、数据规范化和数据平滑\n第5章 评估技术1、评估分类类型输出模型：混淆矩阵和分类正确率、查准率和查全率2、评估数值型输出模型：平均绝对误差，均方误差，均方根误差\n第6章 神经网络1、人工神经元模型(会画会计算)2、BP神经网络结构（会画，比如一个输入一个输出两个包含三个神经元隐层），前向计算过程3、BP算法的一般过程4、卷积神经网络的基本操作——卷积和池化，卷积特征（局部感受野、权值共享）\n第7章 统计技术1、一元线性回归、多元线性回归——最小二乘法2、贝叶斯分析：贝叶斯分类器3、凝聚聚类算法的一般步骤、例题4、Cobweb分层聚类算法：CU值的计算\n","slug":"数据挖掘复习课","date":"2023-02-15T13:38:55.000Z","categories_index":"机器学习","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"ae3ff290d2666f99246dfbc36b578f64","title":"大数据存储复习课","content":"复习课考试题型\n论述题（30分）    -论述自己对概念的理解\n分布式数据库设计及查询优化（20） -分布式数据库的设计，分片的设计、定义、对应的查询优化\n分布式存取优化（30） -物理上的特征指标、传输代价的计算\n存储结构设计 （10） -HBase设计、布隆过滤器设计（PPT）\n分布式事务 （10） -一致性、并发控制三次作业分别对应了2、3、4项\n\n章节回顾第一章• 大数据的由来（为什么会产生大数据存储系统？横向拓展需求、系统可靠可用、一致性需求在传统的关系模型下无法有效解决）• 大数据的特点• 大数据需要怎样的存储系统\n第二章• 客户&#x2F;服务器的体系结构（不同体系结构中AP功能的变化）• share nothing 架构、分库分表架构、存算分离架构与客户&#x2F;服务器架构之间的关系（开放性问题，结合PPT与自己的理解）参考文章• 关系型分布式数据库系统的模式结构• 分布式数据库系统的数据透明性（三种、定义，举例；给操作语句判定是那种透明性）• 多数据库系统和分布式数据库系统的区别与联系\n第三章• 分布式数据库设计的分片原则、定义（运算）、表示方法• 分布式数据库的查询优化策略及片段查询优化方法• 分布式查询的存取优化方法、特征参数的计算（选择运算、投影运算、自然连接运算、半连接运算）\n第四章• HBase解决了HDFS的哪些问题？具有哪些特点？• HBase数据库中region的含义及其特性。同一个表不同行的数据可以存放在不同的服务器，同一个表相同行的数据也可以存放在不同的服务器。这句话如何理解？\n\n\n\n\n\n\n\n\n\n一个服务器是Region的存储机构，但存储一个Region不代表存储一个表；每个Region都包含若干个Store，一个Store就是一个列族，是把列族作为对象存储的，不一定是一个表的，可能是不同表的分片。\n• HBase增删改查的真正操作内容是什么？• HBase的读写流程\n\n\n\n\n\n\n\n\n\nHDFS 的优势： （大文件存储、多副本、自动分块）\n\n如果仅用HDFS进行数据管理，存在一些问题：\nHDFS不支持对数据的随机改写\nHDFS没有数据表的概念\nHDFS无法针对行数统计、过滤扫描等常见数据查询\n功能实现快捷操作，一般需要通过Mapreduce实现。\n\n\n\n\n\n\n\n\nHBase底层采用HDFS存储，但是文件结构和元数据等自身维护。具体来说具有以下特点：\n\n采用面向列加键值对的存储模式\n可实现便捷的横向扩展\n可以实现自动的数据分片\n实现较为严格的读写一致性和自动故障转移\n实现对全文的检索与过滤（过滤器）\n\n第五章\n\n\n\n\n\n\n\n\n每种数据结构主要解决什么样的问题（场景）？实现原理？例如跳表主要支持快速写入，支持区间查询，更新代价低。B+树虽然也支持，但更新代价高，不支持大数据场景。LSM树跳表（内存）和多路文件归并、布隆过滤器（外存）的结合。\n（1）跳跃表• 解决的问题类型（快速写入、更新代价低、支持区间查询)• 查找和插入的流程（实现原理）跳表是LSM树的内存结构；（2）LSM树• 解决的问题类型 （“顺序写入，随机查找”）• 什么是compaction？分为哪两种类型？优缺点。• 为什么说LSM树是一种写入友好的数据结构？\n（3）布隆过滤器• 解决的问题类型（有效排除一些对象）• 构造方法和查询过程（实现原理）\n（4）为什么说HBase是一种“顺序写入，随机查找”的分布式数据库？\n第六章（1）嵌套事务的概念（2）分布式数据库的一致性级别的内容，并可举例说明（3）分布式数据库的CAP理论和BASE理论（会举例说明）（4）分布式事务提交协议（两阶段提交协议执行流程，存在的问题-阻塞，解决的方法-终结协议）（5）HBase的一致性ACID特性的实现方法（了解）（6）分布式一致性算法Paxos（主要流程）\n第七章• 并发控制的基本概念（解决的问题、可串行化调度）• 分布式并发控制解决的问题（三种分布式锁的应用场景、方案思路）• 分布式事务可串行化判定（题目）• 三种分布式锁的应用场景及具体解决方案\n","slug":"大数据存储复习课","date":"2023-02-13T01:18:20.000Z","categories_index":"大数据","tags_index":"学习笔记,大数据存储","author_index":"以太工坊"},{"id":"0485b8f7691dafa496f29ff47600c4f0","title":"Docker导出镜像","content":"\n\n\n\n\n\n\n\n\n主要介绍使用docker export快速导出单个容器镜像。\n都说docker有”一次运行，处处使用”的优点，是实现Dev-ops的有力工具，那么本文相关内容就是其中一环。\n利用export与import先在某个容器里做一些修改，在根目录写入一个文本文件：\nbashroot@minedl:~# docker run -it ubuntu:latest\nroot@ba2179ff43aa:/# ls\nbin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@ba2179ff43aa:/# echo 1111 &gt;&gt; 1.txt\nroot@ba2179ff43aa:/# cat 1.txt\n1111使用docker export导出容器的镜像：\nbashroot@minedl:~# docker export ba2179ff43aa &gt; me.tar\nroot@minedl:~# ls\nme.tar  snap使用docker import导入镜像，可以看到导入了名称为me的镜像：\nbashroot@minedl:~# docker import - me &lt;  me.tar\nsha256:8f5e159f2e21451ff2341526572bc3c67e9240454df0341a2ce447586b9e29a1\nroot@minedl:~# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nme            latest    8f5e159f2e21   4 seconds ago   77.8MB\nmydoc         latest    40dd787fd6e9   9 minutes ago   77.8MB使用导入的me镜像创建容器，查看之前在另一个容器做的修改是否保留：\nbashroot@minedl:~# docker run -it me /bin/bash\nroot@3f21d7037f50:/# ls\n1.txt  bin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@3f21d7037f50:/# cat 1.txt\n1111看到这已经不是之前那个容器，但是修改是保留了的。\n针对单个容器可以使用这种方式快速导入导出，但如果是docker compose创建的容器群，就需要使用load和save了，load和import这两组命令除了使用场景不同，最关键的是export没有保存容器历史版本，可以看作一个时间点的快照。更详细的内容可以参考这篇文章。\n除了使用文件转移容器，还可以使用docker hub与docker file等方式。\n","slug":"Docker导出镜像","date":"2023-01-29T06:54:49.000Z","categories_index":"大数据","tags_index":"技术贴士,Docker","author_index":"以太工坊"},{"id":"d664b9e10cb55e3238e26b1294b7b2ee","title":"MySQL的监听地址","content":"\n\n\n\n\n\n\n\n\n在某云的ECS上搭建了MySQL服务端，防火墙安全组一切正常，却无法远程访问。\n本机扫描服务器端口：\nshell ⚡yangz ❯❯ nmap -sS MD\nStarting Nmap 7.93 ( https://nmap.org ) at 2023-01-26 19:23 中国标准时间\nNmap scan report for MD \nHost is up (0.045s latency).\nNot shown: 996 filtered tcp ports (no-response)\nPORT     STATE  SERVICE\n22/tcp   open   ssh\n80/tcp   open   http\n443/tcp  closed https\n3306/tcp closed   mysql果然，端口是通的，没人监听而已。检查ECS端口使用情况：\nshellroot@minedl:~# netstat -lntp\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      24735/mysqld mysql绑定到了本地回环测试的地址上，所以无法对外提供服务。做如下配置：\nshellvim /etc/mysql/mysql.conf.d/mysqld.cnf修改其中的bind-address &#x3D; 0.0.0.0 ，注意不可以直接注释掉，否则会导致如下第二种结果。\nshelltcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      24735/mysqld #只监听localhost\ntcp6       0      0 :::3306                 :::*                    LISTEN      24794/mysqld #只监听ipv6，不监听ipv4\ntcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN      24877/mysqld #监听所有ipv4出现结果三，本机访问也成功访问。\n","slug":"MySQL的监听地址","date":"2023-01-26T11:43:43.000Z","categories_index":"数据库","tags_index":"MySQL","author_index":"以太工坊"},{"id":"add90185e378e36c94b8bd3e088f97e0","title":"模型的评估","content":"\n  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\n  \n    \n      \n      \n        这里绝对没什么东西哦。\n      \n    \n  \n\n","slug":"模型的评估","date":"2023-01-19T13:01:49.000Z","categories_index":"机器学习","tags_index":"学习笔记,加密","author_index":"以太工坊"},{"id":"ae72f4d2dd275bb9509251bbb9c54603","title":"HSV调试工具","content":"\n\n\n\n\n\n\n\n\nOpencv经常会读取hsv颜色空间的图片，在图片上使用颜色提取器往往不能得到准确结果；如果图像中有多个颜色的不同目标，颜色提取工作也是很麻烦的。\n此工具可以导入一张图片，通过6个进度条的拖动操作来实现HSV三个值的上下限设定，并将结果实时显示到mask和result层，从而缓解上述问题。\n\n仅需拖动进度条，即可快速定位多个目标的HSV范围，甚至可以精确到某一个值。代码如下：\npythonimport cv2  \nimport numpy as np  \n\npath = r&#39;D:\\PlayGround\\CVP\\return.png&#39;  #图像的位置，使用时仅需修改这一属性\n# 滑动条的回调函数，获取滑动条位置处的值  \ndef empty(a):  \n    h_min = cv2.getTrackbarPos(&quot;Hue Min&quot;, &quot;TrackBars&quot;)  \n    h_max = cv2.getTrackbarPos(&quot;Hue Max&quot;, &quot;TrackBars&quot;)  \n    s_min = cv2.getTrackbarPos(&quot;Sat Min&quot;, &quot;TrackBars&quot;)  \n    s_max = cv2.getTrackbarPos(&quot;Sat Max&quot;, &quot;TrackBars&quot;)  \n    v_min = cv2.getTrackbarPos(&quot;Val Min&quot;, &quot;TrackBars&quot;)  \n    v_max = cv2.getTrackbarPos(&quot;Val Max&quot;, &quot;TrackBars&quot;)  \n    print(h_min, h_max, s_min, s_max, v_min, v_max)  \n    return h_min, h_max, s_min, s_max, v_min, v_max  \n    \n# 创建一个窗口，放置6个滑动条  \ncv2.namedWindow(&quot;TrackBars&quot;)  \ncv2.resizeWindow(&quot;TrackBars&quot;, 640, 240)  \ncv2.createTrackbar(&quot;Hue Min&quot;, &quot;TrackBars&quot;, 0, 179, empty)  \ncv2.createTrackbar(&quot;Hue Max&quot;, &quot;TrackBars&quot;, 19, 179, empty)  \ncv2.createTrackbar(&quot;Sat Min&quot;, &quot;TrackBars&quot;, 110, 255, empty)  \ncv2.createTrackbar(&quot;Sat Max&quot;, &quot;TrackBars&quot;, 240, 255, empty)  \ncv2.createTrackbar(&quot;Val Min&quot;, &quot;TrackBars&quot;, 153, 255, empty)  \ncv2.createTrackbar(&quot;Val Max&quot;, &quot;TrackBars&quot;, 255, 255, empty)  \n  \nwhile True:  \n    img = cv2.imread(path)  \n    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  \n    # 调用回调函数，获取滑动条的值  \n    h_min, h_max, s_min, s_max, v_min, v_max = empty(0)  \n    lower = np.array([h_min, s_min, v_min])  \n    upper = np.array([h_max, s_max, v_max])  \n    # 获得指定颜色范围内的掩码  \n    mask = cv2.inRange(imgHSV, lower, upper)  \n    # 对原图图像进行按位与的操作，掩码区域保留  \n    imgResult = cv2.bitwise_and(img, img, mask=mask)  \n    cv2.imshow(&quot;Mask&quot;, mask)  \n    cv2.imshow(&quot;Result&quot;, imgResult)  \n    cv2.waitKey(1)[[|代码工具]]\n","slug":"HSV调试工具","date":"2023-01-17T13:57:48.000Z","categories_index":"OpenCV","tags_index":"代码工具","author_index":"以太工坊"},{"id":"5c593acf87382cf1567db5936b71aafe","title":"Latex公式语法","content":"\n\n\n\n\n\n\n\n\n用来练习Latex语法，同时测试katex引擎的渲染结果\n希腊字母与分行公式\nbye.\n矩阵在matrix加前缀b v p m，对应方括号 竖线 圆括号；不加没括号结合圆点使用\n向量单字母vec，多字母overrightarrow,另有rightarrow是这玩意\n横过来的大括号个个英文字母\n上下划线与帽子先是两种标准写法，在编辑器内无法正常预览再是在编辑器内正常预览的两种写法，全都是over指令，一个是前缀，另一个是后缀\n根号\n分式语法比较特殊，先打\\frac{x}{y}，指令标记在最前面\n角标\n乘法\n不等号标准写法简写，不确定是否能渲染\n连乘\\prod \\sim \\mathbb x \\prime  \n","slug":"Latex公式语法","date":"2023-01-14T13:13:52.000Z","categories_index":"","tags_index":"学习笔记","author_index":"以太工坊"},{"id":"3136cbf4b69b5e1b628e2f41c689c5a1","title":"Obsidian+Hexo+Github全自动部署博客","content":"参考文章文章一：知乎\n","slug":"Obsidian+Hexo+Github全自动部署博客","date":"2023-01-11T14:09:32.000Z","categories_index":"技术贴士","tags_index":"博客","author_index":"以太工坊"},{"id":"5effef9964d08a5f1e7458f8f066fb6c","title":"HDFS无法访问问题","content":"问题描述三个datanode、一个namenode和一个secondary namenode组成的hadoop集群，输入命令查看状态如下，一切正常。\nshell(base) root@node4:~# hdfs dfsadmin -report\nConfigured Capacity: 168292061184 (156.73 GB)\nPresent Capacity: 128058142720 (119.26 GB)\nDFS Remaining: 128058011648 (119.26 GB)\nDFS Used: 131072 (128 KB)\nDFS Used%: 0.00%\nReplicated Blocks:\n    Under replicated blocks: 0\n    Blocks with corrupt replicas: 0\n    Missing blocks: 0\n    Missing blocks (with replication factor 1): 0\n    Low redundancy blocks with highest priority to recover: 0\n    Pending deletion blocks: 0\nErasure Coded Block Groups: \n    Low redundancy block groups: 0\n    Block groups with corrupt internal blocks: 0\n    Missing block groups: 0\n    Low redundancy blocks with highest priority to recover: 0\n    Pending deletion blocks: 0\n\n-------------------------------------------------\nLive datanodes (3):是的，看起来没什么问题。但是HDFS的web页面50070无法访问，HDFS文件端口9000也无法访问使用，排除防火墙和安全组等问题后，检查所有的服务端口：\nshell(base) root@node4:~# netstat -lntp\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      516/systemd-resolve \ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1460/sshd: /usr/sbi \ntcp        0      0 192.168.0.165:8088      0.0.0.0:*               LISTEN      111907/java         \ntcp        0      0 127.0.0.1:6010          0.0.0.0:*               LISTEN      107217/sshd: root@p \ntcp        0      0 127.0.0.1:6011          0.0.0.0:*               LISTEN      110809/sshd: root@p \ntcp        0      0 127.0.0.1:6013          0.0.0.0:*               LISTEN      105767/sshd: root@p \ntcp        0      0 192.168.0.165:8030      0.0.0.0:*               LISTEN      111907/java         \ntcp        0      0 192.168.0.165:8031      0.0.0.0:*               LISTEN      111907/java         \ntcp        0      0 192.168.0.165:8032      0.0.0.0:*               LISTEN      111907/java         \ntcp        0      0 192.168.0.165:8033      0.0.0.0:*               LISTEN      111907/java         \ntcp        0      0 192.168.0.165:9000      0.0.0.0:*               LISTEN      111496/java         \ntcp        0      0 0.0.0.0:9870            0.0.0.0:*               LISTEN      111496/java         \n两个问题：\n\n50070端口不在列表里\n9000开到内网ip上去了\n\n问题1：\n经过仔细排查，发现时代变了，Hadoop 2.x HDFS WEB端口是50070， Hadoop 3.x 就变成了9870.\n问题2：\n配置文件中手动打开\nxml&lt;configuration&gt;\n        &lt;property&gt;\n                 &lt;name&gt;fs.defaultFS&lt;/name&gt;\n                 &lt;value&gt;hdfs://0.0.0.0:9000&lt;/value&gt;\n         &lt;/property&gt;\n         &lt;property&gt;\n                 &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n                 &lt;value&gt;file:/usr/hadoop/tmp&lt;/value&gt;\n                 &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;\n         &lt;/property&gt;\n&lt;/configuration&gt;\n","slug":"HDFS无法访问问题","date":"2022-12-19T08:00:00.000Z","categories_index":"大数据","tags_index":"Hadoop,HDFS","author_index":"以太工坊"},{"id":"42e97344b39e28a5e2b53d7a94abab91","title":"Flink重写watermark","content":"问题\n\n\n\n\n\n\n\n\n时间信息是形如”2022&#x2F;10&#x2F;22 10:34”的字符串，怎样针对这种时间信息，为Flink重写assignTimestampsAndWatermarks\n如果这个字符串已经被解析为一个Java时间对象，例如java.util.Date或java.time.Instant，那么可以在assignTimestampsAndWatermarks函数中将它作为参数传入。例如：\njavaCopy codeDataStream&lt;YourType&gt; stream = ...;\n\n// 假设eventTime是java.util.Date类型\nstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor&lt;YourType&gt;(Time.seconds(10)) &#123;\n    @Override\n    public long extractTimestamp(YourType element) &#123;\n        return element.getEventTime().getTime();\n    &#125;\n&#125;);如果字符串未被解析为Java时间对象，则需要先将其解析为一个时间对象，然后再在assignTimestampsAndWatermarks函数中使用它。可以使用SimpleDateFormat类来解析时间字符串：\njavaCopy codeDataStream&lt;YourType&gt; stream = ...;\n\n// 假设timeString是&quot;2022/10/22 10:34&quot;这样的字符串，并且它已经被解析为java.util.Date类型\nSimpleDateFormat format = new SimpleDateFormat(&quot;yyyy/MM/dd HH:mm&quot;);\nfinal Date eventTime = format.parse(timeString);\n\nstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor&lt;YourType&gt;(Time.seconds(10)) &#123;\n    @Override\n    public long extractTimestamp(YourType element) &#123;\n        return eventTime.getTime();\n    &#125;\n&#125;);需要注意的是，在实际的Flink程序中，需要确保这些代码在并行执行的情况下也能正常工作。例如，如果在一个MapFunction中使用了SimpleDateFormat类，那么这个类必须是线程安全的，否则会导致程序出错。\n","slug":"Flink重写Watermark","date":"2022-11-30T08:00:00.000Z","categories_index":"大数据","tags_index":"Flink","author_index":"以太工坊"},{"id":"aed368cc9508713312cce045a68b1789","title":"大数据架构课程复习","content":"导论大数据系统的需求包括（  ）。\n\n数据需求\n功能需求\n性能需求（高性能、高可用、高可扩展、高容错、安全性等）\n计算场景需求分布式系统&#x2F;集群 or 大数据处理的目标需求：高性能、高可用、容错性、可伸缩，其中高性能包含三个衡量指标：响应时间（延时）、吞吐量、资源使用率；高可用指标：MTTF、MTTR、可用性&#x3D;MTTF&#x2F;（MTTF+MTTR）\n\n大数据与云计算的关系（  ）。\n\n云计算可以为大数据处理提供充足的计算资源。\n\n大数据是云计算服务的典型应用。\n\n大数据可以不使用云计算。大数据计算的典型场景有（  ）\n\n批处理\n\n流计算\n\n交互式查询静态数据有界、持久存储，容量大，适合批处理。\n\n\n流数据无界、持续产生，需要数据窗口及时处理且看不到尽头。\n云计算概述云计算定义\n云计算是一种商业计算模型 。它将计算任务分布在大量计算机构成的资源池上，使各种应用系统能够根据需要获取计算力、存储空间和信息服务。\n通过网络按需提供可动态伸缩的廉价计算服务 ，是一种普遍适用的资源治理思维和模式。\n 云计算是将计算资源比作无处不在的云，是综合虚拟化、分布式计算、效用计算、负载均衡、并行计算、网络存储、热备份冗杂等技术发展演进的结果。\n\n云计算特征\n资源虚拟化和池化统一管理\n超大规模、高可用、高伸缩\n弹性、按需、自助提供服务\n泛在接入、准确计费、价格低廉\n\n三类服务模式1、基础设施即服务 IaaS（Infrastructure as a Service）\n提供服务器、存储和网络等计算资源服务\n主要功能：\n\n用户按需支付 IaaS ，无需购买整套硬件。\n可根据处理和存储需求扩展基础架构。\n节省企业购买和维护硬件的成本。\n数据位于云端，不会有单点故障。2、平台即服务 PaaS（Platform as a Service）\n\n提供开发、管理和交付的环境软件，如操作系统、数据库、中间件、开发平台。\n主要功能\n\n提供开发平台和工具，用于软件厂商快速开发、测试、部署运行。\n软件厂商专注于开发，无需担心底层基础架构。\n云厂商保证平台的安全性、可靠性和稳定性。3、软件即服务 SaaS（Software as a Service）\n\n通过网络提供云端软件服务。\n主要功能\n\n用户付费订阅软件，通过互联网直接访问应用软件，无需管理、安装或者升级软件。\n数据在云端受到保护，设备故障不丢失。\n可根据服务需求对资源用量进行扩展。\n\n四种服务形态公有云:由第三方云服务提供商拥有和运营，并通过 Internet 提供服务的IT基础设施。\n优势：成本低、无需维护、按需伸缩、高可靠高可用。\n缺点：安全性不可控、资源无法自由定制。\n私有云由专供一个企业或组织使用的云计算资源构成。\n优点：相比公有云，资源定制更灵活、安全性更高。\n缺点：建设和运维成本高。\n社区云由多个企业或组织\n混合云，通过安全连接将公有云和私有云环境组合起来，允许在不同云环境之间共享数据和应用程序。\n– 可控制性高，敏感资产私有云。\n– 可用灵活，按需使用公有云。\n– 成本效益高，具备公有云的伸缩性。\n云计算体系结构1、SOA构建层\n封装云计算能力为标准Web services服务，并纳入到SOA体系。\n2、管理中间件层\n云计算的资源管理，并对众多应用任务进行调度，使资源能够高效、安全地为应用服务\n云计算的核心技术云计算核心技术主要有虚拟化和容器化，其中容器化技术因为利用共享的操作系统内核，打包应用及其运行环境，比虚拟化更加轻量、快速、低开销，所以是近些年比较受开发人员追捧的技术。\n虚拟化技术虚拟化（Virtualization ）是将计算机资源抽象映射为虚拟的逻辑实体，突破物理资源的界限进行统一管理，构建云计算环境的核心基础技术。\n◼ 服务器虚拟化：将一台计算机虚拟为多台逻辑计算机\n◼ 存储虚拟化：将底层存储设备抽象化和统一池化管理，独立对外提供存储服务\n◼ 网络虚拟化：对将一张物理网卡虚拟成多张虚拟网卡，通过虚拟机来隔离不同应用\n◼ 桌面虚拟化：将用户桌面环境与其使用的终端设备解耦，在服务商存放每个人的完整桌面环境，用户使用终端设备通过网络访问自己的桌面\n1、服务器虚拟化虚拟机（Virtual Machine） VM\n将一台计算机（物理机、物理服务器）虚拟为多台逻辑计算机\n每台虚拟机拥有独立的“硬件”。\n虚拟机“硬件”是使用物理机的硬件模拟而来的。\n虚拟机执行的工作，实际是由物理机硬件完成的。\n虚拟机监视器（ Virtual Machine Monitor ）VMM\nVMM是实现物理机虚拟为虚拟机的操作系统或者软件。主要功能是为虚拟机提供虚拟的硬件资源，负责管理和分配这些资源，并确保虚拟机之间的相互隔离。\nVMM两种工作模式\n1 Hosted 模式（寄居模式、托管模式）： VMM 运行在物理机的操作系统上，安装使用简易方便，性能较低。\n寄居虚拟化的虚拟化层一般称为虚拟机监控器（ VMM ）。VMM 通过调用 host OS 获得资源，实现 CPU 、内存和 I&#x2F;O 设备的虚拟化。 VMM 创建的虚拟机作为 host OS 的一个进程参与调度。寄居模式下 VMM 可以充分利用 host OS 功能来操作硬件设备；但是经过中间环节导致系统损较大。\n2 Hypervisor 模式（裸金属模式）： VMM 直接运行在物理机的硬件上，提供接近于物理机的性能。\n架构中的 VMM 是一个操作系统，一般称为Hypervisor 。Hypervisor &#x3D; OS + 虚拟化——具备传统操作系统功能，具备虚拟化功能，包括虚拟资源到物理资源的映射，虚拟机系统的隔离。提供接近于物理机的性能，但是支持的 I&#x2F;O 设备有限。\n服务器虚拟化技术分类\n根据对临界指令处理方式的不同\n完全虚拟化（Full Virtualization）\n半虚拟化（Para Virtualization）\n硬件辅助虚拟化（Hardware Assisted Virtualization）\n完全虚拟化\n\nVMM 为 Guest OS 模拟了完整的底层硬件，包括处理器、物理内存、时钟、外设等，客户机操作系统完全不知道自己运行在虚拟机中。\n\n客户机操作系统及其系统软件不作任何修改就可以在虚拟机中运行。\n\n兼容性很好，安装使用简单。\n\n性能较低（因为VMM需要翻译二进制代码，替换敏感指令）。半虚拟化\n\n半虚拟化需修改Guest OS 的内核，把原来在物理机上执行的特权指令或者敏感指令，修改成 VMM 的超级调用。\n\nGuest OS知道自己运行在虚拟机环境中，不能直接调用内核的特权指令和敏感指令，它通过Host的内核直接对CPU进行调用\n\n性能提升，\n\n但实现困难。硬件辅助虚拟化\n\n\nCPU厂商改造 CPU ，引入新的指令和运行模式，帮助VMM 高效地识别和截获敏感指令， 从硬件层面支持虚拟化。通常， Guest OS 的核心指令可以直接下达计算机系统硬件执行，无需经过 VMM 。对于特殊指令，系统会切换到 VMM ，让VMM 来处理特殊指令。\n2、存储虚拟化将底层存储设备抽象化和统一池化管理，独立对外提供存储服务。可以实现：\n\n高可伸缩性，摆脱物理容量限制。\n\n隐藏设备复杂性，统一管理和服务。\n\n整合空间资源，提高设备利用率。\n\n高可靠、高可用。技术类型\n\n基于主机的虚拟化（支持异构设备，性价比高，但是占有主机资源影响性能，影响主机安全和稳定，可拓展性差）\n\n基于存储设备的虚拟化（主机性能不受影响，但不支持异构设备特定厂商）\n\n基于网络的虚拟化\n\n\n3、桌面虚拟化远程桌面服务RDS\n虚拟桌面基础架构VDI\n智能桌面虚拟化IDV\n4、网络虚拟化open stack核心服务：计算服务nova,存储服务swift，镜像服务glance\n虚拟化技术缺陷\n\n虚拟机操作系统运行资源消耗大、启动时间长\n中间环节(hypervisor)降低了系统的服务性能\n用户更关注自己部署的应用程序，却不得不部署运维操作系统和附带的依赖环境\n\n容器化技术容器化是在操作系统内核上的轻量级的虚拟化技术。利用共享的操作系统内核的功能，建立一系列资源相互隔离的封闭运行环境，这些封闭运行环境就像一个个容器（container ），应用程序就部署运行在其中。其优势是轻量、敏捷、易扩容、支持DevOps，提高资源利用率节约成本、加速产品迭代、支持微服务架构、实现运维自动化。\n\n容器共享同一套操作系统内核\n容器打包了应用及其运行环境\n一次构建、跨平台、处处运行\n容器轻量、快速启动、低开销容器实现原理\n\n1、namespace命名空间\n命名空间定义了一个封闭的作用域范围，约定：处于处于同一命名空间的进程，只能看到该名字空间下的资源，如主机名、网络、进程、用户、文件系统等。不同名字空间的进程彼此不可见，互不影响。容器是拥有单独名字空间的进程，运行在容器中的应用像是在独立操作系统中运行一样，容器之间互不影响。\n每个进程拥有七个命名空间用于隔离不同类型的资源\n2、Cgroups(控制群组）\nnamespace能把进程隔离到一个特定环境中，但是无法限制进程使用的物理资源。cgroups（Control Groups ），是 Linux 内核提供的物理资源隔离机制，可以实现对 Linux 进程或者进程组的资源进行限制、隔离和统计的功能。\n容器通过 cgroups 实现对容器所使用物理资源（ CPU 、memory 、 IO 等）的隔离、限制和记录。cgroups把每个容器都当成普通进程对待。通过设置进程组或某个进程的资源限制条件，实现将容器进程与其他进程在资源使用上隔离的目的。\n·         A. namespace 实现资源隔离。\n·         B. cgroups 实现资源控制。\n·         C.每个进程拥有7种命名空间，用于隔离不同类型的资源。\n·         D. cgroups 把每个容器都当成普通进程对待。通过设置进程组或某个进程的资源限制条件，实现将容器进程与其他进程在资源使用上隔离的目的。\n大数据处理概述大数据处理过程大数据处理是针对大数据的采集和预处理、存储和管理、处理和分析、可视化呈现等任务的总和。\n数据采集与预处理数据类型：结构化、半结构化、非结构化\n数据来源：业务数据、互联网数据、物联网数据\n采集方法：日志采集、网络爬虫、API、政府企业机构共享\n数据预处理包括：\n\n数据清洗删除重复值、缺失值处理、列名重命名\n\n数据集成将互相关联的分布式异构数据源逻辑或物理地集成为一体，为用户提供透明的访问服务，数据集成的方式有：\n\n\n数据整合（ETL+数据仓库，物理统一）\n数据联邦（建立统一的逻辑视图）\n数据传播（数据在多个应用间传播）\n混合方式\n\n数据变换将数据从一种表现形式转换为另一种表现形式：\n\n平滑、聚集、泛化、规范化、属性构造\n\n数据规约在保证数据分析质量的前提下，缩小数据规模:\n\n维度规约：小波变换、PCA（主成分分析）、特征选择\n数量规约：聚类、抽样、Logistic回归\n大数据数据处理与分析\n分布式计算模式和框架\n批处理：Hadoop、spark\n流处理： Storm、Flink\n图计算：Pregel、Graph X\n\n\n大数据分析\n交互式查询：Hive、Pig、Spark Sql\n数据挖掘：Mahout\n机器学习：Mllib\n\n\n\n大数据存储与管理大数据解释与可视化分布式计算原理分布式系统是网络中的一组计算机节点为了完成共同的任务而组成的协同工作系统，要求高可用、高性能、可伸缩、容错性；包括分布式存储和分布式计算。分片与副本是基本手段。\n\nHDFS如何存储文件\n把文件拆成固定大小的单元，单元分散存储到不同节点，访问时从各节点拿来合并。\nHDFS如何写入文件\nClient向Namenode申请写一个文件，Namenode做好准备，然后告诉Client准备好了。Client收到确认，循环执行如下步骤直至数据写完：（1）向Namenode申请一个Block，Namenode根据规则选出Data Node后告诉Client。（2）Client向指定的Datanode发送数据，Datanode接受数据写到本地。\n\nHDFS如何读取文件\nClient向Namenode申请读一个文件，Name Node做好准备后返回该文件对应的元数据。Client接收到文件的元数据信息后，去相应的Datanode请求相应的Block数据，最后拼接形成完整的文件内容。\n数据分布式存储的作用：\n一、数据冗余以提高可用性。\n二、读写分离以提高性能。\n分片按一定规则将数据集划分成相互独立正交的数据子集，分布到不同的节点。分片可以实现高性能、水平扩展、高可用。\n分片的要求：分布均匀、负载均衡、迁移数据少（扩缩容）\n基于数据范围数据按Key划分成不同的区间，每个节点负责一个或者多个区间。\n支持范围查询，平衡不容易保证。\n哈希方式在哈希值和系统节点之间建立映射关系，从而将哈希值不同的数据分布到不同的节点上。\n能解决不平衡问题，\n范围查询性能受到影响。\n扩缩容需要迁移很多数据\n一致性哈希\n将节点(server）按特征映射到一个首尾相接的hash环上。\n将数据按特征映射到同一个hash环上。\n将数据保存到环上顺时针第一个节点上。\n并且为每个物理节点设置虚拟节点，哈希映射到虚拟节点的数据实际上保存到与之对应的物理节点，虚拟机节点均匀分散到哈希环上，避免数据倾斜和节点雪崩。扩缩容迁移数据很少，\n\n可能会发生数据倾斜\n因为数据倾斜导致的节点雪崩\n副本建立冗余副本是实现容错、高可用的基本手段。\n建立副本的策略单主复制\n单主复制有且仅有一个Master副本，其他都是备用的Slave副本，维护Master副本的节点作为中心节点，负责维护数据更新、并发控制、协调副本的一致性。\n过程：Master副本宕机后，从Slave选举一个Master,已宕机的master恢复后降为 slave，向新master同步。slave 副本宕机，恢复后从 master 重新同步数据。\n存在的问题：\n（1）可用性问题：master 宕机后的failover操作、slave 竞选、服务切换到新 master 都需要时间，这段时间内系统阻塞，无法提供服务。\n（2）数据一致性问题：master 宕机，某个slave通过竞选成为新的 master，此时新旧 master 之间尚未同步数据，当旧 master 恢复成为一个新slave后，新slave就比新master多一些数据，数据不一致。\n（3）成本问题：slave 副本只用于失败转移，有些浪费。\n多主复制\n所有副本都是 master，副本之间互为主从。写操作可以由任意一个 master 处理，再同步到其它 master。\n多主复制，在并发操作时存在数据不一致性问题。\n无主复制\n不区分 master 和 slave 副本，客户端更新数据时，向多个副本发出写请求；客户端查询数据时，向多个副本发出读请求。\n客户端可以做一些数据补偿工作，但依然存在数据不一致问题。\n副本同步策略同步复制（synchronous replication）\n保证数据复制到所有副本之后，才算是复制完成。副本之间具有强一致性，性能不高。\n异步复制（asynchronous replication）\n只要数据复制到 master 副本，就算复制完成，其它副本异步处理。性能高，但可能丢失数据或者发生数据脏读。\n半同步复制（semi-synchronous replication）\n当数据复制达到一个约定数量的副本时，就算复制完成。兼顾性能和一致性。\n副本一致性模型CAP定理\n一个分布式系统不可能同时满足一致性、可用性和分区容错性，最多只能满足其中的两项。\n\n一致性(Consistentcy) ：所有数据副本的数据都是一致的。\n可用性(Availability) ：所有请求都能获取正确的响应。\n分区容错性(Partition tolerance) ：即使发生了网络分区，系统也能对外提供满足一致性和可用性的服务。\n\n网络分化是网络链路出现问题，将集群节点隔离成多个分区，分区之间网络不可达，分区内部正常。\n分布式系统必须保证分区容错性，否则失去了分布式的意义，所以需要在一致性和可用性之间权衡。\nACID\n\nAtomicity（原子性）：事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。\nConsistency（一致性）：在事务开始之前和事务结束以后，数据库从一个一致状态变成另一个一致状态，数据完整性不会被破坏。\nIsolation（隔离性）：多个并发事务同时执行，不会互相干扰而导致数据不一致。\nDurability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。BASE原理\n\nBASE 弱化了一致性，追求分区容错性和可用性与ACID代表了两类不同的设计哲学。\n\n基本可用(Basic Availability)要求系统能够基本运行，一直提供服务，在出现不可预知故障的时候，允许损失部分可用性，如响应延时或者服务降级。\n\n软状态(Soft State，柔性状态）允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许不同节点的副本之间存在暂时的不一致情况。\n\n最终一致性(Eventually Consistency)要求数据不能一直处于软状态，必须在一段时间后达到一致，保证所有副本中的数据一致性。\n\n\n一致性模型定义了分布式系统中数据复制时保持一致性的基本约束。\n\n强一致性任何时刻，任何用户或节点都可以读到最近一次成功更新的副本数据。一致性要求最高，实践中最难以实现。\n\n单调一致性任何时刻，任何用户一旦读到某个数据在某次更新后的值，该用户将不会再读到比这个值更旧的值。弱于强一致性。\n\n会话一致性任何用户，在某一次会话内一旦读到某个数据在某次更新后的值，该用户在该次会话过程中不会再读到比这个值更旧的值。弱于单调一致性，只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。\n\n最终一致性最终一致性要求一旦更新成功，各个副本上的数据最终将达到完全一致的状态，但达到完全一致状态所需要的时间不能保障。\n\n弱一致性一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。弱一致性系统一般很难在实际中使用，使用弱一致性系统需要应用程序做更多的工作以使系统可用。\n\n\n分布式系统的一致性协议‘\n其中Lease、2PC、PAXOS可以实现完全一致性\nLease机制中心节点保存和维护元数据，要求保证各节点缓存的元数据始终与中心节点上的元数据一致。\n使用场景：\n（1）客户端读取cache节点的元数据\n判断元数据是否已经处于cache节点且Lease处于有效期内。\n若是：则直接返回元数据。\n若否：则向中心节点请求读取数据。中心节点收到读取请求后，返回元数据一个对应的Lease。\n若cache节点接收失败或超时则读取失败，退出流程重试。\n若接收成功，则将中心节点返回的元数据及其Lease记录下来，并向客户端返回元数据。\n（2）客户端修改元数据\n客户端向中心节点发起修改元数据请求。\n中心节点收到请求后，阻塞所有新读数据请求，即只接收读请求，但不返回数据。\n中心节点等待所有与该数据相关的Lease超时，修改数据并向客户端返回修改成功的信息。\n法定人数假设总共N个副本，写操作至少要成功更新W个副本才认为更新成功，读操作至少要读R个副本才能读到更新后的数据。要求：\nW + R &gt; N\n可以根据业务调整W和R，从而在可靠性和性能方面进行权衡\n两阶段提交协议（2PC）保持分布式事务一致性的协议，属于同步复制协议，即所有副本数据都同步完成之后才返回客户端结果。\n2PC 把数据复制分为两个阶段\n表决阶段：主节点将数据发送给所有副本，每个副本都要表决是提交还是回滚，如果副本投提交票，那么它会将数据放到暂存区域，等待最终提交。\n提交阶段：主节点收到其他副本的响应，如果副本都投提交票，那么就发送确认提交给所有副本让它们提交更新，数据就会从暂存区域移到永久区域。只要有一个副本返回回滚就整体回滚。\n2PC 是典型的 CA 系统，为了保证一致性和可用性，一旦出现网络分区或者节点不可用就会拒绝写操作，把系统变成只读的。\n出现节点宕机，2PC会一直阻塞系统，所以在数据复制的场景中不常用，一般用于分布式事务。\nPaxos协议应用场景为多主复制保证一致性（状态机复制+共识算法）。\n三种角色\n\nProposer：提案者，提出提案（propose），可以有多个。\nAcceptor：表决者，对提案进行 accept 表决。\nLearner：同步者，对确定的提案进行同步。提案：数据更新请求，可以表示为：[提案编号n，提案内容value]\n\n步骤：\n\n每个提案者Proposer在提出提案时，都会首先获取到一个全局唯一性的、递增的提案编号 N，将该编号赋予他要提出的提案。\n每个表决者Accepter在 accept 某提案后，会将该提案的编号 N 记录在本地，其中最大的提案编号记作 MaxN。每个表决者仅会 accept 编号大于自己本地 MaxN 的提案。\n一次选举，在众多提案中最终必定且只能有一个提案被选定。\n一旦一个提案被选定，则其它节点会主动同步（learn）该提案到本地。\n没有提案被提出，则不会有提案被选定。prepare-promise, propose-accept or learn, learn\n\nBasic PaxOS的问题只能对一个值形成决议，决议的形成至少需要两次网络来回，在高并发情况下可能需要更多的网络来回，极端情况下甚至可能形成活锁（livelock,两个节点恶意竞争一个值）。\nMulti-Paxos基于Basic Paxos做了两点改进：\n\n针对每一个要确定的值，运行一次Paxos算法实例（Instance），形成决议。每一个Paxos实例使用唯一的Instance ID标识。\n在所有Proposers中选举一个Leader，由Leader唯一地提交Proposal给Acceptors进行表决。这样没有Proposer竞争，解决了活锁问题。在系统中仅有一个Leader进行Value提交的情况下，Prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。这样即使在网络分化的情况下有多个leader，multi-paxos也最多退化到basic-paxos\n\n参考文章时钟\n分布式系统中的三类事件，每一件都可以触发时钟增加\n\n节点内部事件\n发送事件\n接收事件分布式系统中建立逻辑时钟的两种方法\n\nLamport只能表示因果关系\n向量时钟vector clock可以表示因果和并发关系\n①Lamport时间戳是一种逻辑时钟表示法，是一个单调增加的整数。按照一定的规则为分布式系统中的每一个事件都打上一个Lamport时间戳，通过比较时间戳的数值大小，可以确定事件的偏序关系。\n规        则\n\n每个节点本地都有一个时间戳，初始值为0。\n若事件在节点内发生，本地时间戳加1。\n若是发送事件，本地时间戳加1并在消息中带上该时间戳。\n若是接收事件，本地时间戳 &#x3D; Max(本地时间戳，消息中的时间戳) + 1。事件先后：先按时间戳排序，相同则按照节点编号排序（特别注意 节点编号由题目给出！！！！！！！！！！！！)\n\n②向量时钟是在 Lamport 时间戳基础上演进的另一种逻辑时钟方法，它通过向量结构(Vector)记录本节点的 Lamport 时间戳和其他节点的 Lamport 时间戳，能够很好描述同时发生关系以及事件的因果关系。向量时钟算法利用了向量这种数据结构将全局各个进程的逻辑时间戳广播给各个进程：每个进程发送事件时都会将当前进程已知的所有进程时间写入到一个向量中，附带在消息中。\n事件先后：如果 Tb[Q] &gt; Ta[Q] 并且 Tb[P] &lt; Ta[P]，（即在Q节点上事件b先发生，在P节点上a先发生）则认为a、b同时发生，记作 a &lt;-&gt; b，这也是lamport时间戳无法表示的并发关系(concurrent)。\n大数据系统结构简述什么是大数据系统，在建立大数据系统的时候需要考虑权衡哪些需求）\n大数据系统：整合数据采集和预处理、存储和管理、处理和分析、可视化呈现等大数据处理功能的高性能、可伸缩、高可用、高容错、安全易用的软硬件系统；用于帮助用户发现大数据中潜在有价值的信息和知识，把握业务现实，预测业务走向。\n大数据系统的结构取决于大数据系统构建的需求和宏观决策，包括业务目标、数据源类型和特点、性能要求、批处理&#x2F;流式处理（计算框架）、技术选型等。\n传统BI架构数据源+ETL+数据仓库+分析报表\n\n围绕数据仓库的结构化分析，缺乏非结构化分析。\nETL数据预处理功能复杂、臃肿。\nACID特性，影响性能，无法应对大数据规模。\n\n批处理架构数据源+ETL+数据存储+批处理+分析报表\n\n优点：简单易用，技术选型时用大数据组件替换掉BI组件。\n缺点：①没有数据仓库对业务支撑的灵活性，对大量报表和复杂钻取场景，需要手工定制；②以批处理为主，缺乏实时支撑。\n适用场景：以BI场景为主，适于大规模历史数据的离线分析。\n\n流处理架构**数据源+实时数据通道+流式处理+**消息推送\n\n优点：没有臃肿的ETL过程，数据的实效性高。\n缺点：不存在批处理，对数据的重播和历史统计无法很好的支撑。对于离线分析仅仅支撑窗口之内的分析。\n适用场景：预警，监控，对数据有有效期要求的情况。\n\nLambda架构Lambda架构：批处理层 + 流处理层 +服务层。数据以追加的方式通过两条路径并行写到批和流处理系统。分别针对批和流式两条处理路径提供相应的数据计算逻辑。最终通过服务层整合计算结果视图，进行对外服务的输出。\n\n优点：实时+离线分析，对数据分析场景涵盖全面。\n缺点：需要维护批处理层和速度层两套系统：Hadoop &amp; Storm。同一个业务计算逻辑需要在两层分别实现和运维。查询结果合并比较复杂 &amp; 运维复杂。\n适用场景：同时存在实时和离线需求的情况。\n\nKappa架构简化Lambda架构，删除批处理系统，所有数据都走实时路径，一切数据都视为流。通过流处理系统全程处理实时数据和历史数据。数据作为事件按顺序引入到能容错的分布式统一日志中。事件流作为实时数据进入速度层做流式处理，产生实时视图。事件流同时在长期储存中保存。在必要的时候重播事件流，通过流计算引擎重新计算产生历史数据的视图。\n\n优点：解决了Lambda架构里冗余部分，以数据可重播的思想进行了设计，架构简洁。\n缺点：实施难度较高，尤其数据重播部分。\n应用场景：同时存在实时和离线需求情况。\n\nHadoopHadoop版本演变：\n2.0增加Yarn\n3.0 MapReduce基于内存计算、支持多NameNode、精简内核\nHadoop三大核心组件：HDFS、MapReduce、YARN\n作用：5731\n◼ HDFS是分布式存储框架，把文件分布式存储到多个计算机节点上，适合海量数据的存储。\n◼ MapReduce是分布式计算框架，将大规模集群上的并行计算过程抽象为两个函数：Map、Reduce，采用“分而治之”策略，存储在分布式文件系统中的大规模数据集会被切分成许多独立的分片 split，这些分片被多个 Map 任务并行处理。\n◼ Yarn作为资源调度平台，并且负责根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩。\nHDFSHDFS体系结构HDFS的体系结构采用主从（Master&#x2F;Slave）结构模型，一个HDFS集群通常包括：\n（1）一个名称节点（NameNode），名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。\n（2）多个数据节点（DataNode），每个数据节点运行一个datanode进程，负责处理客户端的读&#x2F;写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。数据节点的数据实际上保存在本地Linux文件系统中。\n\nHDFS存储原理为了保证系统的容错性和可用性，HDFS采用了多副本方式对数据进行冗余存储，通常一个数据块的多个副本会被分布到不同的数据节点上。客户端优先使用在同一机架的数据。优点：\n（1）加快数据传输速度\n（2）容易检查数据错误\n（3）保证数据可靠性\n副本存储策略：\n（1）第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点；\n（2）第二个副本：放置在与第一个副本不同的机架的节点上；\n（3）第三个副本：与第一个副本相同机架的其他节点上；\n（3）更多的副本：随机节点。\n数据读写过程写文件\nClient向Namenode申请写一个文件，namenode做好准备后，告诉Client。Client收到确认，循环执行如下步骤直至数据写完：\n1、向Namenode申请一个Block，Namenode根据规则选出DataNode后告诉Client。\n2、Client向指定的Datanode发送数据，Datanode接受数据后写到本地。\n读取文件\nClient向Name Node申请读一个文件，Namenode做好准备后返回该文件对应的元数据信息。Client 接收到文件元数据信息后，去相应的DataNode请求相应Block数据，最后拼接成完整的文件内容。\n数据错误与恢复1、名称节点出错\n名称节点保存了所有的元数据信息，如果出错则整个HDFS集群将失效。HDFS设置检查点机制，把这些元数据周期性复制到备份服务器SecondaryNameNode上。当名称节点出错时，就可以根据SecondaryNameNode进行NameNode元数据数据的恢复。\n2、数据节点出错\n\n每个数据节点会定期向名称节点发送心跳信息，报告自己的状态。\n当数据节点发生故障或网络异常，名称节点无法收到来自数据集节点的心跳信息，此时数据节点会被标记为宕机，节点上所有数据会被标记为不可读，名称节点不会再给它们发送任何I&#x2F;O请求。\n名称节点会定期检查数据块的副本数量，若小于冗余因子，就会启动数据冗余复制。3、数据出错\n\n网络传输和磁盘错误等因素，会造成数据错误。客户端在读取到数据后，会采用md5码和sha1对数据块进行校验，以确定读取到正确的数据。\nMap Reduce体系结构计算模型\n将大规模集群上的并行计算过程抽象为两个函数：Map、Reduce。\n编程容易，无需要掌握分布式并行编程的繁琐细节，即可把自己的程序运行在分布式系统上，实现海量数据的计算。\n采用“分而治之”策略，存储在分布式文件系统中的大规模数据集会被切分成许多独立的分片（split），这些分片被多个Map任务并行处理。\n设计理念是“计算向数据靠拢”，而不是“数据向计算靠拢”，因为移动数据需要大量的网络传输开销。\n采用了Master&#x2F;Slave架构，包括一个Master和若干个Slave（或Worker）。Master上运行JobTracker，负责作业的调度、处理和失败后的恢复，Slave上运行TaskTracker ，负责接收JobTracker发给它的作业指令。\n\n四个组成部分1、Client：\n\na用户编写MapReduce程序，通过Client提交到JobTracker端。\n\nb用户可通过Client提供的一些接口查看作业运行状态。2、Job Tracker：\n\na负责资源监控和作业调度，\n\nb 监控所有Task Tracker与Job的健康状态，一旦发现失败，就将相应的任务转移到其他节点。\n\nc JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler，可插拔，可自定义），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源。3、Task Tracker： \n\na Task Tracker周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）。\n\nb Task Tracker 使用”slot（槽）”等量划分本节点上的资源量（CPU、内存等）。一个Task 只有获取到 slot 后才有机会运行，而Hadoop任务调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。（slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task 使用。）4、Task：分为Map Task 和Reduce Task 两种，均由Task Tracker 启动。\n\n\n工作流程\n（1）程序部署；（2）分配Map任务和Reduce任务；（3）map节点读取数据执行map任务并溢写中 间结果；（4）reduce节点接收中间结果数据并执行reduce任务；（5）将执行结果写入HDFS。\nYarn体系结构Resource Manager处理客户端请求、监控NodeManager、启动和监控Application Master、资源调度与分配\n全局资源管理器，负责整个系统的资源管理和分配。包括两个组件：调度器（Scheduler）和应用程序管理器（Applications Manager）。\n（1）调度器，把集群资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”。调度器是一个可插拔组件，YARN不仅自身提供了许多种直接可用的调度器，也允许用户根据自己的需求重新设计调度器。\n（2）应用程序管理器，管理系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动等。\nApplication Master主要功能是：\n（1）当用户作业提交后，ApplicationMaster 会与 Resource Manager 协商获取资源，ResourceManager 会以容器的形式为 Application Master 分配资源；\n（2）ApplicationMaster 把获得的资源进一步分配给内部的各个任务（Map或Reduce任务），实现资源的“二次分配”；\n（3）与NodeManager保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）；\n（4）定时向ResourceManager发送“心跳”消息，报告资源的使用情况和应用的进度信息；\n（5）当作业完成时，ApplicationMaster向ResourceManager注销容器，执行周期完成。\nNode ManagerNodeManager是驻留在YARN集群中的每个节点上的代理，主要负责：\n\n容器生命周期管理、监控每个容器的资源（CPU、内存等）使用情况\n跟踪节点健康状况、以“心跳”的方式与ResourceManager保持通信、向ResourceManager汇报作业的资源使用情况和每个容器的运行状态、\n接收来自ApplicationMaster的启动&#x2F;停止容器的各种请求。注意：NodeManager主要负责管理抽象的容器，只处理与容器相关的事情，而不具体负责每个任务（Map任务或Reduce任务）自身状态的管理。任务状态的管理工作，是ApplicationMaster完成的，ApplicationMaster会通过不断与NodeManager通信来掌握各个任务的执行状态。\n\nJobHistoryServer：统一管理YARN历史任务。\nWebAppProxyServer： 任务执行时的Web页面代理。负责监管具体MapReduce任务执行全过程，将从Container那里收集过的任务执行信息汇总并显示到一个Web界面上。\nYarn工作流程\n步骤1：用户编写客户端应用程序并向YARN提交，提交内容包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。\n步骤2：YARN中的ResourceManager负责接收和处理来自客户端的请求，为应用程序分配一个容器，在该容器中启动一个ApplicationMaster。\n步骤3：ApplicationMaster被创建后会首先向ResourceManager注册。\n步骤4：ApplicationMaster采用轮询的方式向ResourceManager申请资源。\n步骤5：ResourceManager以“容器”的形式向提出申请的ApplicationMaster分配资源。\n步骤6：在容器中启动任务（运行环境、脚本）。\n步骤7：各个任务向ApplicationMaster汇报自己的状态和进度。\n步骤8：应用程序运行完成后，ApplicationMaster向ResourceManager的应用程序管理器注销并关闭自己。\nYARN统一部署的作用\n在集群中统一部署资源调度框架YARN，在YARN之上部署各种计算框架。\n 由YARN为这些计算框架提供统一的资源调度管理服务，并且根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩。\n 实现一个集群上的不同应用，负载混搭，有效提高了集群的利用率\n 不同计算框架可以共享底层存储，避免了数据集跨集群移动\n\nZooKeeper分布式应用程序可以通过 Zookeeper 实现如下功能：配置管理、命名服务、分布式锁、集群管理\n体系架构Leader\n\n集群中事务请求（写操作）唯一的调度和处理者，保证集群事务的顺序性\n\n集群内部各个服务的调度者Follower\n\n处理集群非事务请求（读操作）\n\n转发事务请求给Leader\n\n参与事务请求提案的投票\n\n参与Leader选举投票Observer\n\n处理客户端的非事务请求\n\n转发事务请求给Leader\n\n只提供数据只读服务，不参与任何形式的投票Leader&#x2F;Followers 集群架构，使 Zookeeper 具备了主从和主备的能力。\n\n\n（1）主从：主节点分配任务，从节点具体执行任务。\n（2）主备：主节点与备份节点，当主节点失效，尽快从 Followers 中重新选出一个充当新的主节点，保证主节点不宕机。\n三种Znode\n持久节点（PERSISTENT）：客户端与Zookeeper断开连接后，该节点依旧存在。默认情况下，所有 znode 均持久。\n临时节点（EPHEMERAL）：客户端活跃时临时节点有效，当客户端与zookeeper断开连接后，该节点自动删除。临时节点不允许有子节点，在leader选举中临时节点起着重要作用。\n顺序节点（SEQUENTIAL）：具有时序编号的节点。顺序节点可以是持久的或者临时的，因此，顺序节点可以是持久顺序节点（PERSISTENT_SEQUENTIAL），或者临时顺序节点（EPHEMERAL_SEQUENTIAL）。Znode原语操作：\n\n \n创建节点（ create ）\n 删除节点（ delete ）\n 更新节点（ set ）\n 获取节点信息（ get ）\n 权限控制（getAcl&#x2F;setAcl）\n 事件监听（watch）\nznode节点操作特性\n多台机器同时创建一个节点，只会有一个成功，可以用作分布式锁\n临时节点生命周期与会话一致，会话结束则临时节点删除，常用来做心跳、监控、负载等\n顺序节点保证全局节点名唯一，可以用作分布式环境下全局自增id\n客户端注册监听关心的目录节点，当节点目录数据发生变化时，Zookeeper会通知客户端\n\nzookeeper提供的服务配置管理\n统一命名服务\n集群管理\n分布式锁（共享锁、排他锁）\nzookeeper如何实现排他锁：\n（1）排他锁的表示：通过 znode 表示一个排他锁，如 &#x2F;x_lock&#x2F;lock。\n（2）获取锁：所有客户端都通过调用 create 接口尝试在 &#x2F;x_lock 下创建临时子节点&#x2F;x_lock&#x2F;lock。当然，最终只会有一个客户端创建成功，则表示该客户端获取了该排他锁。同时，没有获取到锁的其他客户端，注册一个 Watcher 监听子节点的变更情况。\n（3）释放锁：获取锁的客户端宕机或者正常完成业务逻辑后，把临时子节点删除，表示释放了这个排他锁。临时子节点删除后，其他客户端又开始新的一轮获取锁的过程。\nKafka消息队列的两种模型点对点模型和发布订阅模型\n\n点对点无法实现消息的广播和组播\n\n消息队列五大应用场景应用解耦、异步通信、流量削峰、日志处理、消息通信\n体系架构\nProducer 使用 push模式将消息发布到broke。\nConsumer 使用 pull 模式从 broker 订阅并消费消息。\nBroker（kafka服务器，多个broker构成kafka集群）发布到Kafka的消息如何组织和存储，从而获得负载均衡和高吞吐量？\n\n\n发布到Kafka集群的消息都有一个类别，称为Topic。\n\nPartition（分区）是实际存放消息的有序队列，其中的每条消息都分配一个有序的唯一标识（称为偏移量，offset） 。\n\n每个Topic可以保存到一个或多个Partition中。发送到Broker的消息会根据分区规则选择存储到哪一个 Partition。如果分区规则设置合理，则所有消息就可以均匀分布到不同的 Partition 中，从而将请求负载平衡到各个集群节点，提高吞吐率。\n\n任何发布到 Partition 的消息都会被追加到 Partition 尾部。这种顺序的磁盘写操作，是保证 Kafka 高吞吐率的重要原因。Kafka集群如何使用副本获得可用性和容错能力？\n\n在Kafka中，一个 Partition 在集群的不同的 Broker 上有多个副本（Replication）。\n\n多副本的Partition中，只有一个副本是 Leader，其余副本都是 Follower。\n\nLeader 负责处理该分区的所有读写操作，Follower 只是被动地从Leader 复制数据。当 Leader 故障时，通过Zookeeper选举一个 Follower 成为 Leader。Kafka集群如何实现点对点模式和发布订阅模式？\n\nKafka 实现点对点模式。若所有的消费者都隶属于同一个消费组，则所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，相当于点对点模式。\n\nKafka 实现发布&#x2F;订阅模式。若所有的消费者都隶属于不同的消费组，则所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，相当于发布&#x2F;订阅模式。\n\n\n","slug":"大数据架构复习","date":"2022-11-12T08:00:00.000Z","categories_index":"大数据","tags_index":"学习笔记,Hadoop,大数据,大数据架构,MapReduce,Spark,Kafka,云计算","author_index":"以太工坊"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new postbash$ hexo new &quot;My New Post&quot;More info: Writing\nRun serverbash$ hexo serverMore info: Server\nGenerate static filesbash$ hexo generateMore info: Generating\nDeploy to remote sitesbash$ hexo deployMore info: Deployment\n","slug":"hello-world","date":"1970-10-03T02:00:00.000Z","categories_index":"","tags_index":"","author_index":"以太工坊"}]