<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/img/avatar.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/avatar.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/avatar.png">
  <link rel="mask-icon" href="/img/avatar.png" color="#222">
  <meta name="baidu-site-verification" content="codeva-ljr52U8lOC">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"s.zair.top","root":"/","images":"/images","scheme":"Pisces","darkmode":"auto","version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":true,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="复习课第一章 Amdal 定律 对定律的理解（任务不变的情况下，速度的提升、加速比）、加速的极限应用题  6’*5网格和线程块的布局，计算全局id并行、并发、线程束、全局id、CPU多核与GPU众核程序分析题  10*2给代码写结果、分析为什么会有这种结果CPU多核  10*2数据划分：明确每个部分处理的数据范围任务并行：线程池实验CUDA编程    15*2具体的问题，设计网格与线程块，或者给了">
<meta property="og:type" content="article">
<meta property="og:title" content="并行计算复习课">
<meta property="og:url" content="https://s.zair.top/post/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E4%B9%A0%E8%AF%BE">
<meta property="og:site_name" content="以太工坊">
<meta property="og:description" content="复习课第一章 Amdal 定律 对定律的理解（任务不变的情况下，速度的提升、加速比）、加速的极限应用题  6’*5网格和线程块的布局，计算全局id并行、并发、线程束、全局id、CPU多核与GPU众核程序分析题  10*2给代码写结果、分析为什么会有这种结果CPU多核  10*2数据划分：明确每个部分处理的数据范围任务并行：线程池实验CUDA编程    15*2具体的问题，设计网格与线程块，或者给了">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230505172955.png">
<meta property="og:image" content="https://s2.loli.net/2023/03/26/C3A4mBKe5MNXqjE.png">
<meta property="og:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230507203938.png">
<meta property="og:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230507203950.png">
<meta property="og:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230507160525.png">
<meta property="og:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230511162559.png">
<meta property="og:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230511161714.png">
<meta property="article:published_time" content="2023-05-11T08:38:15.000Z">
<meta property="article:modified_time" content="2024-02-22T03:52:12.291Z">
<meta property="article:author" content="Tim">
<meta property="article:tag" content="学习笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230505172955.png">


<link rel="canonical" href="https://s.zair.top/post/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E4%B9%A0%E8%AF%BE.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://s.zair.top/post/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E4%B9%A0%E8%AF%BE","path":"/post/并行计算复习课.html","title":"并行计算复习课"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>并行计算复习课 | 以太工坊</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?5e5c8e78bcbcec96b8795ab83fc501b0"></script>







  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="以太工坊" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">以太工坊</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">以太工坊</p>
      <img class="custom-logo-image" src="/img/avatar.png" alt="以太工坊">
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-标准版"><a href="https://www.zair.top/" rel="section" target="_blank"><i class="fa fa-sitemap fa-fw"></i>标准版</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%8D%E4%B9%A0%E8%AF%BE"><span class="nav-text">复习课</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="nav-text">并行计算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C"><span class="nav-text">并发与并行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flynn%E5%88%86%E7%B1%BB%E6%B3%95"><span class="nav-text">Flynn分类法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Amdahl%E5%AE%9A%E5%BE%8B"><span class="nav-text">Amdahl定律</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA%E6%A6%82%E8%BF%B0"><span class="nav-text">CUDA概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97"><span class="nav-text">异构计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU%E5%92%8CGPU%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="nav-text">CPU和GPU的差异</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA%E7%BA%BF%E7%A8%8B%E7%BB%84%E7%BB%87%E5%BD%A2%E5%BC%8F"><span class="nav-text">CUDA线程组织形式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA%E4%B8%BB%E6%9C%BA-%E8%AE%BE%E5%A4%87%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">CUDA主机&#x2F;设备编程模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%BD%E6%95%B0%E9%99%90%E7%95%8C%E7%AC%A6"><span class="nav-text">函数限界符</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CUDA%E6%A0%B8%E5%87%BD%E6%95%B0%E7%9A%84%E9%99%90%E5%88%B6"><span class="nav-text">CUDA核函数的限制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8BSIMT"><span class="nav-text">并行计算模型SIMT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU%E6%9E%B6%E6%9E%84"><span class="nav-text">GPU架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="nav-text">内存模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F"><span class="nav-text">内存访问模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E4%B8%8Ebank-conflict"><span class="nav-text">共享内存与bank conflict</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81"><span class="nav-text">代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%BF%BB%E8%BD%ACCPU"><span class="nav-text">图像翻转CPU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0"><span class="nav-text">数组相加</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%BF%BB%E8%BD%AC"><span class="nav-text">图像翻转</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE"><span class="nav-text">矩阵转置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E9%98%B5%E7%9B%B8%E4%B9%98"><span class="nav-text">方阵相乘</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="nav-text">直方图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%84%E7%BA%A6%E6%B1%82%E5%92%8C"><span class="nav-text">规约求和</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TOP-K"><span class="nav-text">TOP K</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-text">实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20%E7%BA%A7%E7%9C%9F%E9%A2%98"><span class="nav-text">20级真题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E7%AD%94%E9%A2%98"><span class="nav-text">简答题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E9%A2%98"><span class="nav-text">程序分析题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU%E7%BC%96%E7%A8%8B"><span class="nav-text">CPU编程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU%E7%BC%96%E7%A8%8B"><span class="nav-text">GPU编程</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Tim</p>
  <div class="site-description" itemprop="description">分享我的学习笔记、经验与有趣的小玩意.<br></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Tim-Saijun" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Tim-Saijun" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yangzair@outlook.com" title="E-Mail → mailto:yangzair@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://t.me/tim_run" title="Telegram → https:&#x2F;&#x2F;t.me&#x2F;tim_run" rel="noopener me" target="_blank"><i class="fab fa-telegram fa-fw"></i>Telegram</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zair.top/" title="标准版 → https:&#x2F;&#x2F;www.zair.top" rel="noopener me" target="_blank"><i class="fa fa-globe fa-fw"></i>标准版</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://s.zair.top/post/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E4%B9%A0%E8%AF%BE">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tim">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="以太工坊">
      <meta itemprop="description" content="分享我的学习笔记、经验与有趣的小玩意.<br>">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="并行计算复习课 | 以太工坊">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          并行计算复习课
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-11 16:38:15" itemprop="dateCreated datePublished" datetime="2023-05-11T16:38:15+08:00">2023-05-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-22 11:52:12" itemprop="dateModified" datetime="2024-02-22T11:52:12+08:00">2024-02-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
    <span id="/post/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E4%B9%A0%E8%AF%BE" class="post-meta-item twikoo_visitors" data-flag-title="并行计算复习课" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="twikoo_visitors"></span>
    </span>
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="复习课"><a href="#复习课" class="headerlink" title="复习课"></a>复习课</h2><p>第一章 Amdal 定律 对定律的理解（任务不变的情况下，速度的提升、加速比）、加速的极限<br><strong>应用题</strong>  6’*5<br>网格和线程块的布局，计算全局id<br>并行、并发、线程束、全局id、CPU多核与GPU众核<br><strong>程序分析题</strong>  10*2<br>给代码写结果、分析为什么会有这种结果<br><strong>CPU多核</strong>  10*2<br>数据划分：明确每个部分处理的数据范围<br>任务并行：线程池实验<br><strong>CUDA编程</strong>    15*2<br>具体的问题，设计网格与线程块，或者给了线程块，只需要设计网格；<br>主函数中的固定流程；关键在写核函数；</p>
<h2 id="并行计算"><a href="#并行计算" class="headerlink" title="并行计算"></a>并行计算</h2><h3 id="并发与并行"><a href="#并发与并行" class="headerlink" title="并发与并行"></a>并发与并行</h3><p>串行：单机单核，指令顺序执行。<br><strong>并发</strong>：单机单核，指令在时间上并行执行，同一时间间隔发生。<br><strong>并行</strong>：单机多核，多机单&#x2F;多核，指令在空间上并行，同一时刻发生。<br>并行计算就是在并行计算机或者分布式系统等高性能计算系统上做的超级计算。并行计算可以降低单个问题求解的时间，增加求解规模与精度，提高吞吐率等。</p>
<p>三种分类：<br>计算模式：时间并行（流水线）、空间并行（多处理器）<br>程序逻辑：任务并行、数据并行<br>应用角度：计算密集、数据密集、网络密集</p>
<h3 id="Flynn分类法"><a href="#Flynn分类法" class="headerlink" title="Flynn分类法"></a>Flynn分类法</h3><p>依据指令流(instruction stream)和数据流(data stream)的执行方式对并行计算机体系结构分类的一种方法。<br>包含SISD(早期串行机）,SIMD（单核计算机）,MISD（很少用）,MIMD（多核计算机，并行）;</p>
<h3 id="Amdahl定律"><a href="#Amdahl定律" class="headerlink" title="Amdahl定律"></a>Amdahl定律</h3><p>假定任务数量一定，通过计算性能加速比，揭示了<u>一个程序中无法并行化的部分会限制整个程序的性能提升</u>的规律。<br>$$S&#x3D;\frac{W_{s}+W_{p}}{W_{s}+W_{p}&#x2F;p}$$<br>其中$W_{s}$为串行任务数量，$W_{p}$为并行任务数量，$p$为处理器数目，$S$为加速比。<br>依据串行分量的占比$f&#x3D;W_{s}&#x2F;W$，将上式同时除以$W$可得下面的式子：<br>$$S&#x3D;\frac{f+(1-f)}{f+\frac{1-f}{p}} &#x3D;\frac{p}{1+f(p-1)}$$<br>$\lim_{x\rightarrow \infty}S&#x3D;1&#x2F;f$，当处理器的数目无限增大时，系统能达到的加速比受制于程序中的串行部分。</p>
<pre class="line-numbers language-none"><code class="language-none">1.一个串行应用程序中，有20%的比例必须串行执行，现在需要实现3倍的性能提升，为实现这个目标，需要多少个CPU？如果要实现5倍的加速比，需要多少个CPU？
2.一个运行在5个计算机上的并行程序，有10%的并行部分。相对于在一个计算机上的串行执行，加速比是多少？如果我们想将加速比提升2倍，需要多少个CPU？
3.将一个不可并行部分占5%的应用程序修改为并行程序。目前市场上有两种并行计算机：计算机X有4个CPU，每个CPU可以在1个小时内完成该应用程序的执行；计算机Y有16个CPU，每个CPU可以在2个小时内执行完该应用程序。如果需要最小化运行时间，请问你该买哪个计算机？</code></pre>

<h2 id="CUDA概述"><a href="#CUDA概述" class="headerlink" title="CUDA概述"></a>CUDA概述</h2><h3 id="异构计算"><a href="#异构计算" class="headerlink" title="异构计算"></a>异构计算</h3><p>GPU的并行计算是一种异构计算，分为主机端（CPU）和设备端（GPU），二者关系从来都不是平等的，CUDA甚至需要明确标识代码需要在哪运行。</p>
<h3 id="CPU和GPU的差异"><a href="#CPU和GPU的差异" class="headerlink" title="CPU和GPU的差异"></a>CPU和GPU的差异</h3><blockquote>
<p>直观来说，CPU更多资源用于缓存与控制流，GPU则是更多的数据计算。</p>
</blockquote>
<ol>
<li>在GPU环境下，GPU的核心负责所有计算任务的执行，<strong>但工作指令总是来自CPU</strong>。</li>
<li>在GPU情况下，<strong>GPU核心从不自己获取数据，数据总是来自CPU端，计算结果再传回CPU端</strong>。因此，GPU在后台只是扮演计算加速器的角色，为CPU完成某些外包任务。</li>
<li>这种类型的体系架构只有在有着<strong>大量的并行处理单元</strong>，而不是仅有2个或4个时，才会非常有效。</li>
<li>线程束的概念对GPU的体系结构有重大影响。数据必须以同样大小的数据块为单位输入GPU，<strong>数据块是半个线程束</strong>，即16个元素。</li>
<li>数据必须以半个线程束的大小传输给GPU核心的事实意味着负责将数据传入GPU的存储系统应该每次输入16个数据。这需要一次能够传输16个数的并行存储子系统。这就是为什么GPU的DRAM存储器是由DDR5构成的，因为<strong>它是并行存储器</strong>。</li>
<li>由于GPU核心和CPU核心是完全不同的处理单元，因此可以预见它们<strong>具有不同的ISA</strong>（指令集架构）。即：它们说的是不同的语言。<br>GPU线程与CPU线程也有所不同，创建开销极低。CPU通过多级cache缩减延迟，而GPU是通过流水线提高吞吐量来缩减延迟的。<br>由于其设计目标的不同，CPU需要很强的通用性来处理各种不同的数据类型，同时逻辑判断又会引入大量的分支跳转和中断的处理。而GPU面对的则是类型统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230505172955.png" alt="image.png"></p>
<h3 id="CUDA线程组织形式"><a href="#CUDA线程组织形式" class="headerlink" title="CUDA线程组织形式"></a>CUDA线程组织形式</h3><p><img src="https://s2.loli.net/2023/03/26/C3A4mBKe5MNXqjE.png" alt="image.png"><br>Thread：并行的基本单位<br>Thread Block：互相合作的线程组<br>允许彼此同步<br>通过快速共享内存交换数据<br>以1维、2维或3维组织<br>最多包含1024个线程<br>Grid：一组线程块<br>以1维、2维组织，也可3维<br>共享全局变量<br>Kernel：在GPU上执行的核心程序<br>One kernel             One Grid</p>
<h3 id="CUDA主机-设备编程模型"><a href="#CUDA主机-设备编程模型" class="headerlink" title="CUDA主机&#x2F;设备编程模型"></a>CUDA主机&#x2F;设备编程模型</h3><h4 id="函数限界符"><a href="#函数限界符" class="headerlink" title="函数限界符"></a>函数限界符</h4><ul>
<li>_ <em>device</em> _:在device端执行，并且也只能从device端调用，即作为device端的子函数来使用。</li>
<li>_ <em>host</em> _:在host端执行，也只能从host端调用，与一般的C函数相同。不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。</li>
<li>_ <em>global</em> _ :即kernel函数，它在设备上执行，但是要从host端调用。</li>
</ul>
<h4 id="CUDA核函数的限制"><a href="#CUDA核函数的限制" class="headerlink" title="CUDA核函数的限制"></a>CUDA核函数的限制</h4><ol>
<li>只能访问设备内存</li>
<li>必须返回void类型</li>
<li>不支持可变数量的参数</li>
<li>不支持静态变量</li>
<li>显示异步行为，意味着<strong>host不会等待kernel执行</strong>完就执行下一步</li>
</ol>
<h3 id="并行计算模型SIMT"><a href="#并行计算模型SIMT" class="headerlink" title="并行计算模型SIMT"></a>并行计算模型SIMT</h3><p>线程块是程序启动的基本单位，线程束是程序执行的单位；</p>
<blockquote>
<p>例如，我们说一个块大小是256个线程时，也就是意味着线程块大小为8个线程束。每个线程束总是包含32个线程。这个参数表明：虽然启动程序时，每个线程块有256个线程，但这并不意味着它们会立即执行，也就是说这256个线程并不会在同一时刻都被执行或完成执行。相反，GPU的执行硬件会用8个线程束来执行这些线程。</p>
</blockquote>
<p>SIMT属于SIMD的范畴，因为它也是在多个数据上执行相同的指令。但是，SIMT允许由用户来分配线程，具体来说就是CUDA为每个线程指定了标识符（编号）。<br>一个关键的区别就是SIMD要求同一个向量中的所有元素要在一个统一的同步组中一起执行，而SIMT则允许属于同一个线程束的多个线程独立执行，这几个线程可以有不同的行为。因此SIMT允许线程级并发，也就是在统一线程束下的线程可以同时做不同的事情。<br>三个不同：</p>
<ul>
<li>每个线程都有自己的指令地址计数器</li>
<li>每个线程都有自己的寄存器状态</li>
<li>每个线程可以有一个独立的执行路径</li>
</ul>
<h3 id="GPU架构"><a href="#GPU架构" class="headerlink" title="GPU架构"></a>GPU架构</h3><p><strong>流式多处理器SM</strong><br>一个线程块只能在一个SM上被调度，但一个SM可以对应多个线程块。<br>当SM指定了一个或多个要计算的线程块时，这些线程块会被分为多个warp，等待调度。<br>线程束中的线程都在不同的数据上执行相同的命令。<br>SM容纳线程块的数量，取决于SM内的共享内存和寄存器以及线程占用的资源。<br>线程块里的所有线程在逻辑上并行运行，但并不是所有的线程都可以同时在物理层面执行。（一个SM同时只调度一个warp，其余warp等待，不同的warp间的切换是零开销的因为warp的执行上下文在warp的整个生命周期都会被SM维护）</p>
<blockquote>
<p>NVIDIA GeForce RTX 3090的Compute Capabilities是8.6，其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，求：理论上同一时刻并行执行线程数量为多少？并发执行线程数量为多少？<br>其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，即最多可以存在48个warp，由于warp是通过warp调度器并发执行，warp中32条线程是并行执行，因此笼统上可以认为，同一时刻并行执行线程数量为82*32&#x3D;2624，并发执行线程数量为82*32*48&#x3D;125952。</p>
</blockquote>
<h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><table>
<thead>
<tr>
<th>存储器</th>
<th>位置</th>
<th>是否缓存</th>
<th>访问权限</th>
<th>生存周期</th>
</tr>
</thead>
<tbody><tr>
<td>寄存器</td>
<td>片上</td>
<td>无</td>
<td>device</td>
<td>与线程、核函数相同</td>
</tr>
<tr>
<td>共享内存</td>
<td>片上</td>
<td>无</td>
<td>device</td>
<td>与block相同</td>
</tr>
<tr>
<td>本地内存</td>
<td>板载</td>
<td>无</td>
<td>device</td>
<td>与线程、核函数相同</td>
</tr>
<tr>
<td>全局内存</td>
<td>板载</td>
<td>无</td>
<td>device&amp;host</td>
<td>程序</td>
</tr>
<tr>
<td>纹理内存、常量内存</td>
<td>板载</td>
<td>有</td>
<td>device&amp;host</td>
<td>程序</td>
</tr>
</tbody></table>
<blockquote>
<p>定义在CUDA核函数中的变量，什么时候是寄存器变量，什么时候是本地变量呢？</p>
</blockquote>
<p>以下三种情况是本地变量，其余则寄存器变量</p>
<ul>
<li>编译阶段无法确定的数组</li>
<li>数组或结构体占用的空间很大</li>
<li>核函数中定义了很多的变量，寄存器装不下、<br>从寄存器溢出到本地内存的，本质上与全局内存在同一个存储区域</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230507203938.png" alt="image.png"><br><img src="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230507203950.png" alt="image.png"></p>
<h3 id="内存访问模式"><a href="#内存访问模式" class="headerlink" title="内存访问模式"></a>内存访问模式</h3><p>全局内存通过缓存来实现加载&#x2F;存储。所有对全局内存的访问都会通过L2 cache（一般128字节）。<br><strong>对齐访问</strong><br>第一个地址是缓存粒度（一般32字节）的偶数倍（cache line取数据开始位置就是如此）<br><strong>合并访问</strong><br>一个线程束中的全部线程访问一个连续的内存块。合并访问指的是线程束对全局内存的一次访问请求导致最少的数据传输（合并度&#x3D;100%），否则是非合并访问。</p>
<p><font color="#7030a0">5种访问方式，合并度的计算？？</font> </p>
<p>如果说读取和写入都不能合并访问，那么应该优先保证合并写入。只读数据的非合并访问，可以用__ldg()函数做缓存，也可以用共享内存转换为合并地。</p>
<h3 id="共享内存与bank-conflict"><a href="#共享内存与bank-conflict" class="headerlink" title="共享内存与bank conflict"></a>共享内存与bank conflict</h3><p>共享内存可以被程序员直接操控。<br>共享内存被划分为许多的banks.</p>
<ul>
<li>一个warp中的所有线程访问同一bank同一地址-广播</li>
<li>一个warp中的不同线程访问<strong>一个bank的不同地址</strong>-bank conflict</li>
<li>多个线程访问同一bank同一地址-多播</li>
</ul>
<p>Memory Padding 内存填充解决Bank confilct<br><img src="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230507160525.png" alt="image.png"><br>Padding操作：在sData的第二维+1，即<code>sData[BS][BS+1]</code><br>填充的部分不能用于数据存储，导致可用的共享内存数量减少。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="图像翻转CPU"><a href="#图像翻转CPU" class="headerlink" title="图像翻转CPU"></a>图像翻转CPU</h3><p>多线程翻转图像，同时手动维护缓存。</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">void * MTFlipHM(void * tid)&#123;
        struct Pixel pix; &#x2F;&#x2F;temp swap pixel
        int row, col;
        int id &#x3D; *((int *) tid);
        int start &#x3D; id * ip.Vpixels&#x2F;NumThreads;
        int end &#x3D; start + ip.Vpixels&#x2F;NumThreads;
        unsigned char buffer[16384];
        for (row &#x3D; st ; row &lt; ed; row++)
        &#123;
            memcpy(buffer, TheImage[row], ip.Hbytes);
            col &#x3D; 0;
            while (col &lt; ip.Hpixels * 3 &#x2F;2)&#123;
            pix.B &#x3D; buffer[col];
            pix.G &#x3D; buffer[col+1];
            pix.R &#x3D; buffer[col+2];
            buffer[col]   &#x3D; buffer[ip.Hpixels*3 - col -3];
            buffer[col+1] &#x3D; buffer[ip.Hpixels*3 - col -2];
            buffer[col+2] &#x3D; buffer[ip.Hpixels*3 - col -1];
            buffer[ip.Hpixels*3 - col -3] &#x3D; pix.B;
            buffer[ip.Hpixels*3 - col -2] &#x3D; pix.G;
            buffer[ip.Hpixels*3 - col -1] &#x3D; pix.R;
            col +&#x3D; 3;
            &#125;
        &#125;
        memcpy(TheImage[row],buffer,ip.Hbytes);
        pthread_exit(NULL);
&#125;

void * MTFlipVM(void * tid)&#123;
        struct Pixel pix; &#x2F;&#x2F;temp swap pixel
        int row, col;
        int id &#x3D; *((int *) tid);
        int start &#x3D; id * ip.Vpixels&#x2F;NumThreads;
        int end &#x3D; start + ip.Vpixels&#x2F;NumThreads;
        unsigned char buffer1[16384], buffer2[16384];
        for (row &#x3D; start; row &lt; end; row ++)
        &#123;
            memcpy(buffer1,TheImage[row],ip.Hbytes);
            int  mirrow &#x3D; ip.Vpixels - 1 - row;
            memcpy(buffer2,TheImage[mirrow],ip.Hbytes);
            &#x2F;&#x2F; 再错位拷贝即完成交换
            memcpy(TheImage[row],buffer2,ip.Hbytes);
            memcpy(TheImage[mirrow],buffer1,ip.Hbytes);
        &#125;
&#125;

pthread_create(&amp;ThHandle[i], &amp;ThAttr, MTFlipFunc, (void *)&amp;ThParam[i]);
for(i&#x3D;0; i&lt;NumThreads; i++)
                pthread_join(ThHandle[i], NULL);</code></pre>

<h3 id="数组相加"><a href="#数组相加" class="headerlink" title="数组相加"></a>数组相加</h3><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">const int a&#x3D;1, b&#x3D;2, c&#x3D;3;
__global__ void add(double *x, double *y, double* z)&#123;
	const int n &#x3D; blockIdx.x * blockDim.x + threadIdx.x;
	if (n&lt;N)  z[n] &#x3D; x[n] + y[n];
&#125;
int main()&#123;
	const int N &#x3D; 1e9;
	const int M &#x3D; sizeof(double) * N;
	double *h_x &#x3D; (double*) malloc(M);
	double *h_y &#x3D; (double*) malloc(M);
	double *h_z &#x3D; (double*) malloc(M);
	for (int i&#x3D;0; i&lt;N; i++)
	&#123;
		h_x[i] &#x3D; a;
		h_y[i] &#x3D; b;
	&#125;
	double *d_x, *d_y, *d_z;
	cudaMalloc((void**) &amp;d_x, M);
	cudaMalloc((void**) &amp;d_y, M);
	cudaMalloc((void**) &amp;d_z, M);

	const int block_size &#x3D;  128;
	int grid_size &#x3D; (N+block_size-1) &#x2F; block_size;
	add&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, d_z);
	cudaMemcpy(h_z, d_z, M, cudaMemcpyDeviceToHost);
	free(h_x),free(h_y),free(h_z);
	cudaFree(d_x),cudaFree(d_y),cudaFree(d_z);
&#125;</code></pre>

<h3 id="图像翻转"><a href="#图像翻转" class="headerlink" title="图像翻转"></a>图像翻转</h3><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">__global__ void Vflip(uch *ImgDst, uch *ImgSrc, ui Hpixels, ui Vpixels)&#123;
ui ThrPerBlk &#x3D; blockDim.x;
ui MYbid &#x3D; blockIdx.x;
ui MYtid &#x3D; threadIdx.x;
ui MYgtid &#x3D; ThrPerBlk * MYbid + MYtid;
ui BlkPerRow &#x3D; (Hpixels + ThrPerBlk - 1) &#x2F; ThrPerBlk; &#x2F;&#x2F; ceil
ui RowBytes &#x3D; (Hpixels * 3 + 3) &amp; (~3);
ui MYrow &#x3D; MYbid &#x2F; BlkPerRow;
ui MYcol &#x3D; MYgtid - MYrow*BlkPerRow*ThrPerBlk;
if (MYcol &gt;&#x3D; Hpixels) return;&#x2F;&#x2F; col out of range
ui MYmirrorrow &#x3D; Vpixels - 1 - MYrow;
ui MYsrcOffset &#x3D; MYrow * RowBytes;
ui MYdstOffset &#x3D; MYmirrorrow * RowBytes;
ui MYsrcIndex &#x3D; MYsrcOffset + 3 * MYcol;
ui MYdstIndex &#x3D; MYdstOffset + 3 * MYcol;
&#x2F;&#x2F; swap pixels RGB @MYcol , @MYmirrorcol
ImgDst[MYdstIndex] &#x3D; ImgSrc[MYsrcIndex];
ImgDst[MYdstIndex + 1] &#x3D; ImgSrc[MYsrcIndex + 1];
ImgDst[MYdstIndex + 2] &#x3D; ImgSrc[MYsrcIndex + 2];&#125;

__global__ void Hflip(uch *ImgDst, uch *ImgSrc, ui Hpixels)&#123;
ui ThrPerBlk &#x3D; blockDim.x;
ui MYbid &#x3D; blockIdx.x;
ui MYtid &#x3D; threadIdx.x;
ui MYgtid &#x3D; ThrPerBlk * MYbid + MYtid;
ui BlkPerRow &#x3D; (Hpixels + ThrPerBlk -1 ) &#x2F; ThrPerBlk; &#x2F;&#x2F; ceil
ui RowBytes &#x3D; (Hpixels * 3 + 3) &amp; (~3);
ui MYrow &#x3D; MYbid &#x2F; BlkPerRow;
ui MYcol &#x3D; MYgtid - MYrow*BlkPerRow*ThrPerBlk;
if (MYcol &gt;&#x3D; Hpixels) return;&#x2F;&#x2F; col out of range
ui MYmirrorcol &#x3D; Hpixels - 1 - MYcol;
ui MYoffset &#x3D; MYrow * RowBytes;
ui MYsrcIndex &#x3D; MYoffset + 3 * MYcol;
ui MYdstIndex &#x3D; MYoffset + 3 * MYmirrorcol;
&#x2F;&#x2F; swap pixels RGB @MYcol , @MYmirrorcol
ImgDst[MYdstIndex] &#x3D; ImgSrc[MYsrcIndex];
ImgDst[MYdstIndex + 1] &#x3D; ImgSrc[MYsrcIndex + 1];
ImgDst[MYdstIndex + 2] &#x3D; ImgSrc[MYsrcIndex + 2];&#125;</code></pre>

<h3 id="矩阵转置"><a href="#矩阵转置" class="headerlink" title="矩阵转置"></a>矩阵转置</h3><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">__global__ void transpose(int a[], int b[], int N)&#123;
    &#x2F;&#x2F;分配共享内存
    __shared__ int S[TILE][TILE + 1];
    int bx &#x3D; blockIdx.x * TILE;
    int by &#x3D; blockIdx.y * TILE;
    int ix &#x3D; bx + threadIdx.x;
    int iy &#x3D; by + threadIdx.y;
    if (ix &lt; N &amp;&amp; iy &lt; N)&#x2F;&#x2F; 读入共享内存
        S[threadIdx.y][threadIdx.x] &#x3D; a[iy * N + ix];
    __syncthreads();&#x2F;&#x2F;同步，这是必不可少的
    int ix2 &#x3D; bx + threadIdx.y;
    int iy2 &#x3D; by + threadIdx.x;
    if (ix2 &lt;N &amp;&amp; iy2 &lt; N)&#x2F;&#x2F; 写回
        b[ix2 * N + iy2 ] &#x3D; S[threadIdx.x][threadIdx.y];
&#125;</code></pre>

<h3 id="方阵相乘"><a href="#方阵相乘" class="headerlink" title="方阵相乘"></a>方阵相乘</h3><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">__shared__ float Mds[WIDTH][TILE_WIDTH];
__shared__ float Nds[TILE_WIDTH][WIDTH];
int bx&#x3D;blockIdx.x ; int by &#x3D; blockIdx.y;
int tx&#x3D;threadIdx.x ; int ty &#x3D; threadIdx.y;
int Row &#x3D; by *TILE_WIDTH +ty;
int Col &#x3D; bx*TILE_WIDTH + tx;
float Pvalue &#x3D; 0;
for(int m&#x3D;0; m&lt;WIDTH&#x2F;TILE_WIDTH; ++m)
    &#123;
    &#x2F;&#x2F; 每个线程载入M的子矩阵的一个元素
    Mds[ty][tx] &#x3D; Md[Row*width+(m*TILE_WIDTH+tx)];
    &#x2F;&#x2F;每个线程载入N的子矩阵的一个元素
    Nds[ty][tx] &#x3D; Nd[(m*TILE_WIDTH+ty)*width+Col];
	 __syncthreads();
	 for (int k &#x3D; 0; k &lt; TILE_WIDTH; ++k)
	    Pvalue +&#x3D; Mds[ty][k] * Nds[k][tx];
	 __syncthreads();
	 &#125;
Pd[Row*WIDTH+Col] &#x3D; Pvalue;&#x2F;&#x2F;将结果写回P矩阵</code></pre>

<h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">#define SIZE (100*1024*1024)
&#x2F;&#x2F;通过工具函数big_random_block()来生成随机的字节流
unsigned char *buffer &#x3D;(unsigned char*)big_random_block( SIZE );
unsigned int histo[256];
for (int i &#x3D; 0; i&lt;256; i++)
	histo[i] &#x3D; 0;
for (int i &#x3D; 0; i &lt; SIZE; i++)
	histo[buffer[i]]++;
long histoCount &#x3D; 0;
for (int i &#x3D; 0; i&lt;256; i++) &#123;
	histoCount +&#x3D; histo[i]; &#125;

__global__ void histo_kernel(unsigned char *buffer, long size, unsigned int *histo)&#123;
__shared__ unsigned int temp[256];
temp[threadIdx.x] &#x3D; 0;
__syncthreads();
int i &#x3D; threadIdx.x + blockIdx.x * blockDim.x;
int offset &#x3D; blockDim.x *gridDim.x;
while (i&lt;size)&#123;
	atomicAdd(&amp;temp[buffer[i]], 1);
	i +&#x3D; offset;
&#125;
__syncthreads();
atomicAdd(&amp;(histo[threadIdx.x]), temp[threadIdx.x]);
&#125;</code></pre>

<h3 id="规约求和"><a href="#规约求和" class="headerlink" title="规约求和"></a>规约求和</h3><p>规约求和与TOP K类似，下面的代码为官方代码，理解参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_48266461/article/details/125670866">这篇文章</a> </p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">__global__ void _sum_gpu(int *input, int count, int *output)
&#123;
    __shared__ int sum_per_block[BLOCK_SIZE];

    int temp &#x3D; 0;
    for (int idx &#x3D; threadIdx.x + blockDim.x * blockIdx.x;
         idx &lt; count; idx +&#x3D; gridDim.x * blockDim.x
	)
    &#123;&#x2F;&#x2F; 跨网格循环，一个线程加多个数据，应对海量数据
        temp +&#x3D; input[idx];
    &#125;

    sum_per_block[threadIdx.x] &#x3D; temp;  &#x2F;&#x2F;the per-thread partial sum is temp!
    __syncthreads();

    &#x2F;&#x2F;**********shared memory summation stage***********
    for (int length &#x3D; BLOCK_SIZE &#x2F; 2; length &gt;&#x3D; 1; length &#x2F;&#x3D; 2)
    &#123;
        int double_kill &#x3D; -1;
	if (threadIdx.x &lt; length)
	&#123;
	    double_kill &#x3D; sum_per_block[threadIdx.x] + sum_per_block[threadIdx.x + length];
	&#125;
	__syncthreads();  &#x2F;&#x2F;why we need two __syncthreads() here, and,
	
	if (threadIdx.x &lt; length)
	&#123;
	    sum_per_block[threadIdx.x] &#x3D; double_kill;
	&#125;
	__syncthreads();  &#x2F;&#x2F;....here ?
	
    &#125; &#x2F;&#x2F;the per-block partial sum is sum_per_block[0]

    if (blockDim.x * blockIdx.x &lt; count) &#x2F;&#x2F;in case that our users are naughty
    &#123;
        &#x2F;&#x2F;the final reduction performed by atomicAdd()
        if (threadIdx.x &#x3D;&#x3D; 0) atomicAdd(output, sum_per_block[0]);
    &#125;
&#125;
</code></pre>
<h3 id="TOP-K"><a href="#TOP-K" class="headerlink" title="TOP K"></a>TOP K</h3><p>具体实现流程如下：</p>
<ol>
<li>将数据复制到GPU显存中<br> <code>float *d_data; cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);</code></li>
<li>将数据存储到二元组中<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">typedef struct &#123;     float value;     int index; &#125; Tuple;  
Tuple *d_tuples; 
int threadsPerBlock &#x3D; 256; 
int blocksPerGrid &#x3D; (n + threadsPerBlock - 1) &#x2F; threadsPerBlock;
initializeTuples&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_data, d_tuples, n);
&#96;&#96;&#96;   
3.  对二元组进行归约操作，得到前K个最大&#x2F;最小值的索引
&#96;&#96;&#96;cpp
int *d_indices;
kReduceKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_tuples, d_indices, n, k);
__global__ void kReduceKernel(Tuple *input, int *output, int n, int k) &#123;
    extern __shared__ Tuple shared[];
    int tid &#x3D; threadIdx.x;
    int i &#x3D; blockIdx.x * blockDim.x + threadIdx.x;
    shared[tid] &#x3D; (i &lt; n) ? input[i] : Tuple&#123;0, 0&#125;;
    __syncthreads();
    for (int s &#x3D; blockDim.x &#x2F; 2; s &gt; 0; s &gt;&gt;&#x3D; 1) &#123;
        if (tid &lt; s)
            shared[tid] &#x3D; (shared[tid].value &gt; shared[tid + s].value) ? shared[tid] : shared[tid + s];
        __syncthreads();
    &#125;

    if (tid &#x3D;&#x3D; 0)
        output[blockIdx.x] &#x3D; shared[0].index;
&#125;</code></pre></li>
<li>在CPU中恢复原始数据并按照索引排序，得到前K个最大&#x2F;最小值<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">cudaMemcpy(h_indices, d_indices, size, cudaMemcpyDeviceToHost);  
for (int i &#x3D; 0; i &lt; k; ++i) &#123;     
    int index &#x3D; h_indices[i];     
    h_result[i] &#x3D; h_data[index]; &#125;  
std::sort(h_result, h_result + k);</code></pre>
完成以上步骤后，就可以得到排序后的前K个最大&#x2F;最小值了。</li>
</ol>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><strong>实验一</strong>：PI的三种求法、线程池<br>实验二：矩阵相乘、转置、规约、TOP K 问题<br>全局内存、共享内存优化、bank冲突优化<br>手写并行计算报告3-4页纸 cpu pi三种求法 生产者消费者模式 GPU 主程序流程明确一次即可，核函数不同，重点全局内存与共享内存实现， 矩阵相乘直方图(跨网格循环)规约100w数组中的最大值 报告在考试时上交</p>
<h2 id="20级真题"><a href="#20级真题" class="headerlink" title="20级真题"></a>20级真题</h2><h3 id="简答题"><a href="#简答题" class="headerlink" title="简答题"></a>简答题</h3><p><strong>Amdel定律，处理器n个，串行40%，求加速比极限。</strong><br><strong>给RGB图像680*480，分4个线程（没说怎么分），每个线程处理的像素范围和字节范围；</strong><br><strong>PPT线程束并行并发数量的例题原题；</strong></p>
<blockquote>
<p>NVIDIA GeForce RTX 3090的Compute Capabilities是8.6，其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，求：理论上同一时刻并行执行线程数量为多少？并发执行线程数量为多少？<br>其中包含82个SM，每个SM中允许同时存在的最大线程数量为1536，即最多可以存在48个warp，由于warp是通过warp调度器并发执行，warp中32条线程是并行执行，因此笼统上可以认为，同一时刻并行执行线程数量为82*32&#x3D;2624，并发执行线程数量为82*32*48&#x3D;125952。</p>
</blockquote>
<p><strong>矩阵转置过程的某个元素全局id；</strong><br><img src="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230511162559.png" alt="image.png"><br>问元素3的全局id<br><strong>可不可以一边复制数据，一边转置（CUDA流）</strong>；</p>
<h3 id="程序分析题"><a href="#程序分析题" class="headerlink" title="程序分析题"></a>程序分析题</h3><p>第一题，课堂练习原题；&lt;4,4&gt;改成了&lt;5,5&gt;；要说明过程；<br><img src="https://raw.githubusercontent.com/CenterWander/tuchuang/main/img/20230511161714.png" alt="程序分析一"><br>第二题，少了原子操作的直方图规约，问有什么问题；</p>
<h3 id="CPU编程"><a href="#CPU编程" class="headerlink" title="CPU编程"></a>CPU编程</h3><p>求数组<code>a[2,1000000]</code>中的素数，要求10个线程等分；<br>线程池伪代码：客户端、服务端（邮件功能、导出功能、流量统计等一堆功能）；</p>
<h3 id="GPU编程"><a href="#GPU编程" class="headerlink" title="GPU编程"></a>GPU编程</h3><p>全局内存的矩阵相乘；<br>向量a,b内积，维数&#x3D;1024000000；定死blockdim.x &#x3D; blockdim.y &#x3D;16; 设计Grid；要求用共享内存优化、解决bank冲突、输出结果回到CPU做最终合并。</p>
<p>感受：非代码题宝宝巴士，代码题重拳出击，根本写不完。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Tim
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://s.zair.top/post/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%A4%8D%E4%B9%A0%E8%AF%BE" title="并行计算复习课">https://s.zair.top/post/并行计算复习课</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <a target="_blank" class="social-link" href="https://t.me/tim_run">
            <span class="icon">
              <i class="fab fa-telegram"></i>
            </span>

            <span class="label">Telegram</span>
          </a>
      </div>

      <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag"># 学习笔记</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E5%AE%9E%E9%AA%8C%E4%BA%8C" rel="prev" title="并行编程实验二">
                  <i class="fa fa-angle-left"></i> 并行编程实验二
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/Pyinstaller%E6%89%93%E5%8C%85%E9%97%AE%E9%A2%98" rel="next" title="Pyinstaller打包问题">
                  Pyinstaller打包问题 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments"><div id="twikoo-comments"></div></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Tim</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js" integrity="sha256-4mJNT2bMXxcc1GCJaxBmMPdmah5ji0Ldnd79DKd1hoM=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha256-AjM0J5XIbiB590BrznLEgZGLnOQWrt62s3BEq65Q/I0=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js" integrity="sha256-9cmf7tcLdXpKsPi/2AWE93PbZpTp4M4tqzFk+lWomjU=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




<script class="next-config" data-name="twikoo" type="application/json">{"enable":true,"visitor":true,"envId":"https://twiko.zair.top/.netlify/functions/twikoo","el":"#twikoo-comments"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.twikoo.el)
    .then(() => NexT.utils.getScript(
      CONFIG.twikoo.jsUrl || 'https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js',
      { condition: window.twikoo }
    ))
    .then(() => {
      twikoo.init(CONFIG.twikoo);
    });
});
</script>
<style>
.post-block, .comments {
  overflow: visible;
}
.tk-owo-emotion {
  display: inline-block;
}
</style>

</body>
</html>
